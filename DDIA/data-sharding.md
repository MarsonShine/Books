# 数据分区

当数据量非常大的时候，查询的压力也就越来越大。随着数据量的增长，查询的时间也会越来越慢。这个时候我们就会将数据分区，拆分不到的区域范围，然后分别查询，最后根据需要将结果集合合并。

我们将数据拆分到不同的区域，首先我们要保证每条数据的落点是随机均匀分配的。如何随即均匀的分配这个在后面有提到常用的方案。特别是我们数据是部署到可用的，在不同的节点数据都是[复制荣誉](README.md)的。当我们决定对数据分区时，那么不同的节点的数据以及其他节点的副本数据都要同样实行切分。

我们可以通过**键值数据模型**进行分区，就像是图书馆的书架，我们很容易根据分类名称（键）找到对应的书本范围，然后这些书本都是按照一定的顺序排序放置的，这样我们就能在快速查找对应的书籍。

这种分布方式同样也是有限制场景的，比如局部的数据密集性查询，如在某个分类下的书籍越来越多，最终导致该分区写入还是很高，而其他分区始终处于空闲状态。又比如我们数据看以时间维度作为分区依据，每个分区对应一个时间范围（假设以天为单位），那么在某天的写入操作非常密集，这个时候同样也会导致上述问题。解决这个问题我们可以用除时间以外再以其他内容 + 时间范围共同作为分区依据。

我们还可以**基于关键字哈希值分区**。一个好的哈希函数，就可以让数据均匀的分布到各个节点。根据 key 的哈希值映射到不同分区。既然用哈希散列，自然就无法很好的支持排序，区间范围查询。但是我们可以在决定一个范围分区内进行某种排序，就如 [LSM-Tree/SSTable](https://github.com/MarsonShine/MS.Microservice/blob/8bffead6fbaf8339b0f90636b9c0576592dc2b49/docs/distribution-lock/time-series-database.md#日志结构的合并树lsm-tree) 说到的那样。

**基于文档分区的二级索引**：对于每个分区自己维护本地索引，如我要查颜色为红色，品牌为丰田的汽车。这样我们就会把颜色和品牌作为二级索引，就会快速查询到指定的数据（假设分区依据是主键的范围）。

**基于词条的二级索引分区**：维护一个对所有数据共享的全局索引，并且这个全局索引也要分区。

## 数据拆分的解决方案

### 取模分区

即 hash(key) mod 10，这样就能把数据拆分成 0-9 分区。它的优点就是很简单，但是确定就是当节点数量发生变化时的处理能力很弱，因为会涉及到数据的再分配。

### 固定数量分区

这个很好理解，实现起来也非常简单。总的来说就是要对现有公司数据量整体的一个把控。这样我们就能在数据看中预先拆分出不同的分区。

### 动态分区

当分区的数据增长到超过一个可配的参数阈值，它就开始拆分两个分区，每个分区承担一半的数量（实际上是均匀分配）。那么如果分区数据数量缩小的话，就会缩小到某个阈值以下，就会数据合并。

### 按节点比例分区

当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大的分区来存储，这种方法也可以使每个分区大小保持稳定。