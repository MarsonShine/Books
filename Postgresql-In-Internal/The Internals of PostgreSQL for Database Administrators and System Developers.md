PostgreSQL 的进程架构采用了一种多进程模型，而不是许多现代数据库常见的多线程模型。当你启动 PostgreSQL 服务时，后台会首先启动一个主进程，叫做 postmaster 或者说是“PostgreSQL server process”。这个主进程主要负责监听来自客户端的连接请求，并在有新连接时，为每个连接派生出一个新的子进程，也就是所谓的“客户端进程”或“后端进程”。每一个和数据库交互的会话，其实就是操作系统层面的独立进程，它们之间彼此隔离，各自处理对应客户端的 SQL 请求。

除了这些为客户端服务的进程，PostgreSQL 还会自动运行一系列“辅助进程”，这些进程负责数据库的日常维护，比如写 WAL（预写日志）、清理无用数据、定期刷写缓存到磁盘，以及检查点和统计信息收集等等。这些辅助进程和每个用户的会话进程一样，也是在操作系统中独立存在的进程。

整个架构的设计让 PostgreSQL 在并发处理和崩溃恢复上有很好的健壮性。如果某个连接的进程崩溃了，其他的连接进程和主进程依然可以继续工作，不会相互影响。同时，这种架构也让数据库在高负载下更容易利用多核 CPU 的性能优势。整体来说，PostgreSQL 用一组彼此独立、分工明确的进程协同工作，来保证数据库服务的高效和稳定。

## 索引相关性

`correlation` 反映了这个字段和插入顺序的“线性关系”，高相关性有利于某些类型的顺序扫描和优化。低相关性则意味着随机访问更多，查询时可能更依赖索引。可以通过下面语句查询：

```postgresql
SELECT tablename,attname,correlation FROM pg_stats WHERE tablename = 'sentencepatterns'
```

输出如下：

```
sentencepatterns	Description	1
sentencepatterns	Remark	1
sentencepatterns	CnTranslation	0.01702202
sentencepatterns	Id	0.86093146
sentencepatterns	Text	-0.1022805
sentencepatterns	PatternType	0.79632217
sentencepatterns	Status	1
sentencepatterns	CreateUser	0.9976231
sentencepatterns	CreateTime	0.8611384
sentencepatterns	SortOrder	-0.27549043
```

这里是指该列的“物理存储顺序”和表中行的“物理顺序”之间的线性相关系数。它的取值范围是 -1 到 1。

- 1 表示该列的值**完全按照表的物理顺序递增排列**。
- -1 表示该列的值**完全按照表的物理顺序递减排列**。
- 0 表示没有相关性，列的值分布与物理存储顺序基本无关。

这种相关性信息，PostgreSQL 会用来优化某些查询，比如在决定是否使用索引扫描时。

## PostgreSQL 的查询处理

PostgreSQL执行一条SQL查询语句的过程是一个复杂而精密的系统工程，涉及多个模块的协同工作。当客户端发送一条查询语句到PostgreSQL服务器时，这条语句会经历一个完整的生命周期，从最初的字符串形式转换为最终的执行结果。

### 语法语义分析

整个过程始于查询语句的接收。PostgreSQL的后端进程接收到来自客户端的SQL字符串后，首先会进行词法分析和语法分析。词法分析器（lexer）将SQL字符串分解为一系列的token，这些token包括关键字、标识符、操作符、常量等基本元素。随后，语法分析器（parser）根据PostgreSQL的SQL语法规则，将这些token组织成一个抽象语法树（AST）。这个语法树准确地表示了SQL语句的结构和语义。

在语法分析完成后，查询进入**分析阶段**。分析器会对语法树进行语义分析，这个过程包括名称解析、类型检查和权限验证。名称解析会将表名、列名等标识符与系统目录中的实际对象进行匹配，确保引用的对象确实存在。类型检查会验证操作的数据类型是否兼容，比如确保比较操作的两边具有可比较的类型。权限验证则会检查当前用户是否有权限访问查询中涉及的表和列。分析器还会处理视图的展开，将对视图的查询转换为对基础表的查询。

### 重写器

接下来是**查询重写阶段**。重写器会应用各种查询重写规则来优化查询。这些规则包括常量折叠、谓词下推、子查询提升等。常量折叠会在编译时计算出可以确定的表达式值，比如将"2+3"直接替换为"5"。谓词下推会将WHERE子句中的条件尽可能地推向数据源，减少需要处理的数据量。子查询提升会将某些子查询转换为连接操作，这通常能够带来更好的性能。

重写完成后，查询进入计划阶段，这是整个查询处理过程中最为复杂和关键的部分。计划器需要为查询生成一个执行计划，这个计划指定了如何从存储中获取数据以及如何处理这些数据来产生最终结果。

### 计划器

计划器首先会进行统计信息的收集和分析。PostgreSQL维护着详细的统计信息，包括表的行数、列值的分布、索引的选择性等。这些统计信息对于代价估计至关重要。计划器会查询系统目录中的 `pg_statistic` 表来获取这些信息。

对于每个表的访问，计划器需要决定使用哪种扫描方式。

- 顺序扫描是最基本的访问方式，它会从头到尾读取表中的每一行。这种方式在需要访问表中大部分数据时是最高效的。
- 索引扫描则通过索引来快速定位到满足条件的行，这在需要访问少量数据时非常高效。

计划器会根据**选择性**估计来决定使用哪种扫描方式。

选择性是指满足查询条件的行占总行数的比例。如果选择性很低（即满足条件的行很少），索引扫描通常是更好的选择。如果选择性很高，顺序扫描可能更高效，因为它避免了随机访问的开销。

### 代价估计

代价估计是计划器决策的核心。PostgreSQL使用一个基于代价的优化器，它会为每种可能的执行方案估计代价，然后选择代价最低的方案。代价模型考虑了多个因素，包括CPU代价、I/O代价、内存使用等。对于顺序扫描，代价主要是读取所有页面的I/O代价加上处理每行的CPU代价。对于索引扫描，代价包括读取索引页面的代价、根据索引访问表页面的代价，以及处理匹配行的CPU代价。

### 连接操作

当查询涉及多个表的连接时，计划器需要决定连接的顺序和方法。连接顺序的选择对性能有巨大影响，因为不同的连接顺序会产生不同大小的中间结果。计划器会使用动态规划算法来寻找最优的连接顺序，这个算法会考虑所有可能的连接顺序组合，并选择总代价最低的那个。

对于连接方法的选择，PostgreSQL支持三种主要的连接算法：

- **嵌套循环连接**是最基本的连接方法，它对外表的每一行，都会扫描内表来寻找匹配的行。这种方法在内表很小或者有高效索引的情况下表现良好。
- **归并连接**要求两个输入都已经按照连接键排序，然后同时扫描两个输入来寻找匹配的行。这种方法在处理大量数据时很高效，特别是当数据已经排序或者可以通过索引有序获取时。
- **散列连接**会将较小的表构建成散列表，然后扫描较大的表，对每一行在散列表中查找匹配。这种方法在内存充足且内表不太大时非常高效。

计划器会为每种连接方法估计代价，并选择最优的方法。代价估计会考虑输入的大小、是否需要排序、内存的使用情况等因素。

### 计划树的生成与执行

计划树的生成是一个自底向上的过程。计划器首先为每个基本表生成访问路径，然后逐步构建更复杂的操作。对于连接操作，计划器会考虑不同的连接顺序和连接方法，生成所有可能的路径。对于每个路径，计划器都会计算其代价，并保留代价最低的路径。

在处理复杂查询时，计划器还需要考虑其他操作，如排序、分组、聚合等。排序操作可能使用内存中的快速排序，也可能使用外部排序当数据量超过内存容量时。分组和聚合操作可能使用散列分组或排序分组，选择取决于数据的特性和可用内存。

计划完成后，查询进入执行阶段。执行器会根据计划树来执行查询。执行器采用火山模型（Volcano model），每个计划节点都是一个迭代器，支持初始化、获取下一行和清理三个基本操作。执行从计划树的根节点开始，根节点会向其子节点请求数据，子节点再向其子节点请求数据，这样递归地进行下去，直到叶节点（通常是表扫描操作）。

在执行过程中，PostgreSQL会进行各种优化。比如，它会尽可能地使用流水线处理，让不同的操作并行进行。它还会进行内存管理，确保查询不会使用过多的内存。对于大型查询，PostgreSQL可能会使用临时文件来存储中间结果。

### 其它操作

缓冲区管理也是执行过程中的重要部分。PostgreSQL维护着一个共享缓冲区池，用于缓存经常访问的数据页面。当需要访问一个页面时，执行器首先会检查这个页面是否已经在缓冲区中。如果在，就直接使用缓存的数据。如果不在，就需要从磁盘读取这个页面到缓冲区中。

锁管理确保了并发访问的正确性。PostgreSQL使用多版本并发控制（MVCC）来处理并发读写。每个事务都能看到数据的一个一致快照，而不需要阻塞其他事务。这通过为每行数据维护多个版本来实现。

整个查询执行过程还涉及错误处理和事务管理。如果在执行过程中出现错误，PostgreSQL会回滚已经进行的操作，确保数据的一致性。事务管理确保了ACID属性的满足，即原子性、一致性、隔离性和持久性。

当查询执行完成后，结果会被返回给客户端。对于大型结果集，PostgreSQL可能会使用游标来分批返回结果，避免一次性占用过多内存。

## 混合散列连接

在 PostgreSQL 的执行器里，散列连接本质上是一场“先造房子，再敲门”的流程：把连接键相同的内表行造进一张哈希表，然后让外表每条记录来敲门匹配。只要所有哈希桶能放得进 `work_mem`，这条路就顺滑；可一旦数据溢出内存，数据库只能把哈希表切成若干分区，写进临时文件，等下一轮再读回。这个策略叫混合散列连接（Hybrid Hash Join）。

现实数据往往并不均匀。取电商日志举例，可能只有十分之一的客户贡献了七成的订单。若直接把订单表当作外表探测，某些客户名对应的哈希桶会炸到离谱，内存反复 malloc/free，磁盘分区也突然膨胀，性能惨不忍睹。PostgreSQL 因此在 Hybrid Hash Join 上加了一道“倾斜批次」(skew batch)” 的工序：把外表里最常出现的连接键单独拉到内存里，专门配一张哈希表，先把这些热点一次性喂完，剩下的长尾再慢慢分批——官方称作**高频值（MCV，Most Common Values）**。

很多人第一反应是“MCV 难道要每次查询再统计？那得多慢”。答案是完全不用。数据库维护列统计的时机是 `ANALYZE` 或自动采样，结果塞进元表 `pg_statistic`。规划器读取这里的 MCV 列表，评估它们占多少行、总共多少字节，再衡量 `work_mem`。同意之后，执行器启动时一次性把与这些值对应的内表行插进一张专属哈希表，这便是倾斜批次。整个过程只和内表数据打交道，不扫描外表，所以开销微乎其微。

究竟哪一侧当内表？在纯粹的等值连接里，哈希连接是对称的，规划器会选择更小、更便宜、能够放下的那一边当 build-side。我们先前的例子里，`customers` 只有一万行，而 `purchase_history` 有一百万行，因此客户表几乎必定成为内表。至于写 SQL 时表名的先后顺序，对 INNER JOIN 并不起决定作用；真正影响决策的是**统计估算**、`work_mem` 的大小，以及可能的 join-order 约束或提示(hint)。

混合散列连接开始**构建阶段**时，会把内表分成 N 个批次。假设估算得出需要四个批次，其中 Batch 0 留在内存，Batch 1、2、3 写临时文件；于是磁盘上就只出现三份文件。批次号的分配由哈希值对 N 取模完成，规划器会尽量让每批次大小接近，同时满足 Batch 0 不超出 `work_mem`。倾斜批次并不算在这四里头，它是一块独立的内存区。

探测第一轮到来时，外表行被拆成三种命运。命中 MCV 的，直接击中倾斜批次；哈希值落在 0 号分区的，立即在内存哈希表里比对；其余分区的，写进各自的外表临时文件，等后续轮次再说。因为前两类常常覆盖大多数热数据，磁盘 I/O 压力被显著削弱。

**首轮结束后，那张“倾斜批次 + Batch 0”的哈希表已经没有任何外表行还会引用，执行器会把相关内存统统释放**。接下来它逐个把 Batch 1_in 读取进内存重建哈希桶，再用 Batch 1_out 去探测；然后是 Batch 2、Batch 3，如此反复。每轮都在同一块 `work_mem` 里完成 build-probe-free 的闭环，避免内存碎片与反复分配。

倾斜批次只是 PostgreSQL 针对数据分布极端不均的一剂局部解法。它依赖可靠的统计、足够的内存，以及合适的 join 方向。如果你理解了为什么要单独照顾那 10 % 的客户、为什么要先把 70 % 的外表行在内存里一次性结算，以及为什么四个批次只需要三份磁盘文件，那么你已经真正看懂了这项优化背后的设计取舍。

## 优化器中的查询代价最小路径

在 PostgreSQL 的优化器里，所谓“路径”(path) 并不是执行器真正跑的步骤，而是一种给优化器自己看的、极简化的“路线草图”
。它记录 “如果我要把目前已选的这些表拼成一个中间结果，我打算怎么扫每个表、怎么把它们接起来、预估还能剩多少行、要付出多少代价”。换句话说，它是一棵尚未长成的计划树的轮廓：扫描方式、连接顺序、连接算法、过滤点，都在这张草图里标了记号，但还没生成执行器能直接执行的完整 Plan。官方文档把这种对象称为 *Path*，在选出最便宜的一条之后才会“发育”成真正的 Plan 节点树交给执行器。

优化器先为每个基表各找几条候选路径——例如顺序扫、索引扫、位图索引扫等。接着用动态规划计算每种组合的 `total_cost` 值，并将最小值交给执行器执行的最终的计划树路径。

以下是使用动态规划确定最佳计划树的过程，其步骤如下：

- *第一层* 把 A、B、C 各自的最好/次好路径备好；
- *第二层* 让任意两张表两两配对，枚举 A x B、A x C、B x C 各种扫描-连接组合，得到这些二表集合的候选路径；
- *第三层* 再把二表集合跟剩下一张表去配对，得到覆盖 ABC 的路径。
- 对每个“子集合”只保留当前代价最小的那条（以及少数可能因排序键或并行度不同而保留下来的“可比”路径），这样避免了组合爆炸。这就是 System R 风格的 DP 搜索。

### “代价”到底怎么算

代价是一个抽象单位；只要相对大小可信，绝对值怎样都行。PostgreSQL 默认把顺序读一页磁盘的成本定为 1.0，然后其它动作都折算到同一把尺子上。成本模型由两大块累加而成：

| 成本分量 | 由什么决定                           | 粗略计算方式                                  |
| -------- | ------------------------------------ | --------------------------------------------- |
| I/O 成本 | 需要读写多少块页                     | 页数 × (顺序或随机的 page cost)               |
| CPU 成本 | 要处理多少行、做多少次比较/哈希/投影 | 行数 × (cpu_tuple_cost + cpu_operator_cost …) |

这些“定价参数”在 `postgresql.conf` 里能看到：`seq_page_cost`, `random_page_cost`, `cpu_tuple_cost`, `cpu_operator_cost`, `cpu_index_tuple_cost` 等 。

### **行数 (cardinality) 和选择性 (selectivity)**

要知道要处理多少行，先得估计过滤条件能筛掉多少数据。优化器用 `ANALYZE` 留下的列统计信息：柱状图、MCV 表、NDV 等来算选择性。三表联结时，它会把 `A 的行数 × 连接选择性`得到联结后留下的行数，再把这个结果作为下一步联结的“外表”行数，如此层层向上累加。

**不同连接算法的公式**

- 嵌套循环 (NLJ)：
   `cost = outer_cost + outer_rows × inner_cost_per_row + cpu_per_tuple`
   如果内侧能用索引，那 `inner_cost_per_row` 可能很低；否则就是顺扫整表。
- 哈希连接 (HJ)：
   `build_cost = build_rows × (tuple_cpu + hash_cpu) + build_IO`
   `probe_cost = outer_rows × (tuple_cpu + hash_cpu)`
   两者加总再考虑是否溢出到磁盘。
- 归并连接 (MJ)：
   需要两侧都按连接键有序；如果已排序则几乎是线性，若要先排序还要加上排序成本。

优化器把这些公式里的变量都替换成刚才估出来的行数、参数值，就能算出每条路径的 `startup_cost` 与 `total_cost`。再加上并行度、内存预算等限制，最后选 `total_cost` 最小者为“最优路径” 。

## 事务Id与回环

PostgreSQL 的每条元组都要在元数据里记录两个字段：`xmin`（插入它的事务 ID）和 `xmax`（删除它的事务 ID）。官方采用 32 位无符号整数来设计的。如果把事务 ID 做成 64 位整数，元组会立刻多出 8 字节—— 对于“行很小、行数巨大”的 OLTP 场景，存储与缓存代价极高。

于是 PostgreSQL 选择**用 32 位无符号整数**来保存 txid，只占 4 字节；但 32 位最多 42 亿个编号，长期运行就一定“用完”。解决办法便是把编号空间当作一个**环形刻度盘**：最多 42 亿格，指针走完一圈又回到 0。从此再也不会“编号枯竭”，而数据库仍旧只付出 4 字节的空间成本。

### 事务Id回环

环形编号带来一个新难题：**当指针绕了一圈重新指向一个旧号码时，怎样判断它到底是 10 年前的“老 42”还是刚刚分配的“新 42”？**

PostgreSQL 的做法是把 42 亿个刻度一刀对半：

| 区段                  | 距离本事务的“钟点” | 语义     | 可见性                      |
| --------------------- | ------------------ | -------- | --------------------------- |
| 前面半圈（约 2¹⁰⁺⁰⁰） | 0 ~ –2¹⁰⁺⁰⁰ – 1    | **过去** | 一律可见（取决于提交/回滚） |
| 后面半圈（约 2¹⁰⁺⁰⁰） | +1 ~ +2¹⁰⁺⁰⁰       | **未来** | 一律不可见                  |

> 注意，这里为了区分用了“带符号坐标”的方式来描述分割，实际上数值范围是  $0-2^{32}$

任何事务在读取元组时，只需把 `(tuple_xid - my_xid)` 放进 32 位无符号算术里：

- 若差值 < $2^{31}$：`tuple_xid` 在“未来”
- 弱差值 > $2^{31}$：`tuple_xid` 在“过去”

这样就用一个恒定 O(1) 的加法判断，避免了昂贵的 64 位比较或额外的“时代位”。逻辑顺序依旧保持严格单调：

- “过去”里的编号永远比我小（对我可见或可回收）
- “未来”里的编号永远比我大（对我不可见、也不可修改）

该举措有效避免了编号耗尽的问题。txid 是环形空间，可以绕圈使用，不存在“最大 ID 已用完”的断崖式故障，系统可以持续运行多年而不必重置。

其次，它保持了每个元组头部的存储紧凑，仅用 4 字节就能记录插入和删除事务的信息。相比使用 64 位 ID 节省了一半空间，尤其在存储上千万行时这一点极为关键。

再者，这种“环+半圈”策略让事务之间的可见性判断变得非常高效。通过一次无符号减法操作即可判断一个 txid 属于过去还是未来，大大简化了 MVCC 判断逻辑，并减少了 CPU 分支跳转，提升了查询性能。

最后，为了保证这个模型始终正确，PostgreSQL 还配套设计了**“冻结机制”**和**“反环绕保护”**。当某些 txid 太老，可能即将被新的事务号“追上”时，系统会通过强制 VACUUM 把这些老 txid 替换成特殊的“FrozenXID”，这样即使编号绕圈重叠，也不会误判老事务为新事务。这种保护机制让 PostgreSQL 能在不牺牲一致性的前提下安全运行数十年。

## MVCC 机制下的可见性规则

下面用一组demo，把典型的 MVCC 可见性判定情景逐一跑一遍。为了让重点一眼就能落在 “为什么看得见 / 为什么看不见”，每段都会标注元组头的 `xmin`、`xmax` 以及当前事务的快照内容。

> **示例环境**
>
> - PostgreSQL 16
>
> - 两个独立 psql 会话，分别记为 **S₁** 和 **S₂**
>
> - 表结构：
>
>   ```sql
>   CREATE TABLE demo_mvcc(id int primary key, note text);
>   INSERT INTO demo_mvcc VALUES (1, 'origin');
>   ```

### 场景 A：只有 `xmin`，行版本从未被改动

```postgresql
-- S₁（事务 T1）
BEGIN;
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬──────┬────────┐
│ xmin │ xmax │ note   │
├──────┼──────┼────────┤
│  575 │    0 │ origin │   ← xmax = 0 表示“尚未删除”
└──────┴──────┴────────┘
```

T1 的快照里没有活跃事务，且 `xmax = InvalidXID`。按 MVCC 规则：行可见——这是最朴素的一种情况。

### 场景 B：`xmax` 指向一个正在运行的事务

```postgresql
-- S₂（事务 T2）
BEGIN;
UPDATE demo_mvcc SET note = 'edited by T2' WHERE id = 1;  -- 产生新版本
-- 新行的 xmin = T2，旧行的 xmax = T2 (xmax = 576 假设)

-- S₁ 仍在原事务中再次读
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬─────────────┐
│ xmax │ note        │
├──────┼─────────────┤
│  576 │ origin      │   ← xmax=576 但 T2 未提交
└──────┴─────────────┘
```

T1 的快照把 T2 视为活跃；`xmax` 虽然非零，却对应“未完成事务”。**删除尚未生效**，旧版本仍然对 T1 可见。

### 场景 C：`xmax` 已提交，但在快照里仍是活跃

```postgresql
-- S₂ 提交
COMMIT;               -- T2 now COMMITTED

-- S₁ 仍保持原快照再次读
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬─────────────┐
│ xmax │ note        │
├──────┼─────────────┤
│  576 │ origin      │   ← t_xmax state = COMMITTED
└──────┴─────────────┘
```

**关键点**：T1 启动得更早，快照里依旧把 576 视作“活跃”。因此，即便系统全局显示 576 已提交，T1 还是把该删除操作当作“未来事件”，继续看见旧版本。

### 场景 D：`xmax` 已提交，且在快照里非活跃

```postgresql
-- 结束 T1
COMMIT;

-- 新会话 S₃（事务 T3）
BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED;
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

(0 rows)
```

T3 的快照生成时，576 已被列入已提交集合而非活跃集合；删除操作正式生效，**旧版本对 T3 不可见**。

### 场景 E：`xmin` 对应事务已回滚

```postgresql
-- S₂ 新开事务 T4
BEGIN;
INSERT INTO demo_mvcc VALUES (2, 'temp');
-- T4 decides to abort
ROLLBACK;

-- S₁ 新事务 T5
BEGIN;
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 2;

(0 rows)
```

行版本的 `xmin = T4`，而 T4 最终 ABORTED；快照规则直接排除“未成功的插入”，所以任何事务都看不到这行——直到被 autovacuum 清理。

### 场景 F：冻结（`xmin = FrozenXID`）

```postgresql
VACUUM FREEZE demo_mvcc;        -- 12+ 亿行才常见，此处强行演示
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬──────┬───────────┐
│ xmin │ xmax │ note      │
├──────┼──────┼───────────┤
│    2 │  576 │ origin    │
└──────┴──────┴───────────┘
```

`xmin` 被改写为特殊值 2（`FrozenXID`），意为“久远过去的行”。任何未来快照都会把它当成历史数据直接可见，而不再与具体事务状态关联。

### 场景 G：可滚动游标下的“旧快照”

```postgresql
-- S₁
BEGIN;
DECLARE c CURSOR FOR SELECT note FROM demo_mvcc ORDER BY id;
FETCH NEXT FROM c;     -- 取得 'origin'
-- S₂ 再次插入新行 id=3
BEGIN; INSERT INTO demo_mvcc VALUES (3,'later'); COMMIT;

-- S₁ 继续 fetch
FETCH NEXT FROM c;     -- 仍只能拿到快照时存在的行
```

游标 `c` 固定使用声明时的快照；即便游标生命周期内有新行插入，也不会被它看到。

在 PostgreSQL 的 MVCC 可见性判定中，最典型的情况是行从未被修改，此时只有 `xmin` 字段，这意味着这行是直接可见的。

当行的 `xmax` 字段指向一个仍处于活跃状态的事务（或者即使该事务已经提交，但在当前快照里仍然被视为“活跃”），这说明该行的删除操作还没有对本事务生效，因此这行依然可以被读到。只有当 `xmax` 对应的事务已经提交，并且在本次快照中被判定为非活跃，删除操作才会正式生效，此时这条记录对于本事务就不可见了。

如果一行的 `xmin` 事务回滚，那么这行自始至终都不会出现在任何事务的视野中。

至于那些经过 VACUUM FREEZE 处理、`xmin` 被标记为特殊冻结值的历史行，对于所有快照来说都直接可见，不再受事务环绕与快照隔离影响。

此外，如果在声明游标时已经生成了快照，那么游标在后续操作过程中只会看到声明时快照内的内容，即使有新数据写入也不会被游标“看到”。

## 缓冲管理器

### 环形缓冲区

在读写大表时，PostgreSQL会使用环形缓冲区而不是缓冲池。环形缓冲器是一个很小的临时缓冲区域。PostgreSQL将在共享内存中分配一个环形缓冲区。 环形缓冲区的好处显而易见，如果后端进程在不使用环形缓冲区的情况下读取大表，则所有存储在缓冲池中的页面都会被移除，这会导致缓存命中率降低。环形缓冲区可以避免此问题。

在 PostgreSQL 里，所谓“环形缓冲区”（ring buffer）并不是另一套独立的缓存，而是把 **shared buffers** 中的一小撮块临时划出来，按“首尾相连”的圆环方式循环重用。它只在极端顺序、大批量的 I/O 场景里才会被后台进程拿来用，目的是保护主缓冲池里原本的热点页不被一口气冲掉。

当后端进程开始顺序扫描一个足够大的关系（默认判定标准是：表大小超过 `shared_buffers / 4`），或执行 `COPY FROM`、`CREATE TABLE AS`、`REFRESH MATERIALIZED VIEW`、`VACUUM` 等一次性吞吐量很高的操作时，缓冲管理器会为这个进程分配一种叫 `BAS_BULKREAD / BAS_BULKWRITE / BAS_VACUUM` 的 Buffer 访问策略。该策略背后对应的就是环形缓冲区：

- 对纯读（Bulk Read）和 VACUUM 而言，环形区固定只有 32 个页，也就是 32 × 8 KB ≈ 256 KB；
- 对大量写入（Bulk Write）场景，环形区扩大到 16 MB；
- 这块小环在扫描结束后立即释放给整个缓冲池重新调度。

为什么要这样做？如果让一个顺序扫描照常通过全局时钟淘汰算法去申请新页，它会源源不断把整张大表搬进 shared buffers，原先缓存的小热表、索引页很快就被挤走；扫描一结束，这些页往往再也用不上，于是命中率骤降。把“搬运大表”限定在 256 KB～16 MB 这么小的环里，相当于告诉缓存管理器：“这些块只要保持短期可用即可，转完一圈就可以覆盖”，从而把主缓冲池的大部分空间留给真正需要长时间保留的工作集。

实现上，环形缓冲区完全沿用 shared buffers 的数据结构，只是在取替换页时不再走全局时钟，而是把指针限制在自己的小环里循环前进；写脏页、并发锁和 WAL 刷新等规则都与普通缓冲页一致。这种设计让顺序扫的大吞吐与事务型 OLTP 的热点缓存可以在同一实例里和平共处，不会互相“踩页面”。

> 为什么批量读取和清理过程的默认环形缓冲区大小为256 KB？
>
> 源代码中缓冲区管理器目录下的README中解释了这个问题。顺序扫描使用256KB的环形缓冲区，它足够小，因而能放入L2缓存中，从而使得操作系统缓存到共享缓冲区的页面传输变得高效。通常更小一点也可以，但环形缓冲区需要足够大到能同时容纳扫描中被钉住的所有页面。

## PostgreSQL 中的数据库恢复

在 PostgreSQL 发生宕机并重新启动时，整个实例会先读取 `pg_control` 文件来判断上一次关机是否干净。如果状态字段显示数据库是“in production”，就代表之前没有正常停机，于是服务器自动切换到恢复模式；如果状态是“shut down”，则直接按照常规启动流程继续工作而无需重放日志。进入恢复模式后，启动进程根据 `pg_control` 中保存的最近一次成功检查点位置去定位相应的 WAL 段文件。检查点记录里包含重做点（redo LSN），这是日志重放的起跑线。假如那条检查点损坏，启动进程会退一步去找更早的检查点记录；注意：PostgreSQL 11 之后只存最近一份，丢弃了上上次的检查点记录。

找到检查点后，系统开始顺序读取并重放 WAL 里的 XLOG 记录，从重做点一直推进到日志流的末尾。每条记录对应一次数据页或元数据的修改。若该记录带有“备份区块”（full-page image），就像一张完整快照，无论当前页面是什么状态，都可以直接覆盖，因为这样做不会破坏一致性，也不会因为重复应用而出错，是天然幂等操作。其余普通记录则只是一份“增量补丁”，重放前必须先看它的 LSN 是否比目标数据页头里的 `pd_lsn` 更新；只有当日志记录更新、也就是 LSN 更大时，才真正把修改写回页面，确保旧补丁不会覆盖新数据、补丁也不会被重复打在同一页上。正是这一步对比让恢复过程能够既按顺序前进又保证结果一致，即使在相互交错的大量并发事务场景里也不会出现乱序。

> LSN 自身并不是存放在某块内存里的单独数据，而是 WAL 流上的“位移指针”。当后台或提交路径把 WAL 缓冲区刷新到 `pg_wal` 目录并 `fsync()` 时，那段日志及其 LSN 一并落盘。默认配置下，每次事务提交都会调用 `XLogFlush()` 等待所需日志持久化后才向前端返回“提交成功”。如果崩溃发生在刷新之前，相关日志还停留在共享内存，随电源消失，但事务没有收到成功确认；如果崩溃发生在刷新之后，日志已经在磁盘，恢复进程自然可以用它们把所有已确认的修改重新“重做”出来。换言之，只要保持默认的同步提交和 `fsync=on`，客户端见到的每一个 COMMIT 都意味着对应的 WAL 已经安全存储，因此突然断电不会造成已确认数据的丢失；只有当人为把 `synchronous_commit` 调成异步或关闭 `fsync`，才会引入一个极短的风险窗口，那时“日志写到了内核页缓存但尚未真正落盘”的几毫秒内数据确实可能丢失，这是一种有意识的可靠性与性能权衡，而非 PostgreSQL 默认行为。

整个恢复过程就像把一卷磁带倒带到最后一次对齐的存档点，再一路向前播放最新录制的影像，把未落盘的数据补齐。备份块确保任何时刻都有“整张底片”可用，普通块加上 LSN 比对保证补丁不会乱序，`pg_control` 记录当下磁带是否在正确位置。正是这些机制配合，才让 PostgreSQL 即使遭遇最粗暴的 kill-9 或满盘掉电，也能在下一次启动时原封不动地回到一个一致、完整、只缺失未确认事务的安全状态。

### 时间点恢复（PITR）的工作原理

时间点恢复（Point-in-Time Recovery, PITR）依赖于两份信息：一份是在运行期间通过 `pg_start_backup()` 触发的基础备份，另一份是之后连续归档的所有 WAL 段。基础备份保存了某一时刻磁盘上所有数据文件的原样拷贝；WAL 段按顺序记录自该时刻起发生的每一次页修改与事务状态变更。将这两部分结合，就可以把实例状态精确地还原到日志流中的任何时间戳。

恢复节点的启动程序首先在数据目录中查找 `backup_label` 和 `recovery.conf`。两者同时存在时，服务器不会以普通方式直接挂载数据文件，而是进入恢复模式。`backup_label` 记录了最后一个有效检查点的 WAL 位置，启动进程据此定位到归档目录中对应的段文件，并将该位置视为重做起点。与此同时，它解析 `recovery.conf` 中的参数：`restore_command` 定义了如何把指定段号的归档日志复制到本地临时目录；`recovery_target_time` 设定了回放的终止条件。

当 WAL 流开始回放，每条记录都会按照生成顺序依次应用到数据页。如果记录中带有 full-page image，恢复进程直接用整页内容覆盖目标页面，确保即便之前磁盘快照不一致，恢复后也能处于有效状态。对于普通增量记录，则要先比对记录 LSN 与页头 `pd_lsn`；只有日志位置更新时才执行写入，从而避免反复打补丁或因乱序导致数据回滚。提交和回滚消息本身携带高精度时间戳，进程在回放到这些记录时把时间戳与 `recovery_target_time` 比较，一旦超过目标时刻就立刻停止。回放结束后，系统生成新的 timeline ID 与相应的 `.history` 文件，标记出恢复分叉点并防止后续归档与原来时间线混淆。

这种实现的关键在于 WAL 记录的幂等设计和检查点机制：即便基础备份期间各数据文件的写入时序不同步，full-page image 也能在重做早期将缺口补齐；随后顺序重放的增量记录再把数据库推进到目标时间。正因为如此，制作基础备份时不要求文件系统快照或特殊备份介质，使用 `tar`、`rsync` 等通用工具即可。唯一需要保证的是从备份开始到恢复目标之间的归档日志必须完整无缺。如果归档链条连续，PostgreSQL 就能够凭借回放流程把任何一份“逻辑上不一致”的文件集合纠正为一致状态，并在指定时间点完成交付。

> 设想你在拍一部长篇电视剧。每天收工前，导演会把当天拍好的素材复制到一份安全的硬盘里，这份硬盘就好比 **“基础备份”**；而摄影机同时也不断把每一次镜头切换、台词修改都记进一条条“事件日志”，这些日志对应 PostgreSQL 的 **WAL 归档文件**。只要你手里既有那块基础硬盘，又保存了拍戏全过程的事件日志，就能把剧情回放到任何一个时间点——哪怕演员即兴说错了台词，你也能倒回到台词出错前那一秒，重新开机重拍。这就是 **时间点恢复（PITR）** 的核心思想。
>
> 当数据库因为误操作或灾难需要“回到过去”时，你会先把旧片场（原有数据目录）全部丢弃，换上一份早先拷贝出的基础备份。随后放一张“导演指令卡”到片场里——这张卡就是 **recovery.conf**，上面写着两句话：第一句告诉数据库去哪里拿保存的事件日志（`restore_command`），第二句告诉它要倒带到几点几分（`recovery_target_time`）。
>
> 数据库一启动，看见片场里同时存在 `backup_label`（基础备份自带的说明）与 `recovery.conf`，就知道此刻不能直接营业，而要进入“回放模式”。它先读 `backup_label`，找到拍摄现场最后一次“正式喊卡”——这相当于**检查点**的位置。接着，它按照 `restore_command` 不断把事件日志文件复制进临时工作区，并从那条检查点开始一条条重播：插入过的行再插进去，删除过的行再删一次，一切严格依照时间顺序进行。当回放进度的“时间戳”追上 `recovery_target_time`，数据库便理解为穿越成功，正式结束恢复并切换到可读写状态。

### 时间线与时间线历史文件

“时间线”是把连续 WAL 记录划分为一条条有清晰血缘关系的轨迹，它用一个不断递增的十六进制编号来区分不同的历史分支。时间线 1 通常在初始化集簇时诞生，而每当库通过 PITR 回到过去或把只读备库提升为新的主库，系统都会在恢复结束的那一刻挑选下一个可用编号，切换到一条全新的轨迹。这样做的目的是在物理层面隔离“旧世界”与“新世界”的 WAL 流，防止后续归档或流复制把来自不同历史的段文件混淆在一起。

时间线编号不仅写进内存状态，还嵌入每一个 WAL 段文件名的高八位；当恢复完成并对外开放写入时，最后一段来自旧编号的部分文件会被复制一份，改头换面为新编号继续追加。与此同时，一份后缀为 `.history` 的文本文件被写入 `pg_wal` 目录并立即归档。文件名与新时间线同号，内部逐行记录“本时间线起源于哪条父时间线、在父线的哪个 LSN 处分叉”之类信息。借助这个信息，任何节点在处理归档目录里同时存在多条分支的段文件时，都能沿着正确的祖先链把日志接续下去，避免误吸收别人分支上的写入。

时间线带来的最大收益在于可重复的灾备流程。只要归档中同时保留 WAL 段和相应的 .history 文件，就可以基于任意过去的检查点反复做第二、第三次 PITR，而不会破坏之前产生的分支。每次恢复都会把新分支写出新的 .history，归档系统像“家谱管理员”一样按时间轴把所有分叉都完整保存。运维人员只需保证不同集群或备库的归档路径不要意外合流，就能在需要时随意切换祖先，甚至把备库从时间线 4 拉回线 2 再向另一条方向演进，所有节点都能准确理解这幅树状拓扑，并各自在正确的枝叶上前进。

正因如此，时间线和 .history 文件是 PostgreSQL 物理备份体系里不可或缺的元数据：它们让一连串静态文件拥有了拓扑关系，也让 WAL 重放在多分支环境下依然保持确定性。理解这套机制后，管理者就能更放心地做多次回滚、灰度演练或备库提升，而不必担心哪一段日志会误写到不该写的地方。

#### 例子

举个例子来说明上述的过程：

1. **初始状态：时间线1**

   首先初始化一个新的 PostgreSQL 数据库集群时，它就开启了它的第一个时间线。上面记载的所有记录都属于时间线 1 (Timeline ID = 1)。只要数据库正常运行，不断有新的事务发生，它就会一直在这条时间线上前进。所有产生的 WAL 日志文件，其文件名中都会隐含这个时间线 ID。

2. **历史的岔路口：时间线的诞生**

   现在，意外发生了。你在下午3点钟，不小心执行了一个 `DROP TABLE`，删掉了一张非常重要的表。你慌了，但幸好你有备份！于是你决定使用**时间点恢复（Point-In-Time Recovery, PITR）**功能，把数据库恢复到下午2点59分的状态。

   于是你做了以下操作：

   - 找到一个昨晚的**基础备份（Base Backup）**。
   - 将备份恢复到一个新的地方。
   - 配置恢复参数，告诉 PostgreSQL：“请使用 WAL 日志，把我恢复到下午2点59分那个时间点，然后就停下来。”

   PostgreSQL 忠实地执行了你的命令。它重放（replay）了从昨晚到今天下午2点59分的所有 WAL 日志。现在，数据库的状态和你删除表之前一模一样。

   恢复完成后，你启动了数据库，开始写入新的数据（比如，重新创建了一个用户）。这时，数据库面临一个选择：

   - 选择A (错误的)：继续使用原来的时间线 1 来记录新的 WAL 日志。
   - 选择B (正确的)：创建一个新的时间线，比如时间线 2 (Timeline ID = 2)。

   想象一下，在原来的时间线 1 上，下午3点的位置已经记录了 DROP TABLE 这个“灾难性”事件。如果你现在继续在时间线 1 上写，新的记录就会和旧的“错误历史”混在一起。这会导致巨大的混乱和潜在的数据损坏。

   为了明确区分“被抛弃的旧历史”和“恢复后开始的新历史”，PostgreSQL 必须创建一个新的时间线。

   > 结论一：时间线（Timeline）是数据库历史的一个唯一标识符。每当数据库从一个历史时间点恢复并开始产生与原始历史不同的新变更时，就会创建一个新的时间线。

3. **历史文件的诞生和命名**

   现在我们经过多次恢复操作，有了多个时间线（多个平行宇宙），问题来了：**我们怎么知道时间线 2 是从时间线 1 的哪个点分叉出来的？**

   如果未来数据库又崩溃了，需要再次恢复，它怎么知道应该沿着哪条路径走？它需要一张“时空地图”来导航。

   这张地图，就是**时间线历史文件（Timeline History File）**。

   当一个新的时间线（比如 Timeline 2）被创建时，PostgreSQL 会立刻在 pg_wal 目录下创建一个名为 `00000002.history` 的文件（文件名中的数字就是新的时间线 ID）。

4. **历史文件内容**

   这个文件的内容非常简单，但至关重要。它记录了**“我是谁，我从哪里来”**。

   打开 `00000002.history` 文件，你可能会看到这样一行内容：

   ```
   1    0/50005B0    no recovery target specified
   ```

   这行内容可以解读为：

   - **1**: **父时间线 ID (Parent Timeline ID)**。它告诉我们，当前的时间线 2 是从时间线 1 分叉出来的。
   - **0/50005B0**: **分叉点的 LSN (Log Sequence Number)**。这是 WAL 日志中的一个精确坐标，指明了在时间线 1 的哪个位置发生了分叉。恢复过程会沿着时间线 1 读取到这个 LSN，然后切换到时间线 2。
   - **no recovery target specified**: **原因（Reason）**。一个可读的文本，解释了为什么会发生这次分叉。

   > **结论二：时间线历史文件（.history file）就是一张“历史地图”，它记录了每一次时间线切换的详细信息：从哪条旧时间线（Parent ID）的哪个精确位置（LSN）分叉出来，形成了这条新时间线。**

5. **历史文件如何工作？**

   假设我们的数据库在时间线 2 上运行了一段时间后，又崩溃了。现在我们需要再次进行恢复。

   1. 恢复进程启动，它查看控制文件（`pg_control`），发现自己当前处于时间线 2。
   2. 它需要找到时间线 2 的起点。于是它去 `pg_wal` 目录寻找 `00000002.history` 文件。
   3. 它读取文件内容，知道了：“哦，我的历史始于时间线 1 的 `0/50005B0` 这个点。”
   4. 于是，恢复进程会先去寻找时间线 1 的 WAL 日志，一直重放到 `0/50005B0`。
   5. 然后，它切换到时间线 2，开始寻找并重放时间线 2 的 WAL 日志。

   如果没有这个历史文件，恢复进程就像一个失忆的旅行者，不知道自己的起点在哪里，也就无法完整地重构整个历史。

