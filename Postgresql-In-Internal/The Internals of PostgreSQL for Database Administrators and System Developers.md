PostgreSQL 的进程架构采用了一种多进程模型，而不是许多现代数据库常见的多线程模型。当你启动 PostgreSQL 服务时，后台会首先启动一个主进程，叫做 postmaster 或者说是“PostgreSQL server process”。这个主进程主要负责监听来自客户端的连接请求，并在有新连接时，为每个连接派生出一个新的子进程，也就是所谓的“客户端进程”或“后端进程”。每一个和数据库交互的会话，其实就是操作系统层面的独立进程，它们之间彼此隔离，各自处理对应客户端的 SQL 请求。

除了这些为客户端服务的进程，PostgreSQL 还会自动运行一系列“辅助进程”，这些进程负责数据库的日常维护，比如写 WAL（预写日志）、清理无用数据、定期刷写缓存到磁盘，以及检查点和统计信息收集等等。这些辅助进程和每个用户的会话进程一样，也是在操作系统中独立存在的进程。

整个架构的设计让 PostgreSQL 在并发处理和崩溃恢复上有很好的健壮性。如果某个连接的进程崩溃了，其他的连接进程和主进程依然可以继续工作，不会相互影响。同时，这种架构也让数据库在高负载下更容易利用多核 CPU 的性能优势。整体来说，PostgreSQL 用一组彼此独立、分工明确的进程协同工作，来保证数据库服务的高效和稳定。

## 索引相关性

`correlation` 反映了这个字段和插入顺序的“线性关系”，高相关性有利于某些类型的顺序扫描和优化。低相关性则意味着随机访问更多，查询时可能更依赖索引。可以通过下面语句查询：

```postgresql
SELECT tablename,attname,correlation FROM pg_stats WHERE tablename = 'sentencepatterns'
```

输出如下：

```
sentencepatterns	Description	1
sentencepatterns	Remark	1
sentencepatterns	CnTranslation	0.01702202
sentencepatterns	Id	0.86093146
sentencepatterns	Text	-0.1022805
sentencepatterns	PatternType	0.79632217
sentencepatterns	Status	1
sentencepatterns	CreateUser	0.9976231
sentencepatterns	CreateTime	0.8611384
sentencepatterns	SortOrder	-0.27549043
```

这里是指该列的“物理存储顺序”和表中行的“物理顺序”之间的线性相关系数。它的取值范围是 -1 到 1。

- 1 表示该列的值**完全按照表的物理顺序递增排列**。
- -1 表示该列的值**完全按照表的物理顺序递减排列**。
- 0 表示没有相关性，列的值分布与物理存储顺序基本无关。

这种相关性信息，PostgreSQL 会用来优化某些查询，比如在决定是否使用索引扫描时。

## PostgreSQL 的查询处理

PostgreSQL执行一条SQL查询语句的过程是一个复杂而精密的系统工程，涉及多个模块的协同工作。当客户端发送一条查询语句到PostgreSQL服务器时，这条语句会经历一个完整的生命周期，从最初的字符串形式转换为最终的执行结果。

### 语法语义分析

整个过程始于查询语句的接收。PostgreSQL的后端进程接收到来自客户端的SQL字符串后，首先会进行词法分析和语法分析。词法分析器（lexer）将SQL字符串分解为一系列的token，这些token包括关键字、标识符、操作符、常量等基本元素。随后，语法分析器（parser）根据PostgreSQL的SQL语法规则，将这些token组织成一个抽象语法树（AST）。这个语法树准确地表示了SQL语句的结构和语义。

在语法分析完成后，查询进入**分析阶段**。分析器会对语法树进行语义分析，这个过程包括名称解析、类型检查和权限验证。名称解析会将表名、列名等标识符与系统目录中的实际对象进行匹配，确保引用的对象确实存在。类型检查会验证操作的数据类型是否兼容，比如确保比较操作的两边具有可比较的类型。权限验证则会检查当前用户是否有权限访问查询中涉及的表和列。分析器还会处理视图的展开，将对视图的查询转换为对基础表的查询。

### 重写器

接下来是**查询重写阶段**。重写器会应用各种查询重写规则来优化查询。这些规则包括常量折叠、谓词下推、子查询提升等。常量折叠会在编译时计算出可以确定的表达式值，比如将"2+3"直接替换为"5"。谓词下推会将WHERE子句中的条件尽可能地推向数据源，减少需要处理的数据量。子查询提升会将某些子查询转换为连接操作，这通常能够带来更好的性能。

重写完成后，查询进入计划阶段，这是整个查询处理过程中最为复杂和关键的部分。计划器需要为查询生成一个执行计划，这个计划指定了如何从存储中获取数据以及如何处理这些数据来产生最终结果。

### 计划器

计划器首先会进行统计信息的收集和分析。PostgreSQL维护着详细的统计信息，包括表的行数、列值的分布、索引的选择性等。这些统计信息对于代价估计至关重要。计划器会查询系统目录中的 `pg_statistic` 表来获取这些信息。

对于每个表的访问，计划器需要决定使用哪种扫描方式。

- 顺序扫描是最基本的访问方式，它会从头到尾读取表中的每一行。这种方式在需要访问表中大部分数据时是最高效的。
- 索引扫描则通过索引来快速定位到满足条件的行，这在需要访问少量数据时非常高效。

计划器会根据**选择性**估计来决定使用哪种扫描方式。

选择性是指满足查询条件的行占总行数的比例。如果选择性很低（即满足条件的行很少），索引扫描通常是更好的选择。如果选择性很高，顺序扫描可能更高效，因为它避免了随机访问的开销。

### 代价估计

代价估计是计划器决策的核心。PostgreSQL使用一个基于代价的优化器，它会为每种可能的执行方案估计代价，然后选择代价最低的方案。代价模型考虑了多个因素，包括CPU代价、I/O代价、内存使用等。对于顺序扫描，代价主要是读取所有页面的I/O代价加上处理每行的CPU代价。对于索引扫描，代价包括读取索引页面的代价、根据索引访问表页面的代价，以及处理匹配行的CPU代价。

### 连接操作

当查询涉及多个表的连接时，计划器需要决定连接的顺序和方法。连接顺序的选择对性能有巨大影响，因为不同的连接顺序会产生不同大小的中间结果。计划器会使用动态规划算法来寻找最优的连接顺序，这个算法会考虑所有可能的连接顺序组合，并选择总代价最低的那个。

对于连接方法的选择，PostgreSQL支持三种主要的连接算法：

- **嵌套循环连接**是最基本的连接方法，它对外表的每一行，都会扫描内表来寻找匹配的行。这种方法在内表很小或者有高效索引的情况下表现良好。
- **归并连接**要求两个输入都已经按照连接键排序，然后同时扫描两个输入来寻找匹配的行。这种方法在处理大量数据时很高效，特别是当数据已经排序或者可以通过索引有序获取时。
- **散列连接**会将较小的表构建成散列表，然后扫描较大的表，对每一行在散列表中查找匹配。这种方法在内存充足且内表不太大时非常高效。

计划器会为每种连接方法估计代价，并选择最优的方法。代价估计会考虑输入的大小、是否需要排序、内存的使用情况等因素。

### 计划树的生成与执行

计划树的生成是一个自底向上的过程。计划器首先为每个基本表生成访问路径，然后逐步构建更复杂的操作。对于连接操作，计划器会考虑不同的连接顺序和连接方法，生成所有可能的路径。对于每个路径，计划器都会计算其代价，并保留代价最低的路径。

在处理复杂查询时，计划器还需要考虑其他操作，如排序、分组、聚合等。排序操作可能使用内存中的快速排序，也可能使用外部排序当数据量超过内存容量时。分组和聚合操作可能使用散列分组或排序分组，选择取决于数据的特性和可用内存。

计划完成后，查询进入执行阶段。执行器会根据计划树来执行查询。执行器采用火山模型（Volcano model），每个计划节点都是一个迭代器，支持初始化、获取下一行和清理三个基本操作。执行从计划树的根节点开始，根节点会向其子节点请求数据，子节点再向其子节点请求数据，这样递归地进行下去，直到叶节点（通常是表扫描操作）。

在执行过程中，PostgreSQL会进行各种优化。比如，它会尽可能地使用流水线处理，让不同的操作并行进行。它还会进行内存管理，确保查询不会使用过多的内存。对于大型查询，PostgreSQL可能会使用临时文件来存储中间结果。

### 其它操作

缓冲区管理也是执行过程中的重要部分。PostgreSQL维护着一个共享缓冲区池，用于缓存经常访问的数据页面。当需要访问一个页面时，执行器首先会检查这个页面是否已经在缓冲区中。如果在，就直接使用缓存的数据。如果不在，就需要从磁盘读取这个页面到缓冲区中。

锁管理确保了并发访问的正确性。PostgreSQL使用多版本并发控制（MVCC）来处理并发读写。每个事务都能看到数据的一个一致快照，而不需要阻塞其他事务。这通过为每行数据维护多个版本来实现。

整个查询执行过程还涉及错误处理和事务管理。如果在执行过程中出现错误，PostgreSQL会回滚已经进行的操作，确保数据的一致性。事务管理确保了ACID属性的满足，即原子性、一致性、隔离性和持久性。

当查询执行完成后，结果会被返回给客户端。对于大型结果集，PostgreSQL可能会使用游标来分批返回结果，避免一次性占用过多内存。

## 混合散列连接

在 PostgreSQL 的执行器里，散列连接本质上是一场“先造房子，再敲门”的流程：把连接键相同的内表行造进一张哈希表，然后让外表每条记录来敲门匹配。只要所有哈希桶能放得进 `work_mem`，这条路就顺滑；可一旦数据溢出内存，数据库只能把哈希表切成若干分区，写进临时文件，等下一轮再读回。这个策略叫混合散列连接（Hybrid Hash Join）。

现实数据往往并不均匀。取电商日志举例，可能只有十分之一的客户贡献了七成的订单。若直接把订单表当作外表探测，某些客户名对应的哈希桶会炸到离谱，内存反复 malloc/free，磁盘分区也突然膨胀，性能惨不忍睹。PostgreSQL 因此在 Hybrid Hash Join 上加了一道“倾斜批次」(skew batch)” 的工序：把外表里最常出现的连接键单独拉到内存里，专门配一张哈希表，先把这些热点一次性喂完，剩下的长尾再慢慢分批——官方称作**高频值（MCV，Most Common Values）**。

很多人第一反应是“MCV 难道要每次查询再统计？那得多慢”。答案是完全不用。数据库维护列统计的时机是 `ANALYZE` 或自动采样，结果塞进元表 `pg_statistic`。规划器读取这里的 MCV 列表，评估它们占多少行、总共多少字节，再衡量 `work_mem`。同意之后，执行器启动时一次性把与这些值对应的内表行插进一张专属哈希表，这便是倾斜批次。整个过程只和内表数据打交道，不扫描外表，所以开销微乎其微。

究竟哪一侧当内表？在纯粹的等值连接里，哈希连接是对称的，规划器会选择更小、更便宜、能够放下的那一边当 build-side。我们先前的例子里，`customers` 只有一万行，而 `purchase_history` 有一百万行，因此客户表几乎必定成为内表。至于写 SQL 时表名的先后顺序，对 INNER JOIN 并不起决定作用；真正影响决策的是**统计估算**、`work_mem` 的大小，以及可能的 join-order 约束或提示(hint)。

混合散列连接开始**构建阶段**时，会把内表分成 N 个批次。假设估算得出需要四个批次，其中 Batch 0 留在内存，Batch 1、2、3 写临时文件；于是磁盘上就只出现三份文件。批次号的分配由哈希值对 N 取模完成，规划器会尽量让每批次大小接近，同时满足 Batch 0 不超出 `work_mem`。倾斜批次并不算在这四里头，它是一块独立的内存区。

探测第一轮到来时，外表行被拆成三种命运。命中 MCV 的，直接击中倾斜批次；哈希值落在 0 号分区的，立即在内存哈希表里比对；其余分区的，写进各自的外表临时文件，等后续轮次再说。因为前两类常常覆盖大多数热数据，磁盘 I/O 压力被显著削弱。

**首轮结束后，那张“倾斜批次 + Batch 0”的哈希表已经没有任何外表行还会引用，执行器会把相关内存统统释放**。接下来它逐个把 Batch 1_in 读取进内存重建哈希桶，再用 Batch 1_out 去探测；然后是 Batch 2、Batch 3，如此反复。每轮都在同一块 `work_mem` 里完成 build-probe-free 的闭环，避免内存碎片与反复分配。

倾斜批次只是 PostgreSQL 针对数据分布极端不均的一剂局部解法。它依赖可靠的统计、足够的内存，以及合适的 join 方向。如果你理解了为什么要单独照顾那 10 % 的客户、为什么要先把 70 % 的外表行在内存里一次性结算，以及为什么四个批次只需要三份磁盘文件，那么你已经真正看懂了这项优化背后的设计取舍。

## 优化器中的查询代价最小路径

在 PostgreSQL 的优化器里，所谓“路径”(path) 并不是执行器真正跑的步骤，而是一种给优化器自己看的、极简化的“路线草图”
。它记录 “如果我要把目前已选的这些表拼成一个中间结果，我打算怎么扫每个表、怎么把它们接起来、预估还能剩多少行、要付出多少代价”。换句话说，它是一棵尚未长成的计划树的轮廓：扫描方式、连接顺序、连接算法、过滤点，都在这张草图里标了记号，但还没生成执行器能直接执行的完整 Plan。官方文档把这种对象称为 *Path*，在选出最便宜的一条之后才会“发育”成真正的 Plan 节点树交给执行器。

优化器先为每个基表各找几条候选路径——例如顺序扫、索引扫、位图索引扫等。接着用动态规划计算每种组合的 `total_cost` 值，并将最小值交给执行器执行的最终的计划树路径。

以下是使用动态规划确定最佳计划树的过程，其步骤如下：

- *第一层* 把 A、B、C 各自的最好/次好路径备好；
- *第二层* 让任意两张表两两配对，枚举 A x B、A x C、B x C 各种扫描-连接组合，得到这些二表集合的候选路径；
- *第三层* 再把二表集合跟剩下一张表去配对，得到覆盖 ABC 的路径。
- 对每个“子集合”只保留当前代价最小的那条（以及少数可能因排序键或并行度不同而保留下来的“可比”路径），这样避免了组合爆炸。这就是 System R 风格的 DP 搜索。

### “代价”到底怎么算

代价是一个抽象单位；只要相对大小可信，绝对值怎样都行。PostgreSQL 默认把顺序读一页磁盘的成本定为 1.0，然后其它动作都折算到同一把尺子上。成本模型由两大块累加而成：

| 成本分量 | 由什么决定                           | 粗略计算方式                                  |
| -------- | ------------------------------------ | --------------------------------------------- |
| I/O 成本 | 需要读写多少块页                     | 页数 × (顺序或随机的 page cost)               |
| CPU 成本 | 要处理多少行、做多少次比较/哈希/投影 | 行数 × (cpu_tuple_cost + cpu_operator_cost …) |

这些“定价参数”在 `postgresql.conf` 里能看到：`seq_page_cost`, `random_page_cost`, `cpu_tuple_cost`, `cpu_operator_cost`, `cpu_index_tuple_cost` 等 。

### **行数 (cardinality) 和选择性 (selectivity)**

要知道要处理多少行，先得估计过滤条件能筛掉多少数据。优化器用 `ANALYZE` 留下的列统计信息：柱状图、MCV 表、NDV 等来算选择性。三表联结时，它会把 `A 的行数 × 连接选择性`得到联结后留下的行数，再把这个结果作为下一步联结的“外表”行数，如此层层向上累加。

**不同连接算法的公式**

- 嵌套循环 (NLJ)：
   `cost = outer_cost + outer_rows × inner_cost_per_row + cpu_per_tuple`
   如果内侧能用索引，那 `inner_cost_per_row` 可能很低；否则就是顺扫整表。
- 哈希连接 (HJ)：
   `build_cost = build_rows × (tuple_cpu + hash_cpu) + build_IO`
   `probe_cost = outer_rows × (tuple_cpu + hash_cpu)`
   两者加总再考虑是否溢出到磁盘。
- 归并连接 (MJ)：
   需要两侧都按连接键有序；如果已排序则几乎是线性，若要先排序还要加上排序成本。

优化器把这些公式里的变量都替换成刚才估出来的行数、参数值，就能算出每条路径的 `startup_cost` 与 `total_cost`。再加上并行度、内存预算等限制，最后选 `total_cost` 最小者为“最优路径” 。

## 事务Id与回环

PostgreSQL 的每条元组都要在元数据里记录两个字段：`xmin`（插入它的事务 ID）和 `xmax`（删除它的事务 ID）。官方采用 32 位无符号整数来设计的。如果把事务 ID 做成 64 位整数，元组会立刻多出 8 字节—— 对于“行很小、行数巨大”的 OLTP 场景，存储与缓存代价极高。

于是 PostgreSQL 选择**用 32 位无符号整数**来保存 txid，只占 4 字节；但 32 位最多 42 亿个编号，长期运行就一定“用完”。解决办法便是把编号空间当作一个**环形刻度盘**：最多 42 亿格，指针走完一圈又回到 0。从此再也不会“编号枯竭”，而数据库仍旧只付出 4 字节的空间成本。

### 事务Id回环

环形编号带来一个新难题：**当指针绕了一圈重新指向一个旧号码时，怎样判断它到底是 10 年前的“老 42”还是刚刚分配的“新 42”？**

PostgreSQL 的做法是把 42 亿个刻度一刀对半：

| 区段                  | 距离本事务的“钟点” | 语义     | 可见性                      |
| --------------------- | ------------------ | -------- | --------------------------- |
| 前面半圈（约 2¹⁰⁺⁰⁰） | 0 ~ –2¹⁰⁺⁰⁰ – 1    | **过去** | 一律可见（取决于提交/回滚） |
| 后面半圈（约 2¹⁰⁺⁰⁰） | +1 ~ +2¹⁰⁺⁰⁰       | **未来** | 一律不可见                  |

> 注意，这里为了区分用了“带符号坐标”的方式来描述分割，实际上数值范围是  $0-2^{32}$

任何事务在读取元组时，只需把 `(tuple_xid - my_xid)` 放进 32 位无符号算术里：

- 若差值 < $2^{31}$：`tuple_xid` 在“未来”
- 弱差值 > $2^{31}$：`tuple_xid` 在“过去”

这样就用一个恒定 O(1) 的加法判断，避免了昂贵的 64 位比较或额外的“时代位”。逻辑顺序依旧保持严格单调：

- “过去”里的编号永远比我小（对我可见或可回收）
- “未来”里的编号永远比我大（对我不可见、也不可修改）

该举措有效避免了编号耗尽的问题。txid 是环形空间，可以绕圈使用，不存在“最大 ID 已用完”的断崖式故障，系统可以持续运行多年而不必重置。

其次，它保持了每个元组头部的存储紧凑，仅用 4 字节就能记录插入和删除事务的信息。相比使用 64 位 ID 节省了一半空间，尤其在存储上千万行时这一点极为关键。

再者，这种“环+半圈”策略让事务之间的可见性判断变得非常高效。通过一次无符号减法操作即可判断一个 txid 属于过去还是未来，大大简化了 MVCC 判断逻辑，并减少了 CPU 分支跳转，提升了查询性能。

最后，为了保证这个模型始终正确，PostgreSQL 还配套设计了**“冻结机制”**和**“反环绕保护”**。当某些 txid 太老，可能即将被新的事务号“追上”时，系统会通过强制 VACUUM 把这些老 txid 替换成特殊的“FrozenXID”，这样即使编号绕圈重叠，也不会误判老事务为新事务。这种保护机制让 PostgreSQL 能在不牺牲一致性的前提下安全运行数十年。

## MVCC 机制下的可见性规则

下面用一组demo，把典型的 MVCC 可见性判定情景逐一跑一遍。为了让重点一眼就能落在 “为什么看得见 / 为什么看不见”，每段都会标注元组头的 `xmin`、`xmax` 以及当前事务的快照内容。

> **示例环境**
>
> - PostgreSQL 16
>
> - 两个独立 psql 会话，分别记为 **S₁** 和 **S₂**
>
> - 表结构：
>
>   ```sql
>   CREATE TABLE demo_mvcc(id int primary key, note text);
>   INSERT INTO demo_mvcc VALUES (1, 'origin');
>   ```

### 场景 A：只有 `xmin`，行版本从未被改动

```postgresql
-- S₁（事务 T1）
BEGIN;
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬──────┬────────┐
│ xmin │ xmax │ note   │
├──────┼──────┼────────┤
│  575 │    0 │ origin │   ← xmax = 0 表示“尚未删除”
└──────┴──────┴────────┘
```

T1 的快照里没有活跃事务，且 `xmax = InvalidXID`。按 MVCC 规则：行可见——这是最朴素的一种情况。

### 场景 B：`xmax` 指向一个正在运行的事务

```postgresql
-- S₂（事务 T2）
BEGIN;
UPDATE demo_mvcc SET note = 'edited by T2' WHERE id = 1;  -- 产生新版本
-- 新行的 xmin = T2，旧行的 xmax = T2 (xmax = 576 假设)

-- S₁ 仍在原事务中再次读
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬─────────────┐
│ xmax │ note        │
├──────┼─────────────┤
│  576 │ origin      │   ← xmax=576 但 T2 未提交
└──────┴─────────────┘
```

T1 的快照把 T2 视为活跃；`xmax` 虽然非零，却对应“未完成事务”。**删除尚未生效**，旧版本仍然对 T1 可见。

### 场景 C：`xmax` 已提交，但在快照里仍是活跃

```postgresql
-- S₂ 提交
COMMIT;               -- T2 now COMMITTED

-- S₁ 仍保持原快照再次读
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬─────────────┐
│ xmax │ note        │
├──────┼─────────────┤
│  576 │ origin      │   ← t_xmax state = COMMITTED
└──────┴─────────────┘
```

**关键点**：T1 启动得更早，快照里依旧把 576 视作“活跃”。因此，即便系统全局显示 576 已提交，T1 还是把该删除操作当作“未来事件”，继续看见旧版本。

### 场景 D：`xmax` 已提交，且在快照里非活跃

```postgresql
-- 结束 T1
COMMIT;

-- 新会话 S₃（事务 T3）
BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED;
SELECT xmax, note FROM demo_mvcc WHERE id = 1;

(0 rows)
```

T3 的快照生成时，576 已被列入已提交集合而非活跃集合；删除操作正式生效，**旧版本对 T3 不可见**。

### 场景 E：`xmin` 对应事务已回滚

```postgresql
-- S₂ 新开事务 T4
BEGIN;
INSERT INTO demo_mvcc VALUES (2, 'temp');
-- T4 decides to abort
ROLLBACK;

-- S₁ 新事务 T5
BEGIN;
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 2;

(0 rows)
```

行版本的 `xmin = T4`，而 T4 最终 ABORTED；快照规则直接排除“未成功的插入”，所以任何事务都看不到这行——直到被 autovacuum 清理。

### 场景 F：冻结（`xmin = FrozenXID`）

```postgresql
VACUUM FREEZE demo_mvcc;        -- 12+ 亿行才常见，此处强行演示
SELECT xmin, xmax, note FROM demo_mvcc WHERE id = 1;

┌──────┬──────┬───────────┐
│ xmin │ xmax │ note      │
├──────┼──────┼───────────┤
│    2 │  576 │ origin    │
└──────┴──────┴───────────┘
```

`xmin` 被改写为特殊值 2（`FrozenXID`），意为“久远过去的行”。任何未来快照都会把它当成历史数据直接可见，而不再与具体事务状态关联。

### 场景 G：可滚动游标下的“旧快照”

```postgresql
-- S₁
BEGIN;
DECLARE c CURSOR FOR SELECT note FROM demo_mvcc ORDER BY id;
FETCH NEXT FROM c;     -- 取得 'origin'
-- S₂ 再次插入新行 id=3
BEGIN; INSERT INTO demo_mvcc VALUES (3,'later'); COMMIT;

-- S₁ 继续 fetch
FETCH NEXT FROM c;     -- 仍只能拿到快照时存在的行
```

游标 `c` 固定使用声明时的快照；即便游标生命周期内有新行插入，也不会被它看到。

在 PostgreSQL 的 MVCC 可见性判定中，最典型的情况是行从未被修改，此时只有 `xmin` 字段，这意味着这行是直接可见的。

当行的 `xmax` 字段指向一个仍处于活跃状态的事务（或者即使该事务已经提交，但在当前快照里仍然被视为“活跃”），这说明该行的删除操作还没有对本事务生效，因此这行依然可以被读到。只有当 `xmax` 对应的事务已经提交，并且在本次快照中被判定为非活跃，删除操作才会正式生效，此时这条记录对于本事务就不可见了。

如果一行的 `xmin` 事务回滚，那么这行自始至终都不会出现在任何事务的视野中。

至于那些经过 VACUUM FREEZE 处理、`xmin` 被标记为特殊冻结值的历史行，对于所有快照来说都直接可见，不再受事务环绕与快照隔离影响。

此外，如果在声明游标时已经生成了快照，那么游标在后续操作过程中只会看到声明时快照内的内容，即使有新数据写入也不会被游标“看到”。

## 缓冲管理器

### 环形缓冲区

在读写大表时，PostgreSQL会使用环形缓冲区而不是缓冲池。环形缓冲器是一个很小的临时缓冲区域。PostgreSQL将在共享内存中分配一个环形缓冲区。 环形缓冲区的好处显而易见，如果后端进程在不使用环形缓冲区的情况下读取大表，则所有存储在缓冲池中的页面都会被移除，这会导致缓存命中率降低。环形缓冲区可以避免此问题。

在 PostgreSQL 里，所谓“环形缓冲区”（ring buffer）并不是另一套独立的缓存，而是把 **shared buffers** 中的一小撮块临时划出来，按“首尾相连”的圆环方式循环重用。它只在极端顺序、大批量的 I/O 场景里才会被后台进程拿来用，目的是保护主缓冲池里原本的热点页不被一口气冲掉。

当后端进程开始顺序扫描一个足够大的关系（默认判定标准是：表大小超过 `shared_buffers / 4`），或执行 `COPY FROM`、`CREATE TABLE AS`、`REFRESH MATERIALIZED VIEW`、`VACUUM` 等一次性吞吐量很高的操作时，缓冲管理器会为这个进程分配一种叫 `BAS_BULKREAD / BAS_BULKWRITE / BAS_VACUUM` 的 Buffer 访问策略。该策略背后对应的就是环形缓冲区：

- 对纯读（Bulk Read）和 VACUUM 而言，环形区固定只有 32 个页，也就是 32 × 8 KB ≈ 256 KB；
- 对大量写入（Bulk Write）场景，环形区扩大到 16 MB；
- 这块小环在扫描结束后立即释放给整个缓冲池重新调度。

为什么要这样做？如果让一个顺序扫描照常通过全局时钟淘汰算法去申请新页，它会源源不断把整张大表搬进 shared buffers，原先缓存的小热表、索引页很快就被挤走；扫描一结束，这些页往往再也用不上，于是命中率骤降。把“搬运大表”限定在 256 KB～16 MB 这么小的环里，相当于告诉缓存管理器：“这些块只要保持短期可用即可，转完一圈就可以覆盖”，从而把主缓冲池的大部分空间留给真正需要长时间保留的工作集。

实现上，环形缓冲区完全沿用 shared buffers 的数据结构，只是在取替换页时不再走全局时钟，而是把指针限制在自己的小环里循环前进；写脏页、并发锁和 WAL 刷新等规则都与普通缓冲页一致。这种设计让顺序扫的大吞吐与事务型 OLTP 的热点缓存可以在同一实例里和平共处，不会互相“踩页面”。

> 为什么批量读取和清理过程的默认环形缓冲区大小为256 KB？
>
> 源代码中缓冲区管理器目录下的README中解释了这个问题。顺序扫描使用256KB的环形缓冲区，它足够小，因而能放入L2缓存中，从而使得操作系统缓存到共享缓冲区的页面传输变得高效。通常更小一点也可以，但环形缓冲区需要足够大到能同时容纳扫描中被钉住的所有页面。
