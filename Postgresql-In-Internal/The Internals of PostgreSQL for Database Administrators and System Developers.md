PostgreSQL 的进程架构采用了一种多进程模型，而不是许多现代数据库常见的多线程模型。当你启动 PostgreSQL 服务时，后台会首先启动一个主进程，叫做 postmaster 或者说是“PostgreSQL server process”。这个主进程主要负责监听来自客户端的连接请求，并在有新连接时，为每个连接派生出一个新的子进程，也就是所谓的“客户端进程”或“后端进程”。每一个和数据库交互的会话，其实就是操作系统层面的独立进程，它们之间彼此隔离，各自处理对应客户端的 SQL 请求。

除了这些为客户端服务的进程，PostgreSQL 还会自动运行一系列“辅助进程”，这些进程负责数据库的日常维护，比如写 WAL（预写日志）、清理无用数据、定期刷写缓存到磁盘，以及检查点和统计信息收集等等。这些辅助进程和每个用户的会话进程一样，也是在操作系统中独立存在的进程。

整个架构的设计让 PostgreSQL 在并发处理和崩溃恢复上有很好的健壮性。如果某个连接的进程崩溃了，其他的连接进程和主进程依然可以继续工作，不会相互影响。同时，这种架构也让数据库在高负载下更容易利用多核 CPU 的性能优势。整体来说，PostgreSQL 用一组彼此独立、分工明确的进程协同工作，来保证数据库服务的高效和稳定。

## 索引相关性

`correlation` 反映了这个字段和插入顺序的“线性关系”，高相关性有利于某些类型的顺序扫描和优化。低相关性则意味着随机访问更多，查询时可能更依赖索引。可以通过下面语句查询：

```postgresql
SELECT tablename,attname,correlation FROM pg_stats WHERE tablename = 'sentencepatterns'
```

输出如下：

```
sentencepatterns	Description	1
sentencepatterns	Remark	1
sentencepatterns	CnTranslation	0.01702202
sentencepatterns	Id	0.86093146
sentencepatterns	Text	-0.1022805
sentencepatterns	PatternType	0.79632217
sentencepatterns	Status	1
sentencepatterns	CreateUser	0.9976231
sentencepatterns	CreateTime	0.8611384
sentencepatterns	SortOrder	-0.27549043
```

这里是指该列的“物理存储顺序”和表中行的“物理顺序”之间的线性相关系数。它的取值范围是 -1 到 1。

- 1 表示该列的值**完全按照表的物理顺序递增排列**。
- -1 表示该列的值**完全按照表的物理顺序递减排列**。
- 0 表示没有相关性，列的值分布与物理存储顺序基本无关。

这种相关性信息，PostgreSQL 会用来优化某些查询，比如在决定是否使用索引扫描时。

## PostgreSQL 的查询处理

PostgreSQL执行一条SQL查询语句的过程是一个复杂而精密的系统工程，涉及多个模块的协同工作。当客户端发送一条查询语句到PostgreSQL服务器时，这条语句会经历一个完整的生命周期，从最初的字符串形式转换为最终的执行结果。

### 语法语义分析

整个过程始于查询语句的接收。PostgreSQL的后端进程接收到来自客户端的SQL字符串后，首先会进行词法分析和语法分析。词法分析器（lexer）将SQL字符串分解为一系列的token，这些token包括关键字、标识符、操作符、常量等基本元素。随后，语法分析器（parser）根据PostgreSQL的SQL语法规则，将这些token组织成一个抽象语法树（AST）。这个语法树准确地表示了SQL语句的结构和语义。

在语法分析完成后，查询进入**分析阶段**。分析器会对语法树进行语义分析，这个过程包括名称解析、类型检查和权限验证。名称解析会将表名、列名等标识符与系统目录中的实际对象进行匹配，确保引用的对象确实存在。类型检查会验证操作的数据类型是否兼容，比如确保比较操作的两边具有可比较的类型。权限验证则会检查当前用户是否有权限访问查询中涉及的表和列。分析器还会处理视图的展开，将对视图的查询转换为对基础表的查询。

### 重写器

接下来是**查询重写阶段**。重写器会应用各种查询重写规则来优化查询。这些规则包括常量折叠、谓词下推、子查询提升等。常量折叠会在编译时计算出可以确定的表达式值，比如将"2+3"直接替换为"5"。谓词下推会将WHERE子句中的条件尽可能地推向数据源，减少需要处理的数据量。子查询提升会将某些子查询转换为连接操作，这通常能够带来更好的性能。

重写完成后，查询进入计划阶段，这是整个查询处理过程中最为复杂和关键的部分。计划器需要为查询生成一个执行计划，这个计划指定了如何从存储中获取数据以及如何处理这些数据来产生最终结果。

### 计划器

计划器首先会进行统计信息的收集和分析。PostgreSQL维护着详细的统计信息，包括表的行数、列值的分布、索引的选择性等。这些统计信息对于代价估计至关重要。计划器会查询系统目录中的 `pg_statistic` 表来获取这些信息。

对于每个表的访问，计划器需要决定使用哪种扫描方式。

- 顺序扫描是最基本的访问方式，它会从头到尾读取表中的每一行。这种方式在需要访问表中大部分数据时是最高效的。
- 索引扫描则通过索引来快速定位到满足条件的行，这在需要访问少量数据时非常高效。

计划器会根据**选择性**估计来决定使用哪种扫描方式。

选择性是指满足查询条件的行占总行数的比例。如果选择性很低（即满足条件的行很少），索引扫描通常是更好的选择。如果选择性很高，顺序扫描可能更高效，因为它避免了随机访问的开销。

### 代价估计

代价估计是计划器决策的核心。PostgreSQL使用一个基于代价的优化器，它会为每种可能的执行方案估计代价，然后选择代价最低的方案。代价模型考虑了多个因素，包括CPU代价、I/O代价、内存使用等。对于顺序扫描，代价主要是读取所有页面的I/O代价加上处理每行的CPU代价。对于索引扫描，代价包括读取索引页面的代价、根据索引访问表页面的代价，以及处理匹配行的CPU代价。

### 连接操作

当查询涉及多个表的连接时，计划器需要决定连接的顺序和方法。连接顺序的选择对性能有巨大影响，因为不同的连接顺序会产生不同大小的中间结果。计划器会使用动态规划算法来寻找最优的连接顺序，这个算法会考虑所有可能的连接顺序组合，并选择总代价最低的那个。

对于连接方法的选择，PostgreSQL支持三种主要的连接算法：

- **嵌套循环连接**是最基本的连接方法，它对外表的每一行，都会扫描内表来寻找匹配的行。这种方法在内表很小或者有高效索引的情况下表现良好。
- **归并连接**要求两个输入都已经按照连接键排序，然后同时扫描两个输入来寻找匹配的行。这种方法在处理大量数据时很高效，特别是当数据已经排序或者可以通过索引有序获取时。
- **散列连接**会将较小的表构建成散列表，然后扫描较大的表，对每一行在散列表中查找匹配。这种方法在内存充足且内表不太大时非常高效。

计划器会为每种连接方法估计代价，并选择最优的方法。代价估计会考虑输入的大小、是否需要排序、内存的使用情况等因素。

### 计划树的生成与执行

计划树的生成是一个自底向上的过程。计划器首先为每个基本表生成访问路径，然后逐步构建更复杂的操作。对于连接操作，计划器会考虑不同的连接顺序和连接方法，生成所有可能的路径。对于每个路径，计划器都会计算其代价，并保留代价最低的路径。

在处理复杂查询时，计划器还需要考虑其他操作，如排序、分组、聚合等。排序操作可能使用内存中的快速排序，也可能使用外部排序当数据量超过内存容量时。分组和聚合操作可能使用散列分组或排序分组，选择取决于数据的特性和可用内存。

计划完成后，查询进入执行阶段。执行器会根据计划树来执行查询。执行器采用火山模型（Volcano model），每个计划节点都是一个迭代器，支持初始化、获取下一行和清理三个基本操作。执行从计划树的根节点开始，根节点会向其子节点请求数据，子节点再向其子节点请求数据，这样递归地进行下去，直到叶节点（通常是表扫描操作）。

在执行过程中，PostgreSQL会进行各种优化。比如，它会尽可能地使用流水线处理，让不同的操作并行进行。它还会进行内存管理，确保查询不会使用过多的内存。对于大型查询，PostgreSQL可能会使用临时文件来存储中间结果。

### 其它操作

缓冲区管理也是执行过程中的重要部分。PostgreSQL维护着一个共享缓冲区池，用于缓存经常访问的数据页面。当需要访问一个页面时，执行器首先会检查这个页面是否已经在缓冲区中。如果在，就直接使用缓存的数据。如果不在，就需要从磁盘读取这个页面到缓冲区中。

锁管理确保了并发访问的正确性。PostgreSQL使用多版本并发控制（MVCC）来处理并发读写。每个事务都能看到数据的一个一致快照，而不需要阻塞其他事务。这通过为每行数据维护多个版本来实现。

整个查询执行过程还涉及错误处理和事务管理。如果在执行过程中出现错误，PostgreSQL会回滚已经进行的操作，确保数据的一致性。事务管理确保了ACID属性的满足，即原子性、一致性、隔离性和持久性。

当查询执行完成后，结果会被返回给客户端。对于大型结果集，PostgreSQL可能会使用游标来分批返回结果，避免一次性占用过多内存。

## 混合散列连接

在 PostgreSQL 的执行器里，散列连接本质上是一场“先造房子，再敲门”的流程：把连接键相同的内表行造进一张哈希表，然后让外表每条记录来敲门匹配。只要所有哈希桶能放得进 `work_mem`，这条路就顺滑；可一旦数据溢出内存，数据库只能把哈希表切成若干分区，写进临时文件，等下一轮再读回。这个策略叫混合散列连接（Hybrid Hash Join）。

现实数据往往并不均匀。取电商日志举例，可能只有十分之一的客户贡献了七成的订单。若直接把订单表当作外表探测，某些客户名对应的哈希桶会炸到离谱，内存反复 malloc/free，磁盘分区也突然膨胀，性能惨不忍睹。PostgreSQL 因此在 Hybrid Hash Join 上加了一道“倾斜批次」(skew batch)” 的工序：把外表里最常出现的连接键单独拉到内存里，专门配一张哈希表，先把这些热点一次性喂完，剩下的长尾再慢慢分批——官方称作**高频值（MCV，Most Common Values）**。

很多人第一反应是“MCV 难道要每次查询再统计？那得多慢”。答案是完全不用。数据库维护列统计的时机是 `ANALYZE` 或自动采样，结果塞进元表 `pg_statistic`。规划器读取这里的 MCV 列表，评估它们占多少行、总共多少字节，再衡量 `work_mem`。同意之后，执行器启动时一次性把与这些值对应的内表行插进一张专属哈希表，这便是倾斜批次。整个过程只和内表数据打交道，不扫描外表，所以开销微乎其微。

究竟哪一侧当内表？在纯粹的等值连接里，哈希连接是对称的，规划器会选择更小、更便宜、能够放下的那一边当 build-side。我们先前的例子里，`customers` 只有一万行，而 `purchase_history` 有一百万行，因此客户表几乎必定成为内表。至于写 SQL 时表名的先后顺序，对 INNER JOIN 并不起决定作用；真正影响决策的是**统计估算**、`work_mem` 的大小，以及可能的 join-order 约束或提示(hint)。

混合散列连接开始**构建阶段**时，会把内表分成 N 个批次。假设估算得出需要四个批次，其中 Batch 0 留在内存，Batch 1、2、3 写临时文件；于是磁盘上就只出现三份文件。批次号的分配由哈希值对 N 取模完成，规划器会尽量让每批次大小接近，同时满足 Batch 0 不超出 `work_mem`。倾斜批次并不算在这四里头，它是一块独立的内存区。

探测第一轮到来时，外表行被拆成三种命运。命中 MCV 的，直接击中倾斜批次；哈希值落在 0 号分区的，立即在内存哈希表里比对；其余分区的，写进各自的外表临时文件，等后续轮次再说。因为前两类常常覆盖大多数热数据，磁盘 I/O 压力被显著削弱。

**首轮结束后，那张“倾斜批次 + Batch 0”的哈希表已经没有任何外表行还会引用，执行器会把相关内存统统释放**。接下来它逐个把 Batch 1_in 读取进内存重建哈希桶，再用 Batch 1_out 去探测；然后是 Batch 2、Batch 3，如此反复。每轮都在同一块 `work_mem` 里完成 build-probe-free 的闭环，避免内存碎片与反复分配。

倾斜批次只是 PostgreSQL 针对数据分布极端不均的一剂局部解法。它依赖可靠的统计、足够的内存，以及合适的 join 方向。如果你理解了为什么要单独照顾那 10 % 的客户、为什么要先把 70 % 的外表行在内存里一次性结算，以及为什么四个批次只需要三份磁盘文件，那么你已经真正看懂了这项优化背后的设计取舍。

