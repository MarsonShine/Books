# 高并发网络架构

在这一章节，我们将深入探讨在一个网络服务器内处理众多连接时并发性问题的细节。根据我们架构模型的描述，请求处理过程与应用逻辑是分开的。因此，本章不涉及动态内容的生成，这个主题将在第5章进一步探讨。从网络服务器的视角来看，不同请求之间无需相互协调。但如果应用层面的请求之间有依赖关系——比如，一个长时间轮询的请求在等待某个应用事件，而另一个请求恰好触发了这个事件——这种情况需要在我们的应用服务器模型中得到处理。

本章将概述高性能网络服务器面对海量并发连接时遇到的并发挑战。然后，我们将了解不同的服务器架构是如何利用各种编程模型来管理并行处理、并发性以及 I/O 操作的。最终，我们将对比两种主流的并发模型——基于线程的模型和基于事件驱动的模型，以便更全面地理解它们的差异和应用场景。

## 概述

本章我们要解决的主要问题是在编程模型中将连接/请求正确映射到并发执行流。由于我们的目标是处理多个并行的 HTTP 请求，这主要涉及高度 I/O 绑定的操作。在 Web 基础设施方面，我们希望确保我们的软件实现不会轻易成为瓶颈，并在每个部署的服务器上在负载下实现高硬件资源利用率。在请求/响应和连接处理方面，有几个有趣的指标可以描述服务器的性能：

- 请求吞吐量（#/秒）
- 原始数据吞吐量（Mbps）
- 响应时间（毫秒）
- 并发连接数（#）

此外，还有以下性能统计数据需要在服务器的机器上观察：

- CPU利用率
- 内存使用情况
- 打开的套接字/文件句柄数
- 线程/进程数

重新表述我们的问题，我们希望尽可能并行处理尽可能多的请求，尽快完成，并且使用尽可能少的资源。换句话说，资源利用应该随着工作量的增加而扩展。

### 请求处理工作流程

根据我们在前一章中概述的 Web 服务器要求，我们可以将以下步骤列为处理请求的最小工作流程。附加功能，如请求日志记录或缓存，有意被省略。

1. *接受传入请求* - 在新的 HTTP 连接的情况下，首先必须建立底层的 TCP 连接。
2. *读取请求* - 需要对所有请求进行原始字节的读取（I/O 绑定），然后解析实际的 HTTP 请求（CPU 绑定）。如果请求包含实体，例如 POST 参数或文件上传，则还必须读取此附加内容。根据实现方式，Web 服务器要么缓冲实体直到完全加载，要么直接将其传输到应用服务器。前者允许内容卸载，对于慢速连接很重要，后者由于减少了延迟而很有意思。
3. *将请求分派到应用层* - 根据我们的架构模型，解析后的请求随后被发送到应用服务器。我们使用解耦的组件，因此这通常是一个基于网络的任务，使用消息传递（或其他替代方法，如 RPC）。如果是处理静态内容的 Web 服务器，则访问本地或远程文件系统。所有操作都是 I/O 绑定的。
4. *一旦可用，将生成的响应写入套接字* - 一旦生成响应（例如来自应用服务器的生成的 HTML 文件或来自文件系统的静态图像），就可以通过写入套接字将其返回给客户端。同样，Web 服务器可以缓冲响应，从而为应用服务器提供卸载。或者它直接将生成的响应传输给客户端。
5. *完成请求* - 根据通过请求/响应头和 HTTP 默认值协商的连接状态，Web 服务器要么关闭连接，要么从头开始等待客户端发送下一个请求。

### C10K问题

Kegel 在 1999 年发表了一篇具有里程碑意义的文章[[Keg06](https://berb.github.io/diploma-thesis/community/0_bibliography.html#Kegel2006)]，让“Web 服务器同时处理一万个客户端”成为可能，从而提出了*C10K问题*的概念。原始文章已经多次更新，并成为 Web 服务器可扩展性方面的重要资源。

他通过展示硬件在一定程度上可能不再是高并发连接的瓶颈来激发了他的思考。基于当时合理的硬件条件（即 500 MHz，1 GB内存，6 x 100Mbit/s），Kegel 认为同时处理 1 万个客户端完全可行，每个请求可达到 50KHz、100K字节和 60K位/秒 - 对于 4KB 的有效负载数据来说已经足够了。实际上，当时大多数服务器远未达到这个数字。然后，他研究了 Web 服务器的内部机制，特别评估了常见的 I/O 策略和线程模型。

C10K这个术语在十年后得到了进一步的强化，当时 *Urban Airship* 公司在单个节点上无法处理 50 万并发连接时遇到了困难。他们解决*C500k问题*的兴趣是基于他们的商业模式。为大量移动设备提供通知服务要求他们同时处理极高数量的空闲连接。

### I/O 操作模型

对于常规桌面应用程序，处理基于文件或网络的输入和输出通常是一项零星任务。对于我们的 Web 服务器来说，处理 I/O 操作是主要任务。操作系统提供了不同的 I/O 操作方式，我们将详细了解一下 I/O 操作模型。

在文献中，阻塞（blocking）和同步（synchronous）以及非阻塞（non-blocking）和异步（asynchronous）这两个术语通常可以互换使用，两者描述的概念非常相似。而且，这些术语在不同操作系统的不同层次上使用的含义也不同。为了至少在描述 I/O 操作时进行区分，我们将它们分开。

- **阻塞 vs. 非阻塞**

  使用这些属性，应用程序可以告诉操作系统如何访问设备。当使用阻塞模式时，I/O 操作不会在操作完成之前返回给调用者。在非阻塞模式下，所有调用都会立即返回，但只指示操作的调用状态或错误。因此，可能需要多次调用才能等待操作成功结束。

- **同步 vs. 异步**

  这些属性用于描述 I/O 操作期间的控制流程。同步调用保持控制，即在操作完成之前不返回。异步调用立即返回，允许执行其他操作。

综合这些模式，I/O 可产生四种不同的运行模式。有时，为了方便起见，会使用额外的软件层提供与实际底层模式不同的模式。

- **同步阻塞I/O**

  这是许多常规应用程序中最常见的操作模式。在这种情况下，I/O 操作是一个单独的操作，导致应用程序处于阻塞状态，直到操作完成并将数据从内核空间复制到用户空间（例如读取操作）。在内核级别上，实际的原始操作通常与其他操作多路复用。但对于应用程序本身来说，它代表了一个长时间运行的操作。这种模型不仅对开发人员来说不是直接的模型，而且还会导致应用程序进程在发出 I/O 操作时不需要 CPU 时间。这是操作系统调度程序在切换到其他进程时的方便时间。

- **同步非阻塞I/O**

  在这种模式下，应用程序以非阻塞模式访问 I/O 设备。结果，内核空间立即返回 I/O 调用。通常情况下，设备尚未准备好，调用响应指示应稍后重复调用。通过这样做，应用程序代码通常实现了忙等待行为，这可能非常低效。一旦 I/O 操作完成并且数据在用户空间可用（在读取操作的情况下），应用程序可以继续运行和使用数据。

- **异步阻塞I/O**

  令人惊讶的是，异步阻塞模型仍然使用非阻塞模式进行 I/O 操作。但是，与忙等待不同，此时使用专用的阻塞系统调用来通知 I/O 状态。有几个系统调用提供这样的功能，包括 `select`、`poll`、`epoll` 和 kqueue [[Ste03](https://berb.github.io/diploma-thesis/community/0_bibliography.html#Stevens2003)]。通过这样做，可以将多个 I/O 描述符传递给系统调用。当用于通知的阻塞系统调用的实现稳定且高效时，这是一种适用于高并发 I/O 的良好模型。

- **异步非阻塞I/O**

  这种 I/O 模型立即从 I/O 调用返回。完成后，会发出事件或执行回调。这种模型的有趣特点在于用户级别上没有阻塞或忙等待。整个操作转移到内核空间。这使得应用程序可以利用额外的 CPU 时间，同时在内核级别后台进行 I/O 操作。换句话说，应用程序可以将 I/O 操作与其他需要 CPU 的操作重叠，或者在此期间调度其他 I/O 操作。不出所料，这种模型在高并发 I/O 下也提供良好的性能。

|              | blocking     | non-blocking                    |
| ------------ | ------------ | ------------------------------- |
| 同步         | `read/write` | `read/write` using `O_NONBLOCK` |
| asynchronous | I/O 多路复用 | AIO                             |

表 4.1：Linux 中的 I/O 模型

这些模型只描述了 Linux 操作系统上的低级 I/O 操作。从更抽象的程序员角度来看，可以使用其他模型替代，但通常会带来一些性能损失。应用程序框架可以通过后台线程使用同步阻塞的方式提供 I/O 访问，但为开发人员提供基于回调的异步接口，反之亦然。

从现在开始，在大多数情况下，我们将同步阻塞的方法与其他三种方法区分开来。基于某种信号、通知或回调执行的方法，我们将其称为事件驱动或基于事件的方法。

## 服务器架构

我们已经看到了不同的套接字 I/O 模型，以及在静态内容的 Web 服务器中的文件 I/O 模型。现在，我们需要将 I/O 操作和 CPU 密集型活动（如请求解析和请求处理）合并到通用服务器架构中。

传统上有两种竞争的服务器架构，一种基于线程，另一种基于事件。随着时间的推移，出现了更复杂的变体，有时结合了两种方法。关于线程和事件哪种更适合[高性能 Web 服务器的争论]()[^1][^2][^3]已经持续了很长时间。经过十多年的发展，由于新的可扩展性挑战和向多核 CPU 的趋势，这个争论现在得到了加强。

在评估不同方法之前，我们介绍一般的架构，介绍正在使用的相应模式，并给出一些实际的例子。

### 基于线程的服务器架构

基于线程的方法基本上将每个传入连接与一个单独的线程（或进程）关联起来。通过这种方式，同步阻塞 I/O 是处理 I/O 的自然方式。这是一种常见的方法，得到了许多编程语言的良好支持。它还导致了一种直观的编程模型，因为处理请求所需的所有任务可以按顺序编码。此外，它通过隔离请求并隐藏并发性提供了简单的心智抽象。通过同时使用多个线程/进程，可以实现真正的并发。

在概念上，多进程和多线程架构共享相同的原则：每个新连接都由一个专用的活动处理。

#### 多进程架构

基于 UNIX 的网络服务器的传统方法是每个连接使用一个专用进程来处理连接 [^4]。这种模型也被用于第一个 HTTP 服务器，[CERN httpd](http://www.w3.org/Daemon/Implementation/)。由于进程的性质，它们迅速地隔离不同的请求，因为它们不共享内存。由于进程是相对沉重的结构，创建进程是一种昂贵的操作，服务器通常采用一种称为预派生（preforking）的策略。使用预派生时，主服务器进程在启动时预先派生出多个处理程序进程，如图4.1所示。通常，（线程安全的）套接字描述符在所有进程之间共享，并且每个进程都会阻塞等待新的连接，处理连接，然后等待下一个连接。

![](./asserts/mp-server.svg)

图 4.1：利用预分叉的多进程架构。启动时，主服务器进程会分叉出几个子进程，这些子进程随后将处理请求。各进程之间创建并共享一个套接字。每个请求处理程序都会等待新的连接，然后阻塞新的连接。

一些多进程服务器还会测量负载，并在需要时生成额外的请求。然而，重量级进程的结构限制了同时连接的最大数量。由于连接-进程映射导致的大内存占用会导致并发/内存之间的权衡。特别是在长时间运行的、部分非活动的连接（例如长轮询通知请求）的情况下，多进程架构对于并发请求的可扩展性有限。

流行的。Apache Web 服务器提供了一个基于进程预派生的强大多进程模块，Apache-MPM prefork。它仍然是基于 UNIX 的 Apache 设置的默认多进程模块。

#### 多线程架构

当合理的线程库变得可用时，出现了新的服务器架构，用轻量级线程取代了重量级进程。实际上，它们采用了每个连接一个线程的模型。尽管遵循相同的原则，多线程方法有几个重要的区别。首先，多个线程共享同一地址空间，因此共享全局变量和状态。这使得可以为所有请求处理程序实现共享功能，例如 Web 服务器内部的共享缓存用于可缓存的响应。显然，这需要正确的同步和协调。线程的另一个区别是它们更轻量级的结构，占用的内存更小。与整个进程的完整内存大小相比，线程只消耗有限的内存（即线程堆栈）。此外，线程在创建/终止时需要更少的资源。我们已经看到，在高并发的情况下，进程的维度是一个严重的问题。当将连接映射到活动时，线程通常是一个更高效的替代品。

![](./asserts/mt-server.svg)

图 4.2：使用多线程架构。专用的接受线程会阻塞新的套接字连接，接受连接并将其分派到工作池，然后继续工作。工作池提供一组线程来处理接收到的请求。工作线程要么在处理请求，要么在等待处理新请求。

实践中，常见的架构是在一组用于连接处理的线程之前放置一个单独的调度线程（有时也称为接收线程），如图4.2所示。线程池是限制服务器内最大线程数的常用方式。调度程序在套接字上阻塞以等待新的连接。一旦建立连接，连接将传递给传入连接的队列。线程池中的线程从队列中获取连接，执行请求并在队列中等待新的连接。当队列也有限时，可以限制等待连接的最大数量。额外的连接将被拒绝。尽管这种策略限制了并发性，但它提供了更可预测的延迟，并防止了过载。

Apache-MPM worker 是 Apache Web 服务器的一个多进程模块，它结合了进程和线程。该模块生成多个进程，每个进程管理自己的线程池。

#### 多线程架构的可扩展性考虑

使用每个连接一个线程的多线程服务器易于实现，并遵循简单的策略。可以使用同步阻塞 I/O 操作来自然地表示 I/O 访问。操作系统通过抢占式调度来重叠多个线程。在大多数情况下，至少一个阻塞 I/O 操作会触发调度并导致上下文切换，允许下一个线程继续执行。这是一个适用于良好并发性能的可行模型，也适用于必须执行合理数量的 CPU 密集型操作的情况。此外，多个 CPU 核心可以直接使用，因为线程和进程被调度到所有可用的核心。

在高负载下，多线程 Web 服务器消耗大量内存（由于每个连接的单个线程堆栈），而频繁的上下文切换会导致 CPU 时间的大量损失。间接的惩罚是增加了 CPU 缓存未命中的机会。减少绝对线程数可以提高每个线程的性能，但会限制最大同时连接的整体可扩展性。

### 事件驱动的服务器架构

作为同步阻塞 I/O 的替代方案，事件驱动的方法在服务器架构中也很常见。由于异步/非阻塞调用语义，需要使用其他模型来替代之前概述的每个连接一个线程的模型。常见的模型是将单个线程映射到多个连接。然后，该线程处理这些连接和请求的所有发生的事件。如图4.3所示，新事件被排队，线程执行所谓的事件循环--从队列中出队事件，处理事件，然后获取下一个事件或等待推送新事件。因此，线程执行的工作非常类似于调度程序的工作，将多个连接多路复用到单个执行流中。

![](./asserts/ev-server.svg)

图 4.3：这个概念模型展示了事件驱动架构的内部结构。单线程事件循环从队列中消耗一个又一个事件，并按顺序执行相关的事件处理程序代码。新事件由外部来源发出，如套接字或文件 I/O 通知。事件处理程序会触发 I/O 操作，最终产生新的事件。

处理事件要么需要为特定事件注册的事件处理器代码，要么基于提前与事件关联的回调的执行。线程处理的连接的不同状态通过适当的数据结构组织起来——要么是使用有限状态机显式地，要么是通过回调的延续或闭包隐式地。因此，遵循事件驱动风格的应用程序的控制流程在某种程度上是倒置的。与顺序操作不同，事件驱动程序使用一系列异步调用和回调的级联，这些回调在事件发生时执行。这种概念常常使得控制流程不那么明显，并且使调试复杂化。

事件驱动服务器架构的使用历史上依赖于操作系统级别上异步/非阻塞 I/O 操作的可用性，以及像 epoll 和 kqueue 这样的适合高性能事件通知接口。早期的基于事件的服务器实现，如 [Pai 等人的 Flash web 服务器](https://www.usenix.org/legacy/event/usenix99/full_papers/pai/pai.pdf)。

#### 非阻塞I/O多路复用模式

针对基于事件的 I/O 多路复用，已经出现了不同的模式，推荐用于处理高并发、高性能 I/O 的解决方案。这些模式通常解决网络服务处理多个并发请求的问题。

##### 反应器模式

[反应器模式](SCHMIDT, Douglas C.: Reactor: an object behavioral pattern for concurrent event demultiplexing and event handler dispatching, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA (1995), 529-545)针对同步、非阻塞 I/O 处理，并依赖于事件通知接口。在启动时，遵循这种模式的应用程序注册一组资源（例如，一个套接字）和它感兴趣的事件（例如，一个新连接）。对于应用程序感兴趣的每个资源事件，必须提供一个适当的事件处理器——一个回调或钩子方法。反应器模式的核心组件是**同步事件解复用器**，它使用阻塞事件通知接口等待资源的事件。每当同步事件解复用器接收到一个事件（例如，一个新的客户端连接），它通知一个调度器并等待下一个事件。调度器通过选择关联的事件处理器并触发回调/钩子执行来处理事件。

因此，反应器模式将事件处理和多路复用的通用框架与应用程序特定的事件处理器解耦。原始模式专注于单线程执行。这要求事件处理器遵循非阻塞操作风格。否则，一个阻塞操作可以挂起整个应用程序。反应器模式的其他变体使用事件处理器的线程池。虽然这在多核平台上提高了性能，但必须考虑额外的协调和同步开销。

##### 前摄器模式

相比之下，[前摄器模式](https://www.dre.vanderbilt.edu/~schmidt/PDF/proactor.pdf)利用了真正的异步、非阻塞 I/O 操作，如 [POSIX AIO](http://www.kernel.org/doc/man-pages/online/pages/man7/aio.7.html) 所提供的接口。因此，前摄器可以被认为是之前看到的反应器模式的完全异步变体。**它包括对完成事件的支持**，而不是阻塞事件通知接口。一个主动发起者代表主应用程序线程，负责启动异步 I/O 操作。在发起这样的操作时，它总是注册一个**完成处理程序**和**完成调度程序**。异步操作的执行由异步操作处理器控制，实际上是操作系统的一部分。当 I/O 操作完成时，完成调度程序被通知。接下来，完成处理程序处理结果事件。

与反应器模式相比，一个重要的可扩展性特性是更好的多线程支持。完成处理程序的执行可以轻松地交给专用线程池。

#### 事件驱动架构的可扩展性考虑

单个线程运行事件循环并等待 I/O 通知对可扩展性的影响与之前概述的基于线程的方法不同。不将连接和线程相关联可以显著减少服务器的线程数——在极端情况下，减少到单个事件循环线程加上一些用于 I/O 的操作系统内核线程。这样我们就摆脱了过度上下文切换的开销，也不需要为每个连接分配线程栈。这在负载下减少了内存占用，并减少了 CPU 时间的浪费在上下文切换上。理想情况下，CPU 成为事件驱动网络应用程序的唯一明显瓶颈。在资源完全饱和之前，事件循环随着吞吐量的增加而扩展。一旦负载增加超过最大饱和度，事件队列开始堆积，因为事件处理线程无法匹配。在这种情况下，事件驱动方法仍然提供了充分的吞吐量，但由于过载，请求的延迟线性增加。这可能对于临时负载峰值是可以接受的，但持续过载会降低性能并使服务无法使用。一种对策是更加注重资源的调度和事件处理的解耦，正如我们很快在分析基于阶段的方法时看到的那样。

目前，我们仍然关注事件驱动架构，并将其与多核架构对齐。虽然基于线程的模型涵盖了基于 I/O 的和基于 CPU 的并发，但最初的基于事件的架构仅解决了 I/O 并发。为了利用多个 CPU 或核心，必须进一步适应事件驱动服务器。

一个明显的方法是在单个机器上实例化多个独立的服务器进程。这通常被称为 N-copy 方法，用于在具有N个 CPU/核心的主机上使用 N 个实例。在我们的案例中，一台机器将运行多个 web 服务器实例，并在负载均衡器上注册所有实例。一个不太隔离的替代方案是在所有实例之间共享服务器套接字，因此需要一些协调。例如，这种方法的一个实现是用于 node.js 的 cluster 模块，它克隆应用程序的多个实例并共享单个服务器套接字。

在架构模型中的 web 服务器有一个特定的特性——它们是无状态的，没有共享的组件。即使使用内部缓存来处理动态请求，也需要在服务器架构中进行几项更改。目前，可以接受具有单线程服务器和回调的顺序执行语义的更简单的并发模型作为架构的一部分。正是这种简单的执行模型使得单线程应用程序对开发人员具有吸引力，因为协调和同步的努力减少了，并且保证应用程序代码（即回调）不会并发运行。另一方面，这种特性从本质上阻止了在单个事件驱动应用程序内部利用多个进程。Zeldovich 等人已经用 [libasync-smp](https://www.usenix.org/legacy/publications/library/proceedings/usenix03/tech/full_papers/zeldovich/zeldovich.pdf) 解决了这个问题，这是一个利用多个进程和并行回调执行的异步编程库。简单的顺序编程模型仍然得以保留。**基本思想是使用令牌，即分配给每个回调的所谓颜色。具有不同颜色的回调可以并行执行，而具有相同颜色的回调则保证串行执行**。对所有未标记的回调使用默认颜色，使得这种方法向后兼容没有任何颜色的程序。

让我们用缓存扩展我们的 web 服务器，使用颜色来增加额外的并发。读取和解析新请求是顺序操作，但不同的请求可以同时处理。因此，每个请求获得一个不同的颜色（例如，使用套接字描述符），不同请求的解析操作实际上可以并行进行，因为它们被不同地标记了。在解析了请求之后，服务器必须检查所需的内容是否已经被缓存。否则，必须从应用服务器请求。**现在检查缓存是一个并发操作，必须顺序执行，以提供一致性**。因此，这一步为所有请求使用相同的颜色标签，指示调度程序始终串行运行这些操作，绝不并行。这个库还允许回调执行部分阻塞操作。只要操作没有用共享颜色标记，它就不会直接阻塞其他回调。该库由一个线程池和一组以颜色区分的事件队列支持。这个解决方案允许坚持传统的事件驱动编程风格，但在一定程度上引入了真正的并发。然而，它要求开发者正确标记回调。有时候，在事件驱动程序中推理执行流程已经很困难了，额外的努力可能会进一步复杂化这个问题。

### 综合方法

结合了线程和事件的方法，以及由于两种通用模型的缺点，导致了一些结合了两种特性的替代架构和库的出现。

#### 分阶段事件驱动架构（Staged Event-driven Architecture，SEDA）

Welsh 等人设计了一种形成性架构，称为 [SEDA](https://dl.acm.org/doi/10.1145/502034.502057) ，它结合了线程和事件来构建可扩展的服务器。作为一个基本概念，它将服务器逻辑划分为一系列定义良好的阶段，这些阶段通过队列连接，如图 4.4 所示。请求在处理过程中从一个阶段传递到另一个阶段。每个阶段都由一个线程或线程池支持，可以动态配置。

![](./asserts/seda-server.svg)

图 4.4：本图展示了 SEDA 的概念。在这个示例中，有两个阶段，每个阶段都有一个接收事件的队列、一个由线程池支持的事件处理程序和一个监控资源的控制器。各阶段之间的唯一交互是向管道中的下一阶段发送事件。

这种分离有利于模块化，因为阶段的流水线可以轻松地被更改和扩展。SEDA 设计的另一个非常重要的特性是资源意识和对负载的显式控制。每个阶段排队项目的大小和每个阶段的线程池的工作量提供了对整体负载因子的明确了解。在过载情况下，服务器可以调整调度参数或线程池大小。其他自适应策略包括流水线的动态重配置或有意的请求终止。当资源管理、负载内省和适应性与阶段的应用逻辑解耦时，开发条件良好的服务就简单了。从并发性的角度来看，SEDA 代表了每连接一个线程的多线程和基于事件的并发之间的混合方法。拥有一个线程（或线程池）出队并处理元素类似于事件驱动方法。使用多个具有独立线程的阶段有效地利用了多个 CPU 或核心，并趋向于多线程环境。从开发者的角度来看，某个阶段的处理代码的实现也更类似于传统的线程编程。

SEDA 的缺点是即使在最小负载的情况下，由于队列和阶段遍历也会增加延迟。在后来的[回顾](http://matt-welsh.blogspot.com/2010/07/retrospective-on-seda.html)中，Welsh 还批评了模块边界（阶段）和并发边界（队列和线程）的缺乏区分。这种分布触发了太多的上下文切换，当一个请求通过多个阶段和队列时。一个更好的解决方案是将多个阶段与公共线程池组合在一起。这减少了上下文切换并改善了响应时间。具有 I/O 操作和相对较长执行时间的阶段仍然可以被隔离。

SEDA 模型启发了几个实现，包括通用服务器框架 [Apache MINA](http://http//mina.apache.org) 和企业服务总线如 [Mule ESB](http://www.mulesoft.com/)。

#### 特殊用途库

其他方法关注了一般线程的缺点和特定可用（用户级别）线程库的问题。我们很快就会看到，线程的大多数可扩展性问题都与它们的库的不足有关。例如，von Behren 等人的 [Capriccio 线程库](https://dl.acm.org/doi/10.1145/1165389.945471)承诺通过解决主要线程问题为服务器提供可扩展的线程。广泛的上下文切换问题通过使用非抢占式调度来解决。线程要么在 I/O 操作上让步，要么在显式让步操作上让步。每个线程的栈大小是基于编译时之前的分析而限制的。这样就没有必要预先过度提供有界栈空间。然而，无限循环和递归调用的使用使得无法事先完全计算栈大小。作为一种解决方法，在代码中插入了检查点，以确定栈溢出即将发生并在这种情况下分配新的栈块。检查点在编译时插入，并且放置得当，以确保在两个检查点之间的代码内永远不会发生栈溢出。另外，应用了资源意识的调度，以防止颠簸。因此，监视 CPU、内存和文件描述符，并结合对线程资源使用的静态分析，调度被动态适应。

此外，还开发了结合线程和事件的混合库。[Li 和 Zdancewic](https://dl.acm.org/doi/10.1145/1273442.1250756)基于 Haskell 的并发单子实现了一个组合模型。编程语言 Scala 也提供了可以结合用于服务器实现的事件驱动和多线程并发。

|                                 | 基于线程              | 事件驱动                       |
| :------------------------------ | :-------------------- | ------------------------------ |
| **connection/request state**    | thread context        | state machine/continuation     |
| **main I/O model**              | synchronous/blocking  | asynchronous/non-blocking      |
| **activity flow**               | thread-per-connection | events and associated handlers |
| **primary scheduling strategy** | preemptive (OS)       | cooperative                    |
| **scheduling component**        | scheduler (OS)        | event loop                     |
| **calling semantics**           | blocking              | dispatching/awaiting events    |

表 4.2：基于线程的服务器架构与事件驱动服务器架构的主要区别

### 评估

到目前为止，我们已经考虑了构建并发 Web 服务器的不同架构原则。在为高并发使用实现服务器时，应该应用这些模型中的一个。然而，还有其他因素也会影响实现的实际性能和可扩展性。这包括编程语言、执行环境（例如虚拟机）、操作系统、可用的线程库以及用于 I/O 操作的可用手段（例如，对真正异步 I/O 的支持）。对于每种服务器架构，都可以实现可扩展的服务器实现——然而，实际要求各不相同。

[Pariag 等人](https://dl.acm.org/doi/abs/10.1145/1272996.1273021)进行了基于线程的、事件驱动的和混合管道服务器的详细性能导向比较。基于线程的服务器（knot）利用了前面提到的 Capriccio 库。事件驱动服务器（26#26server）被设计为支持套接字共享和使用 N-copy 方法的多处理器支持。最后，混合管道服务器（WatPipe）受到 SEDA 的极大启发，由四个阶段组成，用于服务 Web 请求。Pariag 及其团队然后对这三个服务器进行了测试和大量调优。最后，他们使用不同的场景对服务器进行了基准测试，包括故意的过载情况。以前的基准测试已经被用来推广[新的基于线程的或事件驱动的架构]() [^Pai99][^Wel01][^vB03a]，通常对新架构有明显的好处。Pariag 等人的广泛基准测试显示，只要进行彻底的调优和（重新）配置，所有三种架构模型都可以用于构建高度可扩展的服务器。结果还表明，使用异步 I/O 的事件驱动架构仍然比基于线程的架构有轻微的优势。

像 nginx（例如 GitHub、WordPress.com）、lighttpd（例如 YouTube、Wikipedia）或 [Tornado](http://www.tornadoweb.org/)（例如 Facebook、Quora）这样的事件驱动 Web 服务器目前非常流行，已经出现了几个遵循这种架构模式的通用框架。可用于 Java 的这类框架包括 [netty](http://www.jboss.org/netty) 和 MINA。

请注意，在本章中我们不进行自己的基准测试。Nottingham，HTTP 标准的编辑之一，撰写了一篇深入的总结，[解释了为什么即使是公正的服务器基准测试也是极其困难和昂贵的](http://www.mnot.net/blog/2011/05/18/http_benchmark_rules)。因此，我们仅专注于 Web 服务器的架构概念和设计原则，并将我们的考虑限制在 [Pariag 等人之前的结果](https://dl.acm.org/doi/abs/10.1145/1272996.1273021)。

[^1]: https://web.stanford.edu/~ouster/cgi-bin/papers/threads.pdf
[^2]: https://www.usenix.org/legacy/events/hotos03/tech/full_papers/blake/blake.pdf
[^3]: https://dl.acm.org/doi/10.1145/502034.502057
[^4]: STEVENS, W. Richard; FENNER, Bill RUDOFF, Andrew M.: *Unix Network Programming, Volume 1: The Sockets Networking API (3rd Edition)*, Addison-Wesley Professional (2003)
[^Pai99]: https://www.usenix.org/legacy/event/usenix99/full_papers/pai/pai.pdf
[^Wel01]: https://dl.acm.org/doi/10.1145/502034.502057
[^vB03a]: https://web.stanford.edu/class/cs240e/papers/threads-hotos-2003.pdf

