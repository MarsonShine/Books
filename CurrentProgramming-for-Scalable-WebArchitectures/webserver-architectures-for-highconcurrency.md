# 高并发网络架构

在这一章节，我们将深入探讨在一个网络服务器内处理众多连接时并发性问题的细节。根据我们架构模型的描述，请求处理过程与应用逻辑是分开的。因此，本章不涉及动态内容的生成，这个主题将在第5章进一步探讨。从网络服务器的视角来看，不同请求之间无需相互协调。但如果应用层面的请求之间有依赖关系——比如，一个长时间轮询的请求在等待某个应用事件，而另一个请求恰好触发了这个事件——这种情况需要在我们的应用服务器模型中得到处理。

本章将概述高性能网络服务器面对海量并发连接时遇到的并发挑战。然后，我们将了解不同的服务器架构是如何利用各种编程模型来管理并行处理、并发性以及 I/O 操作的。最终，我们将对比两种主流的并发模型——基于线程的模型和基于事件驱动的模型，以便更全面地理解它们的差异和应用场景。

## 概述

本章我们要解决的主要问题是在编程模型中将连接/请求正确映射到并发执行流。由于我们的目标是处理多个并行的 HTTP 请求，这主要涉及高度 I/O 绑定的操作。在 Web 基础设施方面，我们希望确保我们的软件实现不会轻易成为瓶颈，并在每个部署的服务器上在负载下实现高硬件资源利用率。在请求/响应和连接处理方面，有几个有趣的指标可以描述服务器的性能：

- 请求吞吐量（#/秒）
- 原始数据吞吐量（Mbps）
- 响应时间（毫秒）
- 并发连接数（#）

此外，还有以下性能统计数据需要在服务器的机器上观察：

- CPU利用率
- 内存使用情况
- 打开的套接字/文件句柄数
- 线程/进程数

重新表述我们的问题，我们希望尽可能并行处理尽可能多的请求，尽快完成，并且使用尽可能少的资源。换句话说，资源利用应该随着工作量的增加而扩展。

### 请求处理工作流程

根据我们在前一章中概述的 Web 服务器要求，我们可以将以下步骤列为处理请求的最小工作流程。附加功能，如请求日志记录或缓存，有意被省略。

1. *接受传入请求* - 在新的 HTTP 连接的情况下，首先必须建立底层的 TCP 连接。
2. *读取请求* - 需要对所有请求进行原始字节的读取（I/O 绑定），然后解析实际的 HTTP 请求（CPU 绑定）。如果请求包含实体，例如 POST 参数或文件上传，则还必须读取此附加内容。根据实现方式，Web 服务器要么缓冲实体直到完全加载，要么直接将其传输到应用服务器。前者允许内容卸载，对于慢速连接很重要，后者由于减少了延迟而很有意思。
3. *将请求分派到应用层* - 根据我们的架构模型，解析后的请求随后被发送到应用服务器。我们使用解耦的组件，因此这通常是一个基于网络的任务，使用消息传递（或其他替代方法，如 RPC）。如果是处理静态内容的 Web 服务器，则访问本地或远程文件系统。所有操作都是 I/O 绑定的。
4. *一旦可用，将生成的响应写入套接字* - 一旦生成响应（例如来自应用服务器的生成的 HTML 文件或来自文件系统的静态图像），就可以通过写入套接字将其返回给客户端。同样，Web 服务器可以缓冲响应，从而为应用服务器提供卸载。或者它直接将生成的响应传输给客户端。
5. *完成请求* - 根据通过请求/响应头和 HTTP 默认值协商的连接状态，Web 服务器要么关闭连接，要么从头开始等待客户端发送下一个请求。

### C10K问题

Kegel 在 1999 年发表了一篇具有里程碑意义的文章[[Keg06](https://berb.github.io/diploma-thesis/community/0_bibliography.html#Kegel2006)]，让“Web 服务器同时处理一万个客户端”成为可能，从而提出了*C10K问题*的概念。原始文章已经多次更新，并成为 Web 服务器可扩展性方面的重要资源。

他通过展示硬件在一定程度上可能不再是高并发连接的瓶颈来激发了他的思考。基于当时合理的硬件条件（即 500 MHz，1 GB内存，6 x 100Mbit/s），Kegel 认为同时处理 1 万个客户端完全可行，每个请求可达到 50KHz、100K字节和 60K位/秒 - 对于 4KB 的有效负载数据来说已经足够了。实际上，当时大多数服务器远未达到这个数字。然后，他研究了 Web 服务器的内部机制，特别评估了常见的 I/O 策略和线程模型。

C10K这个术语在十年后得到了进一步的强化，当时 *Urban Airship* 公司在单个节点上无法处理 50 万并发连接时遇到了困难。他们解决*C500k问题*的兴趣是基于他们的商业模式。为大量移动设备提供通知服务要求他们同时处理极高数量的空闲连接。

### I/O 操作模型

对于常规桌面应用程序，处理基于文件或网络的输入和输出通常是一项零星任务。对于我们的 Web 服务器来说，处理 I/O 操作是主要任务。操作系统提供了不同的 I/O 操作方式，我们将详细了解一下 I/O 操作模型。

在文献中，阻塞（blocking）和同步（synchronous）以及非阻塞（non-blocking）和异步（asynchronous）这两个术语通常可以互换使用，两者描述的概念非常相似。而且，这些术语在不同操作系统的不同层次上使用的含义也不同。为了至少在描述 I/O 操作时进行区分，我们将它们分开。

- **阻塞 vs. 非阻塞**

  使用这些属性，应用程序可以告诉操作系统如何访问设备。当使用阻塞模式时，I/O 操作不会在操作完成之前返回给调用者。在非阻塞模式下，所有调用都会立即返回，但只指示操作的调用状态或错误。因此，可能需要多次调用才能等待操作成功结束。

- **同步 vs. 异步**

  这些属性用于描述 I/O 操作期间的控制流程。同步调用保持控制，即在操作完成之前不返回。异步调用立即返回，允许执行其他操作。

综合这些模式，I/O 可产生四种不同的运行模式。有时，为了方便起见，会使用额外的软件层提供与实际底层模式不同的模式。

- **同步阻塞I/O**

  这是许多常规应用程序中最常见的操作模式。在这种情况下，I/O 操作是一个单独的操作，导致应用程序处于阻塞状态，直到操作完成并将数据从内核空间复制到用户空间（例如读取操作）。在内核级别上，实际的原始操作通常与其他操作多路复用。但对于应用程序本身来说，它代表了一个长时间运行的操作。这种模型不仅对开发人员来说不是直接的模型，而且还会导致应用程序进程在发出 I/O 操作时不需要 CPU 时间。这是操作系统调度程序在切换到其他进程时的方便时间。

- **同步非阻塞I/O**

  在这种模式下，应用程序以非阻塞模式访问 I/O 设备。结果，内核空间立即返回 I/O 调用。通常情况下，设备尚未准备好，调用响应指示应稍后重复调用。通过这样做，应用程序代码通常实现了忙等待行为，这可能非常低效。一旦 I/O 操作完成并且数据在用户空间可用（在读取操作的情况下），应用程序可以继续运行和使用数据。

- **异步阻塞I/O**

  令人惊讶的是，异步阻塞模型仍然使用非阻塞模式进行 I/O 操作。但是，与忙等待不同，此时使用专用的阻塞系统调用来通知 I/O 状态。有几个系统调用提供这样的功能，包括 `select`、`poll`、`epoll` 和 kqueue [[Ste03](https://berb.github.io/diploma-thesis/community/0_bibliography.html#Stevens2003)]。通过这样做，可以将多个 I/O 描述符传递给系统调用。当用于通知的阻塞系统调用的实现稳定且高效时，这是一种适用于高并发 I/O 的良好模型。

- **异步非阻塞I/O**

  这种 I/O 模型立即从 I/O 调用返回。完成后，会发出事件或执行回调。这种模型的有趣特点在于用户级别上没有阻塞或忙等待。整个操作转移到内核空间。这使得应用程序可以利用额外的 CPU 时间，同时在内核级别后台进行 I/O 操作。换句话说，应用程序可以将 I/O 操作与其他需要 CPU 的操作重叠，或者在此期间调度其他 I/O 操作。不出所料，这种模型在高并发 I/O 下也提供良好的性能。

|              | blocking     | non-blocking                    |
| ------------ | ------------ | ------------------------------- |
| 同步         | `read/write` | `read/write` using `O_NONBLOCK` |
| asynchronous | I/O 多路复用 | AIO                             |

表 4.1：Linux 中的 I/O 模型

这些模型只描述了 Linux 操作系统上的低级 I/O 操作。从更抽象的程序员角度来看，可以使用其他模型替代，但通常会带来一些性能损失。应用程序框架可以通过后台线程使用同步阻塞的方式提供 I/O 访问，但为开发人员提供基于回调的异步接口，反之亦然。

从现在开始，在大多数情况下，我们将同步阻塞的方法与其他三种方法区分开来。基于某种信号、通知或回调执行的方法，我们将其称为事件驱动或基于事件的方法。