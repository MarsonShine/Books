# 并发

并发性是系统的一个属性，表示多个活动可以同时执行的事实。根据 [Van Roy 的定义](https://ia902308.us.archive.org/15/items/c-15_20211009/C15.pdf)，一个具有“多个独立活动，每个活动以自己的速度执行”的程序就具有并发性。此外，这些活动之间可能会进行某种形式的交互。活动的并发执行可以发生在不同的环境中，如单核处理器、多核处理器、多处理器甚至分布式系统的多台机器上。然而，它们都面临着相同的挑战：提供通过协调和同步控制不同的执行流的机制，同时确保一致性。

除了最近硬件趋势朝向多核和多处理器系统外，应用程序中使用并发通常是出于性能提升的动机。[Cantrill 等人](https://dl.acm.org/doi/pdf/10.1145/1454456.1454462)描述了并发执行应用程序可以提高性能的三种基本方法：

1. **减少延迟**：通过将工作单元细分为可以并发执行的部分，以更短的时间执行。
2. **隐藏延迟**：底层系统同时执行多个长时间运行的任务。当任务由于需要等待外部资源（如磁盘或网络 I/O 操作）而被阻塞时，这种方法特别有效。
3. **增加吞吐量**：通过并发执行多个任务，可以增加系统的总体吞吐量。需要注意的是，这也加速了那些尚未专门设计为并发执行的独立顺序任务。

并发性的存在是任何类型的分布式系统的固有属性。在不同机器上运行的进程形成一个共同的系统，可以同时在多台机器上执行代码。

从概念上讲，所有的 Web 应用程序都可以被多个用户同时使用。因此，Web 应用程序本质上也是并发的。这不仅仅限于必须同时处理多个客户端连接的 Web 服务器。执行请求的关联业务逻辑的应用程序和后端数据存储也面临并发性的挑战。

## 并发性与并行性

在文献中，关于并发性和并行性的定义以及它们之间的关系存在不同的观点。有时甚至将这两个术语视为同义词。我们现在将介绍对这两个术语及其对编程的影响的区分。

### Concurrency vs. Parallelism

并发性是程序的概念属性，而并行性是运行时状态。程序的并发性取决于编程语言和编码方式，而并行性取决于实际的运行环境。给定两个要并发执行的任务，有几种可能的执行顺序。它们可以按顺序（任意顺序）、交替执行，甚至同时执行。只有同时执行两个不同的任务才能实现真正的并行性。在调度方面，只有在硬件架构支持并行执行的情况下，如多核或多处理器系统，才能实现并行性。单核机器也可以同时执行多个线程，但它永远无法提供真正的并行性。

### 并发编程与并行编程

区分并发编程和并行编程更加棘手，因为它们在不同的概念层面上针对不同的目标。并发编程处理并发和交错的任务以及由于非确定性控制流而产生的复杂性。减少和隐藏延迟与提高吞吐量同样重要。相反，并行编程更加注重确定性的控制流，并主要追求优化的吞吐量。Web 服务器的内部结构是并发编程的典型产物，而像 Google 的 [MapReduce](https://dl.acm.org/doi/pdf/10.1145/1327452.1327492) 或 Java 的 [fork/join](https://dl.acm.org/doi/pdf/10.1145/337449.337465) 这样的并行抽象则提供了并行编程的一个很好的例子。并行编程对于一些专门的任务也是必不可少的。例如，图形处理单元（GPU）专为大规模浮点计算能力而设计，通常可以同时在所有单元上并行运行某种数值计算。高性能计算是并行编程的另一个重要领域。它利用计算机集群并将子任务分配给集群节点，从而加速复杂计算。

### 支持并发的计算机体系结构

|               | Single Instruction | Multiple Instruction |
| :------------ | :----------------- | -------------------- |
| Single Data   | SISD               | MISD                 |
| Multiple Data | SIMD               | MIMD                 |

在观察物理并发实际可行的体系结构时，可以证明前面提到的区别。因此，我们将参考 [Flynn 的分类法](https://users.cs.utah.edu/~hari/teaching/paralg/Flynn72.pdf)如上表所示。该分类法根据指令并发性和可用数据流推导出四种不同类型的计算机体系结构。`SISD`（单指令单数据）类型代表传统的单处理器机器。由于它们缺乏物理并发性，我们不会进一步讨论。`MISD`（多指令单数据）是一种比较特殊的架构类别，有时用于容错计算，在这种情况下，相同的指令会被冗余执行。然而，它与我们的讨论无关。真正的并行性只能在支持多数据流的架构（`SIMD ` 和 `MIMD`）上得到利用。**SIMD（单指令流多数据流）**代表了前述的架构类别，其目标是计算的专用并行执行，例如图形处理单元和矢量处理器。`SIMD` 利用的是数据级并行性，不适合处理网络请求，因此我们不会讨论这类架构。我们将重点讨论剩下的最后一类，即**MIMD（多指令流多数据流）**。`MIMD` 代表依赖共享或分布式内存的架构，因此包括具有多个内核、多个 CPU 甚至多台机器的架构。在接下来的讨论中，我们将主要关注并发编程（涉及子任务的并行执行部分，与[第 5 章](concurrency-concepts-for-applications-and-business-logic.md)相关），并且只关注MIMD类架构。

## 并发编程模型

[Van Roy](https://ia902308.us.archive.org/15/items/c-15_20211009/C15.pdf) 介绍了四种主要的并发编程方法，我们将对其进行简要研究（见下图）。更重要的模型将作为网络架构内并发编程的潜在解决方案在后面进行研究，特别是在[第 5 章](concurrency-concepts-for-applications-and-business-logic.md)。

![](./asserts/concurrency.svg)

### 顺序编程

在这种确定性编程模型中，根本不使用并发性。在其最强形式中，程序的所有操作都有一个总顺序。较弱的形式仍然保持确定性行为。不过，它们不向程序员事先保证确切的执行顺序。或者，它们提供了明确的机制来抢占当前正在执行的任务，例如，协同程序就是这样做的。

### 声明式并发

声明式编程是一种编程模型，它倾向于计算的隐式控制流。控制流不是直接描述的，而是程序计算逻辑的结果。声明式并发模型扩展了声明式编程模型，允许多种执行流。它增加了基于数据驱动或需求驱动方法的隐式并发。虽然这会在运行时引入某种形式的非确定性，但这种非确定性通常无法从外部观察到。

### 消息传递并发

这种模型是一种编程风格，允许并发活动通过消息进行通信。通常，这是活动之间唯一允许的交互形式，而它们在其他方面是完全隔离的。消息传递可以是同步的或异步的，从而导致不同的同步和协调机制和模式。

### 共享状态并发

共享状态并发是一种扩展编程模型，允许多个活动访问有竞争的资源和状态。不同活动之间共享完全相同的资源和状态需要专门的机制来同步访问和协调活动。否则，该模型的一般非确定性和缺失不变性将直接导致状态一致性方面的问题。

## 并发控制的同步与协调

无论实际的编程模型如何，在并发控制方面必须存在隐式或显式的控制（至少在运行时环境中）。当多个执行流同时在同一地址空间中操作而没有任何有序访问协议时，这是危险和不安全的。两个或多个活动可能访问相同的数据，从而导致数据损坏以及应用程序状态不一致或无效。此外，共同解决问题的多个活动需要就它们的共同进度达成一致。这两个问题都代表了并发和并发编程的基本挑战。

同步和协调是两种试图解决这个问题的机制。同步，或者更准确地说，竞争同步，是一种控制多个活动之间对共享资源访问的机制。当多个活动需要访问不能同时访问的资源时，这一点尤为重要。适当的同步机制通过不同活动对资源的排他性和有序访问来实施。协调，有时也称为合作同步，旨在协调协作活动。

在实践中，同步和协调有时会混淆。这两种机制都可以是隐式的或显式的。隐式同步将同步隐藏为编程语言的操作语义的一部分。因此，它不是可见程序代码的一部分。相反，显式同步要求程序员向代码中添加显式的同步操作。

## 任务、进程和线程

到目前为止，我们对并发性的考虑都是基于计算机体系结构和编程模型。现在，我们将通过介绍操作系统使用和提供的实际活动实体，以及这些实体如何映射到硬件，来说明它们之间的相互关系。请注意，从现在起，我们将使用“任务”一词作为执行单位的一般抽象概念。

![](./asserts/conc_exec.svg)

​																								图2.2 多个任务同时执行的正交概念。



同时执行多个任务的能力一直是操作系统的关键需求。这通过多任务处理来解决。这种机制管理任务的交错和交替执行。在多个 CPU 核心或 CPU 的情况下，多任务处理可以通过多进程处理来补充，它将不同的任务分配给可用的核心/ CPU。这两种机制的关键概念是调度，它使用_调度策略_来组织对任务的处理时间分配。适当的策略可以有不同的目标，例如任务之间的公平调度，任务执行的固定延迟或最大利用率。调度策略的另一个区别是它们的抢占模型。在抢占模型中，调度器分配处理时间给一个任务，最终可能会撤销它。任务无法控制抢占。在合作模型中，任务本身有责任在一段时间后主动让出，以允许另一个任务运行。调度是任何操作系统的重要职责。然而，值得注意的是，应用程序本身可以为其自己的内部任务提供某种调度，正如我们将在[第 4 章](webserver-architectures-for-highconcurrency.md)和[第 5 章](concurrency-concepts-for-applications-and-business-logic.md)中看到的那样。

操作系统通常提供不同类型的任务-进程和线程。本质上，它们代表了不同的任务粒度。进程是一种重型的任务单元，拥有从操作系统分配的内存和文件描述符等系统资源。线程是属于某个特定进程的轻型任务单元。在同一进程中分配的所有线程共享内存、文件描述符和其他相关资源。与创建新进程相比，创建线程是一种相对廉价的操作。

大多数并发应用程序广泛使用多线程。然而，这并不意味着编程语言本身就有明确的线程实体。相反，执行环境可能会在运行时将编程语言的其他并发构造映射到实际的线程。同样地，多线程的共享状态属性可能会被语言习惯性地隐藏起来。

## 并发、编程语言和分布式系统

接下来，我们将讨论在构建大型架构时，并发编程、编程语言和分布式系统之间的密切关系。与常规编程相比，分布式系统编程引入了一系列额外的挑战。[分布式计算的谬误](https://arnon.me/wp-content/uploads/Files/fallacies.pdf)很好地概述了一些必须解决的重要陷阱。例如，没有预见到网络中的错误或忽略本地和远程操作的不同语义都是常见的误解。

从软件工程的角度来看，主要挑战在于容错、分布式整合和可靠性。如前所述，分布式系统本身就是并发和并行的，因此并发控制也是必不可少的。

用于分布式系统的编程语言必须包含适当的语言习语和功能，以满足这些要求。否则，就必须在核心语言的基础上提供附加功能的框架。

[Ghosh 等人](https://d-nb.info/1239549970/34)考虑了编程语言对分布式系统的影响。他们指出，Java 和 C++ 等主流语言仍是开发分布式系统的最流行选择。它们大多与中间件框架相结合，提供额外的功能。然而，通用语言的优势并不能在很大程度上满足分布式系统的主要要求。[基于 RPC 的系统（见 Kendall 等人 ）](https://dl.acm.org/doi/book/10.5555/974938)及其基于对象的后代（见 Vinoski [Vin08]）的经验对这种方法提出了一些质疑。提供可分配性的中间件系统弥补了语言核心缺失的功能。因此，这些系统实际上满足了必要的要求，但使用起来往往也很麻烦，而且引入了多余的复杂性。

最近，人们对包含高级并发和分布式计算的各种替代编程语言越来越感兴趣。这些语言的通用性较低，但侧重于分布式系统的重要概念和惯用语，如组件抽象、容错和分布机制。有趣的是，这些面向分布式计算的语言大多也采用了其他并发方法。我们将在[第 5 章](concurrency-concepts-for-applications-and-business-logic.md)中简要介绍其中一些语言。