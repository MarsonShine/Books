# 应用程序和业务逻辑的并发概念

上一章节，[第 4 章](webserver-architectures-for-highconcurrency.md)，讨论了作为 Web 服务器问题的连接并发性。这个挑战的特点是大量的 I/O-bound 操作，但可变状态非常有限。在本章中，我们从一个不同的角度来看待并发性，即专注于应用服务器。也就是说，负责执行应用程序实际业务逻辑的组件，由传入的请求激发。

在大规模 Web 架构中，请求的固有并行性是不可避免的。多个用户同时访问应用程序，创建大量的独立请求。因此，应用服务器是必须处理高度并发的组件。我们在本章中想要处理的主要问题是，当用于应用服务器的业务逻辑时，不同并发范式的含义和后果。这不仅包括处理并发应用程序中状态的影响，还包括特定范式对开发者的简单性和可访问性。

此外，我们不专注于特定的应用服务器实现或 Web 应用程序框架。相反，我们更一般地与并发性和并发编程的范式进行较量。这些反思适用于一般的分布式和并发编程。最终，我们在寻找一种适当的编程抽象，用于应用程序固有的并发性，这不仅允许我们开发可扩展和高性能的应用程序，同时也能在一定程度上驯服并发性的麻烦。

## 概览

应用服务器提供了一种响应式行为，能够根据传入请求生成响应。这个应用服务器组件通过高级消息（或者是远程过程调用 RPC 或类似机制）从上游 Web 服务器接收调用。因此，它与底层的连接处理或请求解析职责解耦。为了生成适当的响应，应用服务器执行与请求 URI 映射的业务逻辑。在应用服务器内部，一个请求的执行流程包括与不同的架构组件交互，如数据库和后端服务，但也包括作为应用逻辑一部分的计算操作：

- **CPU-bound 活动**
  CPU-bound 活动是那些在执行过程中主要消耗 CPU 时间的任务。通常，这些任务是在内存数据上操作的计算密集型算法。就 Web 应用而言，这适用于例如输入验证、模板渲染或即时编码/解码内容等任务。

- **I/O-bound 活动**

  I/O-bound 活动是主要受 I/O 资源限制的任务，如网络 I/O 或文件 I/O。当任务操作的是尚未（或尚不）属于其自身内存的外部数据时，通常会发生 I/O-bound 活动。在我们的架构模型中，这包括访问大多数平台组件，包括存储后端、后台服务和外部服务。

![](./asserts/req_para.svg)

图 5.1：请求处理的执行流程。应用服务器首先查询缓存，然后分派两个独立的数据库查询，最后再次访问缓存。在左侧，执行是严格按顺序进行的。在右侧，独立操作被并行化，以改善延迟结果。

对于 Web 应用的一个请求，通常会触发这两种类型的操作，尽管实际的比例取决于应用的内部结构。许多内容丰富的 Web 应用（例如博客、维基）主要依赖于数据库操作，以及在一定程度上依赖于模板渲染。其他应用主要是 CPU-bound，如提供计算服务的 Web 服务或媒体文件转换的 Web 服务。在这两种情况下，都偏好低延迟的响应，因为它们对于良好的用户体验很重要。

与请求相关的应用逻辑通常以顺序方式实现。为了最小化延迟，应考虑并行化独立操作，如图 5.1 所示。在有向图表示中，第一个节点代表请求的到达，最后一个节点代表编译好的响应。中间的节点代表操作，如数据库操作或计算函数。控制流的分割导致并行操作，这些操作必须在稍后同步。这种模式，也称为 scatter and gather[^Hoh03]，特别适用于 I/O-bound 活动，如数据库操作和访问其他架构组件（网络 I/O）。

![](./asserts/req_coord.svg)

图 5.2：作为交互式网络应用程序一部分的待处理请求之间的协调。用户 A 的浏览器通过长时间轮询不断发送通知请求。一旦用户 B 发布了新信息，网络应用程序就会协调通知并响应两个待处理请求，从而有效地通知用户 A。

此外，请求处理可能包括与其他请求的协调和通信，这可以通过使用外部消息组件，或使用应用服务器组件的内置机制来实现。例如，对于协作性、交互性和 Web 实时应用来说，这是必需的。然后，将发送专门的请求，使服务器最终能够在稍后时间，由其他请求的行为或其他服务器端事件触发时发送响应。

本质上，现代 Web 应用利用的并发属性与早期应用中完全隔离的请求的概念不同，如图 5.2 所示。应用状态不再完全保存在数据库系统内，但在一定程度上也在其他组件中共享，甚至可能在请求之间共享。协作和交互功能以及对低延迟的需求不再允许避开同步和协调。相反，必须拥抱真正的并发性，以适应 Web 应用的应用逻辑。在本章的剩余部分，我们将研究不同的并发编程方法以及它们如何管理状态、协调和同步。然后，我们将检查并发 Web 应用如何利用这些概念。

## 基于线程、锁和共享状态的并发

命令式编程，作为结构化编程最受欢迎的形式，围绕着顺序执行和可变状态的概念构建。它直接源自冯·诺依曼架构的概念。线程通常被视为这一概念的一个延申扩展，它们使得可以同时进行多个控制流。与较重的进程相比，线程是操作系统和硬件架构提供的并行主要构建块（即超线程）。不出所料，线程是大多数编程语言中并发的主要构建块。然而，基于线程、锁和共享状态的并发编程被认为是困难且容易出错的[^Sut05]。

### 共享和可变状态的含义

从概念上讲，线程描述了一个顺序的控制流，乍一看它与其他活动是隔离的。但与进程不同的是，线程共享同一地址空间。这意味着多个独立的线程可能会同时访问同一变量和状态。更糟的是，顺序编程建立在可变状态的概念上，这意味着多个线程也可能竞争写操作。**多线程主要使用抢占式调度**。结果，多个线程之间的切换和交错是未知的。这代表了一种强烈的不确定性形式。如果不加以处理，可变状态和不确定性就会引入竞态条件的严重风险。

当两个或多个线程竞争访问临界区时，就会发生竞态条件，临界区包含了线程之间共享的状态。由于可能的交错种类繁多，竞态条件可能导致各种不一致的状态。例如，一个线程可能读取到过时的状态，而另一个线程已经在更新它。当多个线程同时更改状态时，要么其中一个更改持续存在而其他更改丢失，要么可能持续存在一个受多次更改影响的不一致状态。最终，我们需要机制来保护临界区并强制同步访问。

### 锁机制

同步的一般原语是锁，它控制对临界区的访问。有不同类型的锁，具有不同的行为和语义。信号量[^Dij65]是简单的锁，提供等待(`wait`)和信号(`signal`)功能。在进入临界区或使用共享资源之前，必须调用等待函数。一旦通过了临界区，就使用信号释放它。通过在 `wait` 调用中阻塞其他竞争者，`semaphore` 可以防止多个线程同时获取该 `semaphore`。其他标识符实现，即所谓的计数标识符，允许一定数量的线程通过。因此，二进制寄存器可视为仅限于单个活动线程的计数寄存器。其他互斥结构提供了所有权的概念，这意味着临界区段暂时由一个不同的线程拥有，该线程也是唯一能在稍后解锁临界区段的实例。

更高级的互斥构造是监视器[^Hoa74][^Lam79b]，它使用条件变量以模块化方式保护部分。通常，这些部分的粒度为对象，或方法/函数。内部条件变量允许一个阻塞的线程暂时让出并等待其他线程触发的条件修改。锁机制的一个属性是**可重入性**。当锁支持可重入性时，已经获得某个锁的线程可以再次通过该锁。这对于可能重复访问临界区的递归函数来说是一个重要属性。除了计数锁，还有区分不同访问语义的锁。读/写锁允许读取线程的共享访问，但对要求写访问的线程提供独占访问。

### 锁的后果

锁允许我们序列化对关键部分的访问。互斥的使用使临界区段内的线程具有原子行为，因为对于其他等待的线程来说，它的执行是一个单一的操作。识别易受竞赛条件影响的代码段，并谨慎地在其周围加锁，可以抑制不确定性，并实现序列化访问。

然而，锁的概念引入了另一个多线程代码的危险。当获得的锁未被释放或要获得的锁永远不可用时，不正确的锁定实际上可能会破坏应用程序。很明显，当开发人员必须明确地将 `wait` 和 `signal` 函数置于保护部分时，就会发生错误锁定。更高级的抽象，如监视器，通常提供手段来标记整个代码段以进行互斥，并隐式获取和释放锁。然而，它们仍然可能遭受锁定问题。最臭名昭著的锁定问题是所谓的死锁。当两个或多个线程以循环依赖的方式竞争锁时，就会发生死锁。在最简单的情况下，两个线程都拥有一个单独的锁，但还需要获得对方线程的锁。由于没有线程能够在不获取第二个锁的情况下前进，因此两个线程都被阻塞，无法继续。

其他锁定问题包括活锁和锁启动。与死锁类似，活锁也会阻止线程继续运行。不过，线程在活锁情况下不会被阻塞。相反，它们会随着其他相关线程的状态变化而稳定地改变状态，反过来，这些线程也会改变状态。在一个示例场景中，两个线程必须获得两个资源才能继续运行。当它们无法同时获得两个资源时，它们会返回第一个资源，然后重新尝试获得两个资源。当两个线程同时开始获取第一个资源，然后又重新启动时，就会出现活锁。活锁可视为饥饿的一种特殊情况。它一般描述的是线程因其他贪婪的线程不断索取锁或资源而反复无法获取锁或资源的情况。

尽管一些饥饿问题，如活锁，可能在运行时使用随机回退进行重试来处理，但由于非确定性，潜在的锁定问题通常非常难以检测。当使用细粒度的多个锁时，死锁的风险增加。因此，通常建议使用粗粒度的锁以避免死锁。识别大的临界区并用锁保护它们不仅确保了序列化访问。事实上，粗粒度的锁导致线程最终顺序执行。这与我们之前增加并行性的目标相反。

为了具有真正的硬件并行性，我们需要选择非常细的锁粒度，使得多个线程可以在独立的临界区中继续进行。许多小的临界区不仅增加了锁管理的开销，因为锁定管理并非免费。然而，锁的广泛使用强调了上述危险的风险。显然，选择正确的锁粒度并不容易。

除了活锁、死锁和锁饥饿的问题外，锁在实践中还有另一个困难。给定多段代码，这些代码的临界区受到锁的保护，我们不能保证这些代码的组合不会导致死锁。本质上，我们不能在没有新的锁定问题风险的情况下组合线程安全的实现。这对于较大的代码片段，如框架组件或模块，尤其重要。锁定问题可能通过坚决的开发政策来解决，这些政策严格规定了锁的使用、获取顺序和条件。然而，这些政策不能以编程方式强制执行。此外，当使用外部或闭源组件时，确保正确锁定变得不可能。

尽管如此，基于线程、共享状态和锁定的并发编程仍然是主流，并且在大多数语言中都可用。重要的是要认识到，这种方法代表了并发的低级概念。它比我们很快就会看到的其他概念更接近裸机。然而，所有这些概念仍然在底层使用线程。

### 案例研究：Java中的并发

Java 编程语言从其存在之初就提供了基于线程的并发。它实现了 Mesa 监视器[^Lam79b]用于锁定和互斥，并提供了语言核心的几个同步原语。并发行为在 Java 语言规范[^Gos12]中定义，该规范详细描述了 JMM。Java 的一致性基于发生前顺序和隐式内存屏障的概念。然而，它并不为线程提供顺序一致性，正如许多开发者错误地假设的那样。事实上，JMM 类似于对称多处理，其中多个 CPU 拥有自己的缓存，但共享一个公共主内存。当 CPU 访问内存时，它们刷新自己的缓存并最终刷新更改。从比喻的意义上讲， Java 线程类似于 CPU，主内存是线程之间的共享内存，CPU 缓存是线程本地的数据副本。刷新或刷新的过程代表了所谓的内存屏障的穿越。除了上述排序外，JMM 还根据内存屏障定义了哪些操作不能被其他线程中断（原子性），以及何时变更必须传播给其他线程（可见性）。例如，启动和结束线程或使用同步原语会触及内存屏障，但也会触及对几个具有特定特性的变量的访问（见下文）。

`synchronized` 关键字使用给定对象作为监视器来保护整个方法或一个独特的代码块。Java 监视器是可重入的，支持递归调用。此外，每个 Java 对象都可以用作监视器，因此提供了条件信号的手段。`wait()` 方法阻塞持有监视器的线程并释放监视器，以允许其他线程继续并更改条件。在这种情况下，其他线程可以使用 `notify()` 和 `notifyAll()` 向等待线程发出信号。

`volatile` 关键字规避了变量的线程本地拷贝，并在每次访问时强制从共享内存中获取新副本。它只能用于单个原子操作。例如，增加值（多次操作）不是原子的。`final` 关键字使变量不可变。不可变值对并发的好处是避免了刷新值的需要，因为它们不能再被更改。建议始终将字段设置为 `final`，除非有不这样做的理由[^Blo08]。此外，Java 提供了一组原子实体（`java.util.concurrent.atomic`），类似于 `volatile` 变量。然而，这些实体是对象，确保所有操作的原子性，并使用内部非常高效的机制，如比较和交换。

活动由 `Thread` 类表示，该类提供了诸如 `start()` 之类的线程处理方法。这个类还有几个协调方法，如 `resume()` 和 `stop()`，不幸的是这些方法被破损了，不应该使用[^Blo08]。`Runnable` 接口从 `Thread` 类中抽象出来，只拥有一个 `run()` 方法，一旦线程启动，最终由线程执行这个方法。

虽然这是 Java 中并发编程的基础，但从 Java 5 开始引入了几种高级抽象，主要是为了促进并发应用程序的开发。显式锁（`java.util.concurrent.locks`）提供比同步的隐式监视器锁更广泛的锁定操作（例如，读写锁）。并发集合，如`ConcurrentMap` 或 `BlockingQueue`，扩展了现有集合，并提供线程安全操作以及协调访问的操作。`Runnable`、`Callable` 和 `Executor` 框架提供了另一种抽象。本质上，这些类将要执行的任务与实际执行它们的实体解耦。与线程池实体（例如`ExecutorService`）结合使用，这是许多并发应用程序的非常有用的抽象。`Futures` 允许在另一个线程中异步执行 `Callable`，立即返回最终结果的代理对象。对于线程之间更复杂的协调，提供了几种高级协调原语。这包括显式计数信号量、`CountDownLatch`（由倒计时触发的屏障）和 `CyclicBarrier`（用于线程重复协调的屏障点）。在 Java 7 中，引入了 fork/join 框架[^Lea00]。该框架旨在通过产生子任务并使用分而治之的策略，轻松并行化计算密集型任务。它提供了隐式任务协调并采用工作窃取。

下面的清单显示了一个用 Java 编写的示例 Web 应用程序，使用 [jetty](http://jetty.codehaus.org/jetty/) 和 [Java Servlets](http://www.oracle.com/technetwork/java/javaee/servlet/index.html)。在启动时，CountingRequestHandler被实例化一次。请求在内部通过线程池处理，因此并发请求可能触发 `CountingRequestHandler` 的 `handle()` 方法的同时调用。每个线程都访问共享变量 `count`，因此必须使用 `synchronized` 块进行保护。这演示了监视器的使用（在这个特定案例中，使用 `AtomicLong` 类将代表一个更优雅和高效的解决方案）。

一个用  Java  编写的简约并发网络应用程序，可返回目前已处理的请求数：

```java
import java.io.IOException;
import javax.servlet.ServletException;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import org.eclipse.jetty.server.Request;
import org.eclipse.jetty.server.Server;
import org.eclipse.jetty.server.handler.AbstractHandler;

public class CountingRequestHandler extends AbstractHandler {
	
	//Variable for counting requests handled so far
	private long count = 0;
	
	public void handle(String target, Request baseRequest, 
			HttpServletRequest request, HttpServletResponse response)
			throws IOException, ServletException {
		
		response.setContentType("text/plain");
		response.setStatus(200);
		baseRequest.setHandled(true);
		
		final long current; 
		//Access and modification of a variable shared between threads.
		synchronized (this) {
			current = ++count;
		}
		
		response.getWriter().println(""+current);
	}

	public static void main(String[] args) throws Exception {
		Server server = new Server(8080);
		server.setHandler(new CountingRequestHandler());

		server.start();
		server.join();
	}
}
```

### 多线程和锁用于并发应用逻辑

在多线程应用服务器中，每个应用请求被分配一个专用线程来处理。只要不需要与其他线程之间的协调，这种编程模型非常简单。隔离视图使得将请求逻辑编程为一系列操作变得容易。此外，当请求主要执行 CPU 绑定操作时，这种方法是一个有效的选择。当请求逻辑包含 I/O 绑定操作时，延迟通常隐藏在服务器内部，因为有多个请求需要同时处理。然而，这并不加快单个请求的处理速度，它只增加了服务器的总吞吐量。为了减少单个请求的实际延迟，我们需要进一步并行化单个请求的操作。额外的线程有助于同时执行更多工作，只要操作是独立的，因此可以并行运行。实际上越多的操作是 I/O 绑定的，我们就越多地遇到[第 4 章](webserver-architectures-for-highconcurrency.md)中看到的同样问题。使用更多线程来并行化 I/O 会因为重度上下文切换和高内存消耗而导致问题。在我们的架构中，服务是通过网络访问的分离组件，这导致了对 I/O 绑定操作的强烈关注。本质上，通过并行化工作可以减少延迟，但这通常对 CPU 绑定操作更有效。对于 I/O 绑定操作，这种方法并不很好地扩展。

关于请求之间的协调问题，我们已经看到，可以使用锁定并辅以条件变量来协调线程。然而，在应用服务器中，锁定的困难和传入请求的强烈非确定性使得实现完全正确的请求间协调模式相当困难。相反，更可取的做法是依赖外部的 pub/sub 消息组件（如 redis），尽管这仍然会阻塞线程。同样，建议使用外部设施（如键/值存储）在请求之间共享状态，以规避应用服务器内部的显式锁定。这种方法的另一个优点是可以通过实例化新的应用服务器来实现透明的扩展。

## 通过软件事务存储器实现并发性

我们已经看到，基于锁的并发有几个缺点。不确定性和共享状态要求防止出现竞争条件。锁的概念要求开发人员通过明确放置锁来保护关键部分。反过来，由于锁的顺序和不确定性，这可能会在运行时产生不可预测的锁定问题。此外，使用锁时，并发代码的可组合性也得不到保证。

我们现在研究另一种方法，它仍然建立在共享状态和锁的概念上，但不依赖开发人员的推理来正确加锁。相反，加锁成为底层运行环境的一部分，编程语言为并发代码段提供了更高的抽象。

### 事务内存

共享状态并发的无锁替代方案是 TM。它可以追溯到计算机科学中一个著名的概念--事务。并发但隔离的操作是数据库系统的既定概念 [^Hel07]。TM 继承了这一理念，并将其应用于共享状态并发[^Kni86][^Her93]。数据库事务对数据库行进行读写，而 TM 事务则对与其他线程共享的状态进行读写。TM 的概念有多种实现方式。HTM 提供了 TM 的硬件实现，通过事务缓存和扩展指令集等事务组件扩展了 CPU 架构。STM 不需要对硬件进行任何改动，完全通过软件支持事务处理。混合事务处理技术本质上是一种 STM 实现，它利用了不断进步的硬件对事务处理技术的支持。由于 HTM 的开发和实施成本较高，TM 主要以 STM 的形式提供。不过，有些人认为，一旦这种编程模型建立起来，混合模型最终可能会出现[^Cas08]。

传统的事务（见[第 6 章](concurrent-scalable-storage-backends.md)）即原子性、一致性、隔离性和持久性。因此，事务表现为单一操作，在尚未提交或中止的情况下不会产生不一致的状态。它们也不会干扰其他正在进行的事务，其结果总是被持久化的。需要注意的是，这种持久性与数据库系统和事务管理（TM）的事务不同。后者只将事务结果保存在内存中，但不从应用崩溃中恢复状态。由于这些属性，事务是可串行化的。事务的结果可以通过等效的顺序执行看似原子的操作来复现。事务的并发控制可以是悲观的或乐观的。悲观并发控制强制对资源进行保守锁定，导致事务吞吐量低。乐观并发控制将事务的完整性检查延迟到事务结束时。如果出现冲突，事务将被中止并重启。当事务不是长时间运行且不太频繁地发生冲突时，乐观并发控制提供了非常好的性能，重试的开销可以忽略不计。

### 软件事务内存

现在我们将只关注 STM，因为已经有几种实现方法可供使用。优化并发控制是现有 STM 实现的首选。为了将 STM 概念集成到语言中并实现底层的 STM 运行时，我们必须认识到在语言层面需要哪些构造。一方面，我们需要一种将代码部分标记为事务的方法。另一方面，我们可能需要区分线程间共享的变量和资源（需要事务调用语义）和非事务的线程本地变量。否则，任何读写操作都会导致事务。

一旦在运行时启动了事务，底层实现就会开始保存一个读取集和一个写入集 [^Her93]。这两个集合包含了事务已读取或更改的所有变量和状态。这对于以后提交前的完整性检查是必要的。此外，只要事务尚未完成，更改就不会应用到实际的共享变量上，而是应用到线程本地副本上，通常以事务日志的形式出现。一旦事务被验证为不冲突，其所有更改就会以原子方式刷新到实际共享状态。虽然这通常包含某种形式的锁，但这种行为对开发人员来说是完全透明的。为了检测冲突事务，STM 实现会在提交前将事务的读写集与实际状态进行比较。当另一个事务已经改变了某个状态并成功提交时，STM 会检测到差异并中止该事务。相反，旧的读写集会被丢弃和刷新，事务也会重新开始。在某种程度上，饥饿情况仍然会发生，特别是当一个长时间运行的事务不断被其他先成功提交的事务超越时。除此之外，STM 提供的互斥功能不需要显式加锁，也没有上述加锁问题的危险。

要代表一个有价值的并发模型，还需要其他功能。我们已经看到，基于锁的多线程缺乏对可组合性的支持。此外，我们还需要使用 STM 协调不同线程的机制。扩展的 STM 模型[^Har08]已经满足了这两个要求。事务的粒度允许将不同的事务操作粘合在一起，从而产生新的事务复合操作。可以使用 `retry` 和 `orElse` 等操作符实现更高级的组合。前一种操作符基于与监控器条件变量类似的概念。当一个运行中的事务检查到一个包含与预期值不同的状态的条件时，该事务可以通过调用 `retry` 来“让步”。借助读取集，底层运行时可以检测到哪些变量迄今为止已被访问过。一旦这些变量中的一个在其他事务中被修改，运行时就会恢复之前的事务，并检查条件是否为真。`orElse` 操作符允许组成两个或多个事务。当第一个事务通过重试调用收益时，下一个事务将被执行。从本质上讲，这些操作符在事务模型中引入了阻塞协调的概念。因此，事务现在可以等待事件发生，或在单个事务行为中包含替代控制流。

STM 有一些重要的局限性。由于 TM 事务仅限于内存操作，因此只能用于协调对共享状态的访问，而不能用于对外部资源的访问。此外，事务特性要求操作不可撤销，因此事务除了修改共享状态外，不得有任何副作用。例如，禁止在事务中使用 I/O 操作。

此外，事务的长度和冲突事务的比例也会对 STM 部署的性能产生持久影响。事务执行的时间越长，就越有可能引起冲突，至少在有很多冲突事务的情况下，必须中止事务。

不过，STM 对共享状态和线程的传统并发模型进行了有益的扩展，避免了锁定的负担。它允许在没有死锁危险的情况下组成并发操作。不过，在 STM 系统中仍可能出现争用和饥饿现象。前者往往是许多事务同时更改相同值的结果。当一个很长的事务与多个很短的事务持续竞争时，后者就会显现出来。

在使用乐观并发控制的情况下，只要没有很多并发和冲突的写操作，STM 就能提供合理的性能。

### TM VS 垃圾回收

对于基于锁的编程，TM 的理念和 STM 方法仍存在争议。批评者认为，STM 持续面临着一些挑战 [^Cas08]，这也是为什么迄今为止它仍主要受到学术界关注的原因。例如，如何处理对同一变量的事务性和非事务性访问，以及如何将变量私有化（即从事务性访问切换到线程本地访问），这些问题仍不明确。此外，要求代码无副作用的缺点也提出了一个问题：如何将无法定义为事务的代码纳入事务操作中。反对 STM 的最主要论据还是基于软件的事务处理实施所带来的性能开销。

支持 STM 的人反驳说，近期 STM 系统的性能已大幅提高，STM 已经是一种稳健的解决方案 [^Dra11]。各种实施方案也提出了不同的私有化方法。最后但并非最不重要的一点是，Clojure 的持续成功证明了较新 STM 实现的成熟性。Clojure 是第一种将 STM 作为第一类内置并发概念的编程语言。在 Clojure 之前，STM 实现主要是基于特殊单子的并发 Haskell 扩展。

在围绕 TM 的争论中，最有趣的概念可能是与垃圾回收的类比[^Gro07]。垃圾回收处理的是托管引用，而 TM 处理的是托管状态。这两个概念都是在运行时对内存进行操作，并将困难的工作从应用程序开发人员手中解放出来。与 TM 相比，当垃圾收集首次被提出来时，人们对它提出了非常类似的反对意见。此外，与手动内存管理相比，最初的垃圾收集器也存在明显的性能开销。不过，随着时间的推移，垃圾收集器已经得到了极大的改进，现在已经成为许多高级语言不可或缺的一部分。在不久的将来，共享内存模型将继续盛行，时间将证明这种类比是否会继续下去，TM 是否会成为共享状态并发的合理高层抽象。

### 案例研究：Clojure 中的并发性

Clojure 是一种在 JVM 上运行的编程语言，深受 Lisp 的影响。它非常注重函数式编程概念。Clojure 的另一个决定性特征是其精心设计的并发方法。事实上，并发编程是开发 Clojure 的主要原因之一[^Hic08]。与 Scala 一样，Clojure 也是建立在 Java 的基础上，并在内部使用 Java 的并发原语。Clojure 结合异步代理和成熟的 STM 实现，提供了非常强大的不变性概念。

为了理解这些概念之间的合作，有必要详细阐述 Clojure 的身份、状态、引用和值等概念。值是不可变的数据，永远不会改变。这在某种程度上甚至适用于命令式编程。例如，我们不会直接更改数值变量的值（即数字），而是会为该变量分配另一个值。但这并不影响旧值。面向对象编程通过统一身份和状态混淆了这一概念。在 Clojure 中，身份是“一个稳定的逻辑实体，随着时间的推移与一系列不同的值相关联”。换句话说，身份是一个与值有可变关联的实体，身份的状态由其在给定时间内的值决定。根据当前的状态，引用指向一个标识，而标识又指向一个值。状态变化是将标识重新分配给其他值。

虽然这对于数字等值来说不言自明，但 Clojure 也将这一原则应用于数据结构。当通过添加新元素来改变列表时，新值就是添加了新元素的旧列表。不过，旧列表仍保持不变。为了支持列表和映射等非原始数据类型的这一概念，Clojure 使用了所谓的持久化数据结构 [^Oka96]。在这种情况下，持久并不表示持久存储。相反，持久数据结构会保留其历史。持久化数据结构面临的主要挑战是如何高效地实现数据结构的多个版本而不产生冗余值。这种间接性是 Clojure 并发概念的一个重要特性，并能保持值的不变性。

Clojure 的运行时系统自动支持基于值和身份的状态更改。因此，Clojure 提供了四种不同类型的可变状态引用，它们具有不同的影响，如表 :autorefClojure 处理可变状态的基元 5.0 所示。`var` 引用基元类似于命令式编程语言中的传统变量，可以重新赋值给其他值。不过，`var` 仅是线程本地变量，其他线程无法访问。因此，状态是可变的，但不能共享。

|                  |             |              |
| :--------------- | :---------- | ------------ |
|                  | synchronous | asynchronous |
| **coordinated**  | `ref`       |              |
| **independent**  | `atom`      | `agent`      |
| **thread-local** | `var`       |              |

表 5.1：用于处理可变状态的 Clojure 基元

`atom` 引用基元与 Java 的原子实体非常相似。它们允许管理共享、同步、独立的状态。`atom` 的状态可以通过显式取消引用来访问。要改变值，有三种操作，即重置（设置新值）、交换（应用修改函数）和比较-设置（低级变体）。

ref 基元定义了可以通过解引用来访问的引用，以便进行读取操作。修改操作只能作为 STM 事务的一部分执行。Clojure 的 STM 实现使用了基于时间戳的并发控制机制 MVCC [^Ber81][^Ree78]。`dosync` 函数用于封装事务操作，其函数体中的所有函数调用都在同一事务中运行。`ref-set` 用于直接将 `ref` 设置为新值。`alter` 操作应用了一个实现 `ref` 状态交换的函数。`commute` 操作的工作方式与 `alter` 相同，但它意味着修改函数是换向的，从而有效地在内部允许更多并发性（使用事务内的值）。最后，`ensure` 会阻止其他事务为 `ref` 设置事务内值。这就避免了写偏移：多个事务读取重叠的数据集，但在进行不相关的修改时不会看到其他事务的变化。如前所述，事务不应包含具有副作用的操作，如 I/O 操作。这是因为 STM 的内部实现可能会中止和重试事务。

最后一个基元是 `agent`，它提供对可变状态的独立、异步和共享访问。代理隔离了可被线程读取访问的状态。线程还可以向代理发送操作（即修改函数）。然后，代理按顺序执行接收到的操作。对于动作的发送者来说，执行是异步进行的，而且每个 `agent` 的执行总是保证单线程运行。正如我们即将看到的，`agent` 的概念不同于 `actor` 的概念。代理在其内部状态上执行接收到的函数。因此，发送的函数定义了一种行为。代理提供自己的内部行为，并等待处理传入的不可变消息。

Clojure 迫使开发者明确标注可变状态。否则，状态根本无法修改。只有这样，Clojure 应用程序才会更加健壮，因为它能防止意外和非预期的可变性。它要求开发人员为状态处理选择合适的并发基元。

[Avout](http://avout.io/) 是 Clojure 的外部贡献，它提供了基于 [Apache ZooKeeper](http://zookeeper.apache.org/) 的分布式 MVCC STM 实现，用于协调。它支持在多个（远程）JVM 实例之间使用 `atom` 和 `ref` 基元。

一个用 Clojure 编写的简约并发网络应用程序，可返回目前已处理的请求数：

```clojure
(ns counting.server
  (:use noir.core)
  (:require [noir.server :as server]))

(def counter (ref 0))

(defpage "/" []
	(dosync (commute counter inc))
    (str @counter))

(server/start 8080)
```

前面的列表为我们之前的网络应用程序示例提供了一个基于 Clojure 的解决方案。该解决方案利用了 [noir web 框架](http://webnoir.org/)，而该框架又使用了 jetty 网络服务器。该简约应用程序定义了一个 `ref` 类型的计数器，并注册了一个用于处理请求的函数。每次请求时，该函数都会在 `dosync` 块中执行一个 STM 事务。在这种情况下，会使用 `commute` 操作，以事务方式递增计数器的值。通常情况下，使用 `alter` 方法代替 `commute` 操作。不过，增量操作是换向操作，因此使用 `commute` 操作可能会加快事务执行速度。事务完成后，`counter` 的值会被取消引用（@），转换成字符串并作为响应返回。我们特意在外部而非实际事务内部取消引用 `counter ref` 的值，是为了演示对 `ref` 进行非事务读取访问的可能性（这会产生一个短暂的窗口，在这个窗口中，`counter` 的值可能已被另一个请求更改）。与前面的 Java 示例一样，使用 Clojure 原子会更优雅，因为计数器是唯一要修改的变量。

### 用于并发应用逻辑的 STM

与之前基于锁的方法一样，使用 STM 的应用服务器也会将请求映射到线程。我们已经看到，当 I/O 绑定操作占主导地位时，这种方法变得越来越不合适。STM 并不能解决这个问题，事实上，它根本不允许在事务内部进行 I/O 操作。不过，当状态在应用服务器中共享时，STM 可以支持并发应用逻辑。根据应用的类型，应用状态可能会被分片并隔离到几个不同的服务器上（例如，在不同服务器上托管小方块的多人游戏），或者必须提供给所有应用服务器（例如，社交网络应用中的即时消息通知）。在后一种情况下，分布式 STM 变体允许进行分发。当 STM 实现提供与条件变量类似的机制时，也支持作为事务一部分的线程间协调。

因此，由于没有显式锁定，STM 使应用服务器内的共享状态更易于管理，但并不能解决 I/O 绑定并行化问题。

## 基于 Actor 并发

我们迄今考虑过的并发模型都有共享状态的概念。多个线程可以同时访问共享状态，因此必须通过加锁或使用事务来保护共享状态。状态的可变性和共享性不仅是这些模型的固有特性，也是复杂性的固有特性。我们现在来看看一种完全不同的方法，它完全禁止共享状态的概念。状态仍然是可变的，但它只与允许改变状态的单个实体（即所谓的行动者（actors））相关联。

### Actor 模型

actor 模型是并发建模和消息传递概念的理论基础[^Hew73]。它的核心思想是利用 actor 作为并发原语，这些 actor 能够在接收到消息时以不同的方式行动：

- 向其他 actor 发送有限数量的消息。
- 生成有限数量的新 actor。
- 改变自己的内部行为，这种改变将在处理下一条进来的消息时生效。

在通信方面，actor 模型采用异步消息传递。特别是，它不使用任何中间实体，如通道。相反，每个 actor 都拥有一个邮箱，并且可以被寻址。这些地址不应与身份混淆，每个 actor 可以没有、一个或多个地址。当 actor 发送消息时，必须知道接收者的地址。此外，actor 被允许给自己发送消息，这些消息将在未来的某个步骤中被接收和处理。请注意，地址和 actor 的映射不是概念模型的一部分（尽管它是实现的一个特性）。

![](./asserts/actors.svg)

图 5.3：由多个 actor 组成的网络示例。每个角色都有自己的邮箱和独立状态。根据其指定行为，行为体通过发送新信息、产生新行为体和/或改变其未来行为来响应传入信息。

信息是异步发送的，最终到达接收者邮箱的时间可以任意延长。此外，**actor 模型不保证消息的排序**。在邮箱中排队和取消排队都是原子操作，因此不可能出现竞赛条件。行为体利用上述可能性按顺序处理从其邮箱收到的信息，并做出反应。第三种可能性是改变自己的内部行为，最终可以处理可变状态。不过，新 actor 只有在当前消息处理完毕后才会应用。因此，从概念角度来看，每次消息处理运行仍然是无副作用的操作。由于每个行为体完全独立于其他实例，因此行为体模型可用于对固有并发系统进行建模。如图 5.3 所示，没有共享状态，角色之间的交互完全基于异步消息。

### 并行编程的 actor 实现

除了并发系统的理论模型外，actor 的概念还代表了并发编程模型的蓝图。从严格的函数式适应到面向对象范式的扩展[^Gue07]，人们已经考虑了几种概念实现[^Agh90]。Erlang [^Vin07]是第一种相当流行的编程语言，它采用了并发的 actor 模型。最近，actor 模型越来越流行，并进入了许多新的编程语言，而且通常是作为一流的语言概念。在许多其他语言中，可以使用建立在传统多线程基础上的第三方库来使用行为模型。

在实施 actor 模型时，必须遵守最初想法所定义的一系列规则。首先，actor 不得共享任何状态。这就禁止 actor 传递引用、指针或任何其他类型的共享数据作为消息的一部分。只能发送不可变的数据和 actor 地址（即“名称”）。与完全尽力而为的方式相比，actor 之间的消息传递通常有更多的保证。大多数实现都能确保从一个 actor 发送到另一个 actor 的两条信息在到达时保持顺序。消息传递总是异步的，多个 actor 发送的传入消息的交错是不确定的。

对于消息处理，大多数实现都提供模式匹配。这使开发人员能够区分不同类型的消息，并提供与消息类型相关的不同处理代码。从 actor 的角度看，接收消息是一个阻塞操作，而发送新消息则始终是非阻塞的。有些实现还提供了选择性接收语义。根据其行为，actor 可以等待邮箱中的特定信息，并暂时推迟其他信息的接收。

底层运行时平台必须为数量有限的 CPU 内核和资源分配可能数量巨大的 actor，并安排有待处理消息的 actor 的执行时间。大多数系统主要采用无锁实现，因为只有邮箱操作才需要原子行为。例如，Erlang 虚拟机会启动一个进程，并根据可用内核的数量生成一个线程池[^Lar08]。内部调度器在进程队列中组织 actors，并抢先工作。当一个运行中的 actor 处理完一条消息或执行了一定数量的还原（即函数调用）后，调度器就会切换到下一个准备运行的 actor。对于 I/O 操作，Erlang 虚拟机会生成解耦的操作系统线程。缩减限制和后台 I/O 操作促进了公平性和及时性，因为任何 actor 都不能在较长时间内绑定 CPU 时间。

许多 actor 模型的实现提供了额外的功能，这些功能也是 actor 模型的延伸，即分布支持和容错。并发概念通常以单机为目标。actor 模型并没有为消息传递提供很多保证。异步、无限制的消息传递实际上类似于基于网络的通信。actor 的状态隔离不需要多个 actor 实例之间的共享访问。actor 使用地址指定，可以轻松提供位置透明度。`actor` 模型本质上是并行的，因此很容易扩展 actor 模型的实现，以支持分布式部署。例如，分布式 Erlang 系统利用运行 Erlang 虚拟机的多个节点，透明地提供分布式消息传递。

传统的、基于线程的并发给容错带来了困难。非确定性和不可预测的调度与共享状态和锁定相结合，需要非常复杂的复制和快照策略。actor 模型提供了其他基元，使复制变得更加容易。在 actor 邮箱中排队的隔离状态和传入消息与快照和日志非常相似。actor 的消息处理是单线程的，并提供了隐式让开点。Erlang 奉行“让崩溃发生”的理念 [^Arm07]。actor 孤立、无共享的特性允许单个 actor 发生故障而不影响其他任何行为体。此外，actor 模型本身也可用于容错，通过生成 actor 的层次树来进行监督。一旦某个 actor 崩溃，监管 actor 就会收到消息并做出反应。监管者可能会重新启动 actor、停止其他 actor 或通过向自己的监管者发送错误信息来升级。

actor 对状态具有隔离作用，可有效防止共享可变状态。此外，并发编程不需要锁。不过，在这种编程模型中，死锁和竞赛条件等并发问题仍未完全消除，因为不正确的应用程序可能会重新引入这些问题。两个 actor 互相等待一条消息，这代表了一种循环依赖关系。在实践中，可以通过使用超时来防止即将发生的死锁。一些开发人员可能会将 actor 发送消息的任意排序解释为传统的竞赛条件。然而，这是 actor 模型的一个特征属性，证明了异步性。因此，这些开发人员忽视了 actor 模型的基本思想，由此产生的“竞争条件 ”实际上是不恰当的应用程序设计的表现。

### Actor 编程

actor 模型的并发性与基于线程的锁或 STM 并发性截然不同。隔离的可变状态和异步消息传递产生了与线程不同的其他编程模式。

首先，我们必须明白，与线程相比，actors 代表了非常轻量级的基元。它们可以以最小的开销生成和销毁。因此，并行创建和使用大量实例是完全可行的。actor 还可以根据消息执行任意复杂的计算。actor 可以向自己发送消息，这样就可以使用消息模式来重现递归。此外，actor 还可以向地址已知的其他 actor 发送消息，因此基于 actor 的程序本质上是一个高度动态的 actor 网络（有向图）。因此，现有的基于消息的应用集成模式[^Hoh03]提供了一套全面的模式，也可用于 actor 并发编程。这包括用于路由、过滤、转换和组合的流行消息模式。

隔离可变状态并强制执行不可变消息可保证隐式同步。然而，异步消息传递和无全局状态的概念对协调性提出了挑战。应用程序可能需要在多个参与者之间达成共识或一致的状态视图。当多个参与者必须严格协调以提供不同的应用功能时，正确的消息传递就会变得非常苛刻。因此，许多实现提供了更高层次的抽象，根据复杂的消息流实现低层次的协调协议，但向开发人员隐藏了内部的复杂性。对于 Erlang 而言，OTP 是一个标准库，包含丰富的抽象、通用协议实现和行为。

另一种常见的方法是事务处理器。例如，多个 actor 可能需要以协调的方式修改其内部状态。在这种情况下，作为协调多个角色事务操作的专用角色的事务处理器，可以通过提供抽象事务逻辑来提供帮助。一些事务处理器还将 STM 概念应用于事务处理行为 [^Les09][^Les11]。

### 案例研究：Scala 中的并发性

Scala 是一种在 JVM 上运行的通用对象函数式语言。它与 Java 兼容，但提供了更强的表达能力、高级编程概念和函数式编程的许多功能。在并发性方面，Scala 实现了基于 actor 的并发模型，并支持值的显式不变性。不过，Scala 应用程序也可以使用 Java 编程语言的并发原语。

Erlang 会产生多个底层线程，并为运行的 actor 实现自定义调度程序，而 Scala 则会受到 JVM 的多线程影响。此外，Scala 的角色实现并不是语言核心的一部分，而是其标准库的一部分。这意味着 actor 库本身就是在 Scala 中实现的。Scala actor最初面临的一个挑战是 JVM 中的多线程限制。可能的线程数量有限，没有可用的协同调度，而且从概念上讲，线程没有 actor 那么轻量级。因此，Scala 提供了单一的角色概念，但却提供了两种不同的消息处理机制 [^Hal06][^Hal08]。

- **基于线程的 Actors**

  当使用 `receive` 原语时，actor 由一个专用线程提供内部支持。这显然限制了可扩展性，并要求线程在等待新消息时暂停和阻塞。

- **基于事件的 Actors**

  `react` 原语允许采用事件驱动的执行策略，它不会直接将 actor 与线程耦合。相反，一个线程池可用于多个 actor。这种方法使用延续闭包来封装 actor 及其状态。然而，这种机制有一些局限性，而且会掩盖控制流[^Hal08]。从概念上讲，这种实现方式与线程池支持的事件循环非常相似。actor 代表事件处理程序，消息则类似于事件。

一般来说，`react` 更受青睐，因为它不会将每个 actor 与专用线程耦合。因此，`react` 原始码能产生更好的可扩展性。

Scala 消息 actor 的语法遵循 Erlang 风格。消息应该是不可变的值，但目前还没有强制执行。通常会使用 case 类，这是一种特殊的封装类。当使用模式匹配来确定消息到达时的类型时，它们尤其有用。Scala 还通过提供远程 actor（通过 TCP/IP 通信并依赖于 Java 序列化）来支持 actor 的分发。

下面的列表展示了我们之前示例的网络应用中基于 actor 的解决方案。该解决方案是用 Scala 编写的，并使用了 [Play 网络应用程序框架](http://www.playframework.org/)。该框架并没有使用常规的 Scala 角色，而是使用了 [akka 库](http://www.akka.io/)提供的 actor 实现。如下图所示，应用程序启动了一个 actor，并注册了一个用于处理请求的方法。该方法会向 actor 发送一条异步的“访问”消息。通过使用 `?` 操作符，将返回一个代表最终回复的 `Future`。如果没有发生超时，则 actor 的回复一旦可用，就会被用作 `SimpleResult` 的响应体。如下表所示，`CoutingActor` 的内部结构非常简单。该 actor 提供了一个计数器变量，并通过递增该值来响应“访问”消息，然后将其发送回原始发送者。

基于 akka 行为器实现的 scala actor。该 actor 封装了一个计数器状态，并通过返回迄今为止的总访问次数来响应每个“访问”消息：

```scala
package actors

import akka.actor.Actor
import Actor._

class CoutingActor extends Actor {

	var count = 0;

	def receive = {
		case "visit" => 
			count = count+1
			sender ! ""+count 
	}
}
```

一个用 Scala 编写的简约并发网络应用程序，使用 Play 网络框架返回迄今为止处理的请求数：

```scala
package controllers

import akka.util.Timeout
import akka.pattern.ask
import akka.actor._
import akka.util.duration._
import actors.CoutingActor
import play.api._
import play.api.mvc._
import play.api.libs.concurrent._
import play.api.libs.iteratee.Enumerator

object Application extends Controller {

	val system = ActorSystem("counter")
	val actor = system.actorOf(Props[CoutingActor])

	def index = Action {
		AsyncResult {
			implicit val timeout= Timeout(5.seconds)
			(actor ? "visit").mapTo[String].asPromise.map { result =>
				SimpleResult(
					header = ResponseHeader(200, Map(CONTENT_TYPE -> "text/plain")), 
					body = Enumerator(result)
				)		   
			}
		}    
	}
}
```

### 并发应用逻辑的 Actors

当应用服务器使用 actor 模型时，每个传入的请求都代表一个新的 actor。为了实现请求操作的并行化，actor 会产生新的 actor，并通过消息分配工作。这就实现了并行 I/O 绑定操作和并行计算。通常情况下，单个请求流或多或少代表了多个 actor 之间复杂的消息流，使用的消息传递模式包括分散/收集、路由器、充实器或聚合器[^Hoh03]。

然而，使用 actor 实现请求逻辑与顺序请求逻辑实现明显不同。多个 actor 之间的必要协调以及异步消息传递所导致的不太明显的执行流，为并发提供了一个可以说不太舒适但却更现实的抽象。

actor 模型的另一个特点是可以通过添加新机器来扩展整个角色系统。例如，Erlang 使虚拟机能够催生分布式系统。在这种情况下，远程 actor 可以持有孤立的应用状态，但整个系统的所有其他角色都可以通过消息传递访问这些状态。