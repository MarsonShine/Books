# 应用程序和业务逻辑的并发概念

上一章节，[第 4 章](webserver-architectures-for-highconcurrency.md)，讨论了作为 Web 服务器问题的连接并发性。这个挑战的特点是大量的 I/O-bound 操作，但可变状态非常有限。在本章中，我们从一个不同的角度来看待并发性，即专注于应用服务器。也就是说，负责执行应用程序实际业务逻辑的组件，由传入的请求激发。

在大规模 Web 架构中，请求的固有并行性是不可避免的。多个用户同时访问应用程序，创建大量的独立请求。因此，应用服务器是必须处理高度并发的组件。我们在本章中想要处理的主要问题是，当用于应用服务器的业务逻辑时，不同并发范式的含义和后果。这不仅包括处理并发应用程序中状态的影响，还包括特定范式对开发者的简单性和可访问性。

此外，我们不专注于特定的应用服务器实现或 Web 应用程序框架。相反，我们更一般地与并发性和并发编程的范式进行较量。这些反思适用于一般的分布式和并发编程。最终，我们在寻找一种适当的编程抽象，用于应用程序固有的并发性，这不仅允许我们开发可扩展和高性能的应用程序，同时也能在一定程度上驯服并发性的麻烦。

## 概览

应用服务器提供了一种响应式行为，能够根据传入请求生成响应。这个应用服务器组件通过高级消息（或者是远程过程调用 RPC 或类似机制）从上游 Web 服务器接收调用。因此，它与底层的连接处理或请求解析职责解耦。为了生成适当的响应，应用服务器执行与请求 URI 映射的业务逻辑。在应用服务器内部，一个请求的执行流程包括与不同的架构组件交互，如数据库和后端服务，但也包括作为应用逻辑一部分的计算操作：

- **CPU-bound 活动**
  CPU-bound 活动是那些在执行过程中主要消耗 CPU 时间的任务。通常，这些任务是在内存数据上操作的计算密集型算法。就 Web 应用而言，这适用于例如输入验证、模板渲染或即时编码/解码内容等任务。

- **I/O-bound 活动**

  I/O-bound 活动是主要受 I/O 资源限制的任务，如网络 I/O 或文件 I/O。当任务操作的是尚未（或尚不）属于其自身内存的外部数据时，通常会发生 I/O-bound 活动。在我们的架构模型中，这包括访问大多数平台组件，包括存储后端、后台服务和外部服务。

![](./asserts/req_para.svg)

图 5.1：请求处理的执行流程。应用服务器首先查询缓存，然后分派两个独立的数据库查询，最后再次访问缓存。在左侧，执行是严格按顺序进行的。在右侧，独立操作被并行化，以改善延迟结果。

对于 Web 应用的一个请求，通常会触发这两种类型的操作，尽管实际的比例取决于应用的内部结构。许多内容丰富的 Web 应用（例如博客、维基）主要依赖于数据库操作，以及在一定程度上依赖于模板渲染。其他应用主要是 CPU-bound，如提供计算服务的 Web 服务或媒体文件转换的 Web 服务。在这两种情况下，都偏好低延迟的响应，因为它们对于良好的用户体验很重要。

与请求相关的应用逻辑通常以顺序方式实现。为了最小化延迟，应考虑并行化独立操作，如图 5.1 所示。在有向图表示中，第一个节点代表请求的到达，最后一个节点代表编译好的响应。中间的节点代表操作，如数据库操作或计算函数。控制流的分割导致并行操作，这些操作必须在稍后同步。这种模式，也称为 scatter and gather，特别适用于 I/O-bound 活动，如数据库操作和访问其他架构组件（网络 I/O）。

![](./asserts/req_coord.svg)

图 5.2：作为交互式网络应用程序一部分的待处理请求之间的协调。用户 A 的浏览器通过长时间轮询不断发送通知请求。一旦用户 B 发布了新信息，网络应用程序就会协调通知并响应两个待处理请求，从而有效地通知用户 A。

此外，请求处理可能包括与其他请求的协调和通信，这可以通过使用外部消息组件，或使用应用服务器组件的内置机制来实现。例如，对于协作性、交互性和 Web 实时应用来说，这是必需的。然后，将发送专门的请求，使服务器最终能够在稍后时间，由其他请求的行为或其他服务器端事件触发时发送响应。

本质上，现代 Web 应用利用的并发属性与早期应用中完全隔离的请求的概念不同，如图 5.2 所示。应用状态不再完全保存在数据库系统内，但在一定程度上也在其他组件中共享，甚至可能在请求之间共享。协作和交互功能以及对低延迟的需求不再允许避开同步和协调。相反，必须拥抱真正的并发性，以适应 Web 应用的应用逻辑。在本章的剩余部分，我们将研究不同的并发编程方法以及它们如何管理状态、协调和同步。然后，我们将检查并发 Web 应用如何利用这些概念。

## 基于线程、锁和共享状态的并发

命令式编程，作为结构化编程最受欢迎的形式，围绕着顺序执行和可变状态的概念构建。它直接源自冯·诺依曼架构的概念。线程通常被视为这一概念的一个延申扩展，它们使得可以同时进行多个控制流。与较重的进程相比，线程是操作系统和硬件架构提供的并行主要构建块（即超线程）。不出所料，线程是大多数编程语言中并发的主要构建块。然而，基于线程、锁和共享状态的并发编程被认为是困难且容易出错的[^Sut05]。

### 共享和可变状态的含义

从概念上讲，线程描述了一个顺序的控制流，乍一看它与其他活动是隔离的。但与进程不同的是，线程共享同一地址空间。这意味着多个独立的线程可能会同时访问同一变量和状态。更糟的是，顺序编程建立在可变状态的概念上，这意味着多个线程也可能竞争写操作。**多线程主要使用抢占式调度**。结果，多个线程之间的切换和交错是未知的。这代表了一种强烈的不确定性形式。如果不加以处理，可变状态和不确定性就会引入竞态条件的严重风险。

当两个或多个线程竞争访问临界区时，就会发生竞态条件，临界区包含了线程之间共享的状态。由于可能的交错种类繁多，竞态条件可能导致各种不一致的状态。例如，一个线程可能读取到过时的状态，而另一个线程已经在更新它。当多个线程同时更改状态时，要么其中一个更改持续存在而其他更改丢失，要么可能持续存在一个受多次更改影响的不一致状态。最终，我们需要机制来保护临界区并强制同步访问。

### 锁机制

同步的一般原语是锁，它控制对临界区的访问。有不同类型的锁，具有不同的行为和语义。信号量是简单的锁，提供等待(`wait`)和信号(`signal`)功能。在进入临界区或使用共享资源之前，必须调用等待函数。一旦通过了临界区，就使用信号释放它。通过在 `wait` 调用中阻塞其他竞争者，`semaphore` 可以防止多个线程同时获取该 `semaphore`。其他标识符实现，即所谓的计数标识符，允许一定数量的线程通过。因此，二进制寄存器可视为仅限于单个活动线程的计数寄存器。其他互斥结构提供了所有权的概念，这意味着临界区段暂时由一个不同的线程拥有，该线程也是唯一能在稍后解锁临界区段的实例。

更高级的互斥构造是监视器，它使用条件变量以模块化方式保护部分。通常，这些部分的粒度为对象，或方法/函数。内部条件变量允许一个阻塞的线程暂时让出并等待其他线程触发的条件修改。锁机制的一个属性是**可重入性**。当锁支持可重入性时，已经获得某个锁的线程可以再次通过该锁。这对于可能重复访问临界区的递归函数来说是一个重要属性。除了计数锁，还有区分不同访问语义的锁。读/写锁允许读取线程的共享访问，但对要求写访问的线程提供独占访问。

### 锁的后果

锁允许我们序列化对关键部分的访问。互斥的使用使临界区段内的线程具有原子行为，因为对于其他等待的线程来说，它的执行是一个单一的操作。识别易受竞赛条件影响的代码段，并谨慎地在其周围加锁，可以抑制不确定性，并实现序列化访问。

然而，锁的概念引入了另一个多线程代码的危险。当获得的锁未被释放或要获得的锁永远不可用时，不正确的锁定实际上可能会破坏应用程序。很明显，当开发人员必须明确地将 `wait` 和 `signal` 函数置于保护部分时，就会发生错误锁定。更高级的抽象，如监视器，通常提供手段来标记整个代码段以进行互斥，并隐式获取和释放锁。然而，它们仍然可能遭受锁定问题。最臭名昭著的锁定问题是所谓的死锁。当两个或多个线程以循环依赖的方式竞争锁时，就会发生死锁。在最简单的情况下，两个线程都拥有一个单独的锁，但还需要获得对方线程的锁。由于没有线程能够在不获取第二个锁的情况下前进，因此两个线程都被阻塞，无法继续。

其他锁定问题包括活锁和锁启动。与死锁类似，活锁也会阻止线程继续运行。不过，线程在活锁情况下不会被阻塞。相反，它们会随着其他相关线程的状态变化而稳定地改变状态，反过来，这些线程也会改变状态。在一个示例场景中，两个线程必须获得两个资源才能继续运行。当它们无法同时获得两个资源时，它们会返回第一个资源，然后重新尝试获得两个资源。当两个线程同时开始获取第一个资源，然后又重新启动时，就会出现活锁。活锁可视为饥饿的一种特殊情况。它一般描述的是线程因其他贪婪的线程不断索取锁或资源而反复无法获取锁或资源的情况。

尽管一些饥饿问题，如活锁，可能在运行时使用随机回退进行重试来处理，但由于非确定性，潜在的锁定问题通常非常难以检测。当使用细粒度的多个锁时，死锁的风险增加。因此，通常建议使用粗粒度的锁以避免死锁。识别大的临界区并用锁保护它们不仅确保了序列化访问。事实上，粗粒度的锁导致线程最终顺序执行。这与我们之前增加并行性的目标相反。

为了具有真正的硬件并行性，我们需要选择非常细的锁粒度，使得多个线程可以在独立的临界区中继续进行。许多小的临界区不仅增加了锁管理的开销，因为锁定管理并非免费。然而，锁的广泛使用强调了上述危险的风险。显然，选择正确的锁粒度并不容易。

除了活锁、死锁和锁饥饿的问题外，锁在实践中还有另一个困难。给定多段代码，这些代码的临界区受到锁的保护，我们不能保证这些代码的组合不会导致死锁。本质上，我们不能在没有新的锁定问题风险的情况下组合线程安全的实现。这对于较大的代码片段，如框架组件或模块，尤其重要。锁定问题可能通过坚决的开发政策来解决，这些政策严格规定了锁的使用、获取顺序和条件。然而，这些政策不能以编程方式强制执行。此外，当使用外部或闭源组件时，确保正确锁定变得不可能。

尽管如此，基于线程、共享状态和锁定的并发编程仍然是主流，并且在大多数语言中都可用。重要的是要认识到，这种方法代表了并发的低级概念。它比我们很快就会看到的其他概念更接近裸机。然而，所有这些概念仍然在底层使用线程。

### 案例研究：Java中的并发

Java 编程语言从其存在之初就提供了基于线程的并发。它实现了 Mesa 监视器用于锁定和互斥，并提供了语言核心的几个同步原语。并发行为在 Java 语言规范中定义，该规范详细描述了 JMM。Java 的一致性基于发生前顺序和隐式内存屏障的概念。然而，它并不为线程提供顺序一致性，正如许多开发者错误地假设的那样。事实上，JMM 类似于对称多处理，其中多个 CPU 拥有自己的缓存，但共享一个公共主内存。当 CPU 访问内存时，它们刷新自己的缓存并最终刷新更改。从比喻的意义上讲， Java 线程类似于 CPU，主内存是线程之间的共享内存，CPU 缓存是线程本地的数据副本。刷新或刷新的过程代表了所谓的内存屏障的穿越。除了上述排序外，JMM 还根据内存屏障定义了哪些操作不能被其他线程中断（原子性），以及何时变更必须传播给其他线程（可见性）。例如，启动和结束线程或使用同步原语会触及内存屏障，但也会触及对几个具有特定特性的变量的访问（见下文）。

`synchronized` 关键字使用给定对象作为监视器来保护整个方法或一个独特的代码块。Java 监视器是可重入的，支持递归调用。此外，每个 Java 对象都可以用作监视器，因此提供了条件信号的手段。`wait()` 方法阻塞持有监视器的线程并释放监视器，以允许其他线程继续并更改条件。在这种情况下，其他线程可以使用 `notify()` 和 `notifyAll()` 向等待线程发出信号。

`volatile` 关键字规避了变量的线程本地拷贝，并在每次访问时强制从共享内存中获取新副本。它只能用于单个原子操作。例如，增加值（多次操作）不是原子的。`final` 关键字使变量不可变。不可变值对并发的好处是避免了刷新值的需要，因为它们不能再被更改。建议始终将字段设置为 `final`，除非有不这样做的理由。此外，Java 提供了一组原子实体（`java.util.concurrent.atomic`），类似于 `volatile` 变量。然而，这些实体是对象，确保所有操作的原子性，并使用内部非常高效的机制，如比较和交换（compare and swap,cas）。

活动由 `Thread` 类表示，该类提供了诸如 `start()` 之类的线程处理方法。这个类还有几个协同方法，如 `resume()` 和 `stop()`，不幸的是这些方法被破坏了，不应该使用。`Runnable` 接口从 `Thread` 类中抽象出来，只拥有一个 `run()` 方法，一旦线程启动，最终由线程执行这个方法。

虽然这是 Java 中并发编程的基础，但从 Java 5 开始引入了几种高级抽象，主要是为了促进并发应用程序的开发。显式锁（`java.util.concurrent.locks`）提供比同步的隐式监视器锁更广泛的锁定操作（例如，读写锁）。并发集合，如`ConcurrentMap` 或 `BlockingQueue`，扩展了现有集合，并提供线程安全操作以及协调访问的操作。`Runnable`、`Callable` 和 `Executor` 框架提供了另一种抽象。本质上，这些类将要执行的任务与实际执行它们的实体解耦。与线程池实体（例如`ExecutorService`）结合使用，这是许多并发应用程序的非常有用的抽象。`Futures` 允许在另一个线程中异步执行 `Callable`，立即返回最终结果的代理对象。对于线程之间更复杂的协调，提供了几种高级协调原语。这包括显式计数 `semephore`、`CountDownLatch`（由倒计时触发的屏障）和 `CyclicBarrier`（用于线程重复协调的屏障）。在 Java 7 中，引入了 fork/join 框架[^Lea00]。该框架旨在通过产生子任务并使用分而治之的策略，轻松并行化计算密集型任务。它提供了隐式任务协调并采用工作窃取。

下面的清单显示了一个用 Java 编写的示例 Web 应用程序，使用 [jetty](http://jetty.codehaus.org/jetty/) 和 [Java Servlets](http://www.oracle.com/technetwork/java/javaee/servlet/index.html)。在启动时，`CountingRequestHandler` 被实例化一次。请求在内部通过线程池处理，因此并发请求可能触发 `CountingRequestHandler `的 `handle()` 方法的同时调用。每个线程都访问共享变量 `count`，因此必须使用 `synchronized` 块进行保护。这演示了监视器的使用（在这个特定案例中，使用 `AtomicLong` 类将代表一个更优雅和高效的解决方案）。

一个用  Java  编写的简约并发网络应用程序，可返回目前已处理的请求数：

```java
import java.io.IOException;
import javax.servlet.ServletException;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import org.eclipse.jetty.server.Request;
import org.eclipse.jetty.server.Server;
import org.eclipse.jetty.server.handler.AbstractHandler;

public class CountingRequestHandler extends AbstractHandler {
	
	//Variable for counting requests handled so far
	private long count = 0;
	
	public void handle(String target, Request baseRequest, 
			HttpServletRequest request, HttpServletResponse response)
			throws IOException, ServletException {
		
		response.setContentType("text/plain");
		response.setStatus(200);
		baseRequest.setHandled(true);
		
		final long current; 
		//Access and modification of a variable shared between threads.
		synchronized (this) {
			current = ++count;
		}
		
		response.getWriter().println(""+current);
	}

	public static void main(String[] args) throws Exception {
		Server server = new Server(8080);
		server.setHandler(new CountingRequestHandler());

		server.start();
		server.join();
	}
}
```

### 多线程和锁用于并发应用逻辑

在多线程应用服务器中，每个应用请求被分配一个专用线程来处理。只要不需要与其他线程之间的协调，这种编程模型非常简单。隔离视图使得将请求逻辑编程为一系列操作变得容易。此外，当请求主要执行 CPU 绑定操作时，这种方法是一个有效的选择。当请求逻辑包含 I/O 绑定操作时，延迟通常隐藏在服务器内部，因为有多个请求需要同时处理。然而，这并不加快单个请求的处理速度，它只增加了服务器的总吞吐量。为了减少单个请求的实际延迟，我们需要进一步并行化单个请求的操作。额外的线程有助于同时执行更多工作，只要操作是独立的，因此可以并行运行。实际上越多的操作是 I/O 绑定的，我们就越多地遇到[第 4 章](webserver-architectures-for-highconcurrency.md)中看到的同样问题。使用更多线程来并行化 I/O 会因为重度**上下文切换**和高**内存消耗**而导致问题。在我们的架构中，服务是通过网络访问的分离组件，这导致了对 I/O 绑定操作的强烈关注。本质上，通过并行化工作可以减少延迟，但这通常对 CPU 绑定操作更有效。对于 I/O 绑定操作，这种方法并不很好地扩展。

关于请求之间的协调问题，我们已经看到，可以使用锁定并辅以条件变量来协调线程。然而，在应用服务器中，锁定的困难和传入请求的强烈非确定性使得实现完全正确的请求间协调模式相当困难。相反，更可取的做法是依赖外部的 pub/sub 消息组件（如 redis），尽管这仍然会阻塞线程。同样，建议使用外部设施（如键/值存储）在请求之间共享状态，以规避应用服务器内部的显式锁定。这种方法的另一个优点是可以通过实例化新的应用服务器来实现透明的扩展。

## 通过软件事务存储器实现并发性

我们已经看到，基于锁的并发有几个缺点。不确定性和共享状态要求防止出现竞争条件。锁的概念要求开发人员通过明确放置锁来保护关键部分。反过来，由于锁的顺序和不确定性，这可能会在运行时产生不可预测的锁定问题。此外，使用锁时，并发代码的可组合性也得不到保证。

我们现在研究另一种方法，它仍然建立在共享状态和锁的概念上，但不依赖开发人员的推理来正确加锁。相反，加锁成为底层运行环境的一部分，编程语言为并发代码段提供了更高的抽象。

### 事务内存

共享状态并发的无锁替代方案是 TM。它可以追溯到计算机科学中一个著名的概念--事务。并发但隔离的操作是数据库系统的既定概念 [^Hel07]。TM 继承了这一理念，并将其应用于共享状态并发[^Her93]。数据库事务对数据库行进行读写，而 TM 事务则对与其他线程共享的状态进行读写。TM 的概念有多种实现方式。HTM 提供了 TM 的硬件实现，通过事务缓存和扩展指令集等事务组件扩展了 CPU 架构。STM 不需要对硬件进行任何改动，完全通过软件支持事务处理。混合事务处理技术本质上是一种 STM 实现，它利用了不断进步的硬件对事务处理技术的支持。由于 HTM 的开发和实施成本较高，TM 主要以 STM 的形式提供。不过，有些人认为，一旦这种编程模型建立起来，混合模型最终可能会出现[^Cas08]。

传统的事务（见[第 6 章](concurrent-scalable-storage-backends.md)）即原子性、一致性、隔离性和持久性。因此，事务表现为单一操作，在尚未提交或中止的情况下不会产生不一致的状态。它们也不会干扰其他正在进行的事务，其结果总是被持久化的。需要注意的是，这种持久性与数据库系统和事务管理（TM）的事务不同。后者只将事务结果保存在内存中，但不从应用崩溃中恢复状态。由于这些属性，事务是可串行化的。事务的结果可以通过等效的顺序执行看似原子的操作来复现。事务的并发控制可以是悲观的或乐观的。悲观并发控制强制对资源进行保守锁定，导致事务吞吐量低。乐观并发控制将事务的完整性检查延迟到事务结束时。如果出现冲突，事务将被中止并重启。当事务不是长时间运行且不太频繁地发生冲突时，乐观并发控制提供了非常好的性能，重试的开销可以忽略不计。

### 软件事务内存

现在我们将只关注 STM，因为已经有几种实现方法可供使用。优化并发控制是现有 STM 实现的首选。为了将 STM 概念集成到语言中并实现底层的 STM 运行时，我们必须认识到在语言层面需要哪些构造。一方面，我们需要一种将代码部分标记为事务的方法。另一方面，我们可能需要区分线程间共享的变量和资源（需要事务调用语义）和非事务的线程本地变量。否则，任何读写操作都会导致事务。

一旦在运行时启动了事务，底层实现就会开始保存一个读取集和一个写入集 [^Her93]。这两个集合包含了事务已读取或更改的所有变量和状态。这对于以后提交前的完整性检查是必要的。此外，只要事务尚未完成，更改就不会应用到实际的共享变量上，而是应用到线程本地副本上，通常以事务日志的形式出现。一旦事务被验证为不冲突，其所有更改就会以原子方式刷新到实际共享状态。虽然这通常包含某种形式的锁，但这种行为对开发人员来说是完全透明的。为了检测冲突事务，STM 实现会在提交前将事务的读写集与实际状态进行比较。当另一个事务已经改变了某个状态并成功提交时，STM 会检测到差异并中止该事务。相反，旧的读写集会被丢弃和刷新，事务也会重新开始。在某种程度上，饥饿情况仍然会发生，特别是当一个长时间运行的事务不断被其他先成功提交的事务超越时。除此之外，STM 提供的互斥功能不需要显式加锁，也没有上述加锁问题的危险。

要代表一个有价值的并发模型，还需要其他功能。我们已经看到，基于锁的多线程缺乏对可组合性的支持。此外，我们还需要使用 STM 协调不同线程的机制。扩展的 STM 模型[^Har08]已经满足了这两个要求。事务的粒度允许将不同的事务操作粘合在一起，从而产生新的事务复合操作。可以使用 `retry` 和 `orElse` 等操作符实现更高级的组合。前一种操作符基于与监控器条件变量类似的概念。当一个运行中的事务检查到一个包含与预期值不同的状态的条件时，该事务可以通过调用 `retry` 来“让步(yield)”。借助读取集，底层运行时可以检测到哪些变量迄今为止已被访问过。一旦这些变量中的一个在其他事务中被修改，运行时就会恢复之前的事务，并检查条件是否为真。`orElse` 运算符允许组合两个或多个事务。当第一个事务调用 `retry` 时产生让步,则执行下一个事务。从本质上讲,这些运算符将阻塞协调的概念引入到事务模型中。因此,现在事务可以等待某些事件发生,或者在单个事务行为中包含替代控制流程。

STM 有一些重要的局限性。**由于 TM 事务仅限于内存操作**，因此只能用于协调对共享状态的访问，而不能用于对外部资源的访问。此外，事务特性要求操作不可撤销，因此事务除了修改共享状态外，不得有任何副作用。例如，禁止在事务中使用 I/O 操作。

此外，事务的长度和冲突事务的比例也会对 STM 部署的性能产生持久影响。事务执行的时间越长，就越有可能引起冲突，至少在有很多冲突事务的情况下，必须中止事务。

不过，STM 对共享状态和线程的传统并发模型进行了有益的扩展，避免了锁定的负担。它允许在没有死锁危险的情况下组成并发操作。不过，在 STM 系统中仍可能出现争用和饥饿。前者往往是许多事务同时更改相同值的结果。后者可能在一个非常长的事务持续与多个短事务竞争时变得明显。

在使用乐观并发控制的情况下，只要没有很多并发和冲突的写操作，STM 就能提供合理的性能。

### TM VS 垃圾回收

对于基于锁的编程，TM 的理念和 STM 方法仍存在争议。批评者认为，STM 持续面临着一些挑战，这也是为什么迄今为止它仍主要受到学术界关注的原因。例如，如何处理对同一变量的事务性和非事务性访问，以及如何将变量私有化（即从事务性访问切换到线程本地访问），这些问题仍不明确。此外，要求代码无副作用的缺点也提出了一个问题：如何将无法定义为事务的代码纳入事务操作中。反对 STM 的最主要论据还是基于软件的事务处理实施所带来的性能开销。

支持 STM 的人反驳说，近期 STM 系统的性能已大幅提高，STM 已经是一种稳健的解决方案。各种实现也采用了不同的私有化方法。最后但同样重要的是,Clojure 持续取得的成功证明了新一代 STM 实现的成熟度。Clojure 是第一种将 STM 作为一等公民内置的并发概念的编程语言。在 Clojure 之前,STM 实现主要是作为并发 Haskell 的扩展存在,基于特殊的单子。

在围绕 TM 的争论中，最有趣的概念可能是与垃圾回收的类比。垃圾回收处理的是托管引用，而 TM 处理的是托管状态。这两个概念都是在运行时对内存进行操作，并将困难的工作从应用程序开发人员手中解放出来。与 TM 相比，当垃圾收集首次被提出来时，人们对它提出了非常类似的反对意见。此外，与手动内存管理相比，最初的垃圾收集器也存在明显的性能开销。不过，随着时间的推移，垃圾收集器已经得到了极大的改进，现在已经成为许多高级语言不可或缺的一部分。在不久的将来，共享内存模型将继续盛行，时间将证明这种类比是否会继续下去，TM 是否会成为共享状态并发的合理高层抽象。

### 案例研究：Clojure 中的并发性

Clojure 是一种在 JVM 上运行的编程语言，深受 Lisp 的影响。它非常注重函数式编程概念。Clojure 的另一个决定性特征是其精心设计的并发方法。事实上，并发编程是开发 Clojure 的主要原因之一。与 Scala 一样，Clojure 也是建立在 Java 的基础上，并在内部使用 Java 的并发原语。Clojure 结合异步代理和成熟的 STM 实现，提供了非常强大的不变性概念。

为了理解这些概念之间的合作，有必要详细阐述 Clojure 的身份、状态、引用和值等概念。值是不可变的数据，永远不会改变。这在某种程度上甚至适用于命令式编程。例如，我们不会直接更改数值变量的值（即数字），而是会为该变量分配另一个值。但这并不影响旧值。面向对象编程通过统一身份和状态混淆了这一概念。在 Clojure 中，身份是“一个稳定的逻辑实体，随着时间的推移与一系列不同的值相关联”。换句话说，身份是一个与值有可变关联的实体，身份的状态由其在给定时间内的值决定。根据当前的状态，引用指向一个标识，而标识又指向一个值。状态变化是将标识重新分配给其他值。

虽然对于数值等值而言这是不言自明的,但 Clojure 也将这一原则应用于数据结构。当通过添加新元素来更改列表时,新值即是原有列表附加新元素之后的结果。但是,原有列表保持不变。为了支持诸如列表和映射表这类非原始数据类型,Clojure 利用了所谓的持久数据结构。在这个背景下,持久并不表示持久存储,而是指数据结构保留了它们的历史版本。高效地实现一种数据结构的多个版本而不产生冗余值,是持久数据结构面临的主要挑战。这种间接性是 Clojure 并发概念的一个重要特性,并保证了值的不可变性。

Clojure 运行时系统基于值和标识自动支持状态变更。因此,Clojure 提供了四种不同类型的可变状态引用,它们具有不同的影响,如表5.0所示:用于处理可变状态的 Clojure 基本元素。var 引用基元类似于命令式编程语言中可重新赋值的传统变量。但是,var 只是线程局部的,不能被其他线程访问。因此,状态是可变的,但并非共享的。

|                  |             |              |
| :--------------- | :---------- | ------------ |
|                  | synchronous | asynchronous |
| **coordinated**  | `ref`       |              |
| **independent**  | `atom`      | `agent`      |
| **thread-local** | `var`       |              |

表 5.1：用于处理可变状态的 Clojure 基元

`atom` 引用基元与 Java 的原子实体非常相似。它们允许管理共享、同步、独立的状态。`atom` 的状态可以通过显式解引用来访问。要改变值，有三种操作，即 `reset`（设置新值）、`swap`（应用修改函数）和 `compare-and-set`（低级变体）。

`ref` 基元定义了可以通过解引用来访问的引用，以便进行读取操作。修改操作只能作为 STM 事务的一部分执行。Clojure 的 STM 实现使用了基于时间戳的并发控制机制 MVCC [^Ber81][^Ree78]。`dosync` 函数用于封装事务操作，其函数体中的所有函数调用都在同一事务中运行。`ref-set` 用于直接将 `ref` 设置为新值。`alter` 操作应用了一个实现 `ref` 状态交换的函数。`commute` 操作的工作方式与 `alter` 相同，但它意味着修改函数是换向的，从而有效地在内部允许更多并发性（使用事务内的值）。最后，`ensure` 会阻止其他事务为 `ref` 设置事务内值。这就避免了写偏移：多个事务读取重叠的数据集，但在进行不相关的修改时不会看到其他事务的变化。如前所述，事务不应包含具有副作用的操作，如 I/O 操作。这是因为 STM 的内部实现可能会中止和重试事务。

最后一个基元是 `agent`，它提供对可变状态的独立、异步和共享访问。代理隔离了可被线程读取访问的状态。线程还可以向代理发送操作（即修改函数）。然后，代理按顺序执行接收到的操作。对于动作的发送者来说，执行是异步进行的，而且每个 `agent` 的执行总是保证单线程运行。正如我们即将看到的，`agent` 的概念不同于 `actor` 的概念。代理在其内部状态上执行接收到的函数。因此，发送的函数定义了一种行为。代理提供自己的内部行为，并等待处理传入的不可变消息。

Clojure 迫使开发者明确标注可变状态。否则，状态根本无法修改。只有这样，Clojure 应用程序才会更加健壮，因为它能防止意外和非预期的可变性。它要求开发人员为状态处理选择合适的并发基元。

[Avout](http://avout.io/) 是 Clojure 的外部贡献，它提供了基于 [Apache ZooKeeper](http://zookeeper.apache.org/) 的分布式 MVCC STM 实现，用于协调。它支持在多个（远程）JVM 实例之间使用 `atom` 和 `ref` 基元。

一个用 Clojure 编写的简约并发网络应用程序，可返回目前已处理的请求数：

```clojure
(ns counting.server
  (:use noir.core)
  (:require [noir.server :as server]))

(def counter (ref 0))

(defpage "/" []
	(dosync (commute counter inc))
    (str @counter))

(server/start 8080)
```

前面的列表为我们之前的网络应用程序示例提供了一个基于 Clojure 的解决方案。该解决方案利用了 [noir web 框架](http://webnoir.org/)，而该框架又使用了 jetty 网络服务器。该简约应用程序定义了一个 `ref` 类型的计数器，并注册了一个用于处理请求的函数。每次请求时，该函数都会在 `dosync` 块中执行一个 STM 事务。在这种情况下，会使用 `commute` 操作，以事务方式递增计数器的值。通常情况下，使用 `alter` 方法代替 `commute` 操作。不过，增量操作是换向操作，因此使用 `commute` 操作可能会加快事务执行速度。事务完成后，`counter` 的值会被解引用（`@`），转换成字符串并作为响应返回。我们特意在外部而非实际事务内部解引用 `counter ref` 的值，是为了演示对 `ref` 进行非事务读取访问的可能性（这会产生一个短暂的窗口，在这个窗口中，`counter` 的值可能已被另一个请求更改）。与前面的 Java 示例一样，使用 Clojure 原子会更优雅，因为计数器是唯一要修改的变量。

### 用于并发应用逻辑的 STM

与之前基于锁的方法一样，使用 STM 的应用服务器也会将请求映射到线程。我们已经看到，当 I/O 绑定操作占主导地位时，这种方法变得越来越不合适。STM 并不能解决这个问题，事实上，它根本不允许在事务内部进行 I/O 操作。不过，当状态在应用服务器中共享时，STM 可以支持并发应用逻辑。根据应用的类型，应用状态可能会被分片并隔离到几个不同的服务器上（例如，在不同服务器上托管小方块的多人游戏），或者必须提供给所有应用服务器（例如，社交网络应用中的即时消息通知）。在后一种情况下，分布式 STM 变体允许进行分发。当 STM 实现提供与条件变量类似的机制时，也支持作为事务一部分的线程间协调。

因此，由于没有显式锁定，STM 使应用服务器内的共享状态更易于管理，但并不能解决 I/O 绑定并行化问题。

## 基于 Actor 并发

我们迄今考虑过的并发模型都有共享状态的概念。多个线程可以同时访问共享状态，因此必须通过加锁或使用事务来保护共享状态。状态的可变性和共享性不仅是这些模型的固有特性，也是复杂性的固有特性。我们现在来看看一种完全不同的方法，它完全禁止共享状态的概念。状态仍然是可变的，但它只与允许改变状态的单个实体（即所谓的行动者（actors））相关联。

### Actor 模型

actor 模型是并发建模和消息传递概念的理论基础。它的核心思想是利用 actor 作为并发原语，这些 actor 能够在接收到消息时以不同的方式行动：

- 向其他 actor 发送有限数量的消息。
- 生成有限数量的新 actor。
- 改变自己的内部行为，这种改变将在处理下一条进来的消息时生效。

在通信方面，actor 模型采用异步消息传递。特别是，它不使用任何中间实体，如通道。相反，每个 actor 都拥有一个邮箱，并且可以被寻址。这些地址不应与身份混淆，每个 actor 可以没有、一个或多个地址。当 actor 发送消息时，必须知道接收者的地址。此外，actor 被允许给自己发送消息，这些消息将在未来的某个步骤中被接收和处理。请注意，地址和 actor 的映射不是概念模型的一部分（尽管它是实现的一个特性）。

![](./asserts/actors.svg)

图 5.3：由多个 actor 组成的网络示例。每个角色都有自己的邮箱和独立状态。根据其指定行为，行为体通过发送新信息、产生新行为体和/或改变其未来行为来响应传入信息。

信息是异步发送的，最终到达接收者邮箱的时间可以任意延长。此外，**actor 模型不保证消息的排序**。在邮箱中排队和取消排队都是原子操作，因此不可能出现竞赛条件。行为体利用上述可能性按顺序处理从其邮箱收到的信息，并做出反应。第三种可能性是改变自己的内部行为，最终可以处理可变状态。不过，新 actor 只有在当前消息处理完毕后才会应用。因此，从概念角度来看，每次消息处理运行仍然是无副作用的操作。由于每个行为体完全独立于其他实例，因此行为体模型可用于对固有并发系统进行建模。如图 5.3 所示，没有共享状态，角色之间的交互完全基于异步消息。

### 并行编程的 actor 实现

除了并发系统的理论模型外，actor 的概念还代表了并发编程模型的蓝图。从严格的函数式适应到面向对象范式的扩展，人们已经考虑了几种概念实现[^Agh90]。Erlang [^Vin07]是第一种相当流行的编程语言，它采用了并发的 actor 模型。最近，actor 模型越来越流行，并进入了许多新的编程语言，而且通常是作为一流的语言概念。在许多其他语言中，可以使用建立在传统多线程基础上的第三方库来使用行为模型。

在实施 actor 模型时，必须遵守最初想法所定义的一系列规则。首先，actor 不得共享任何状态。这就禁止 actor 传递引用、指针或任何其他类型的共享数据作为消息的一部分。只能发送不可变的数据和 actor 地址（即“名称”）。与完全尽力而为的方式相比，actor 之间的消息传递通常有更多的保证。大多数实现都能确保从一个 actor 发送到另一个 actor 的两条信息在到达时保持顺序。消息传递总是异步的，多个 actor 发送的传入消息的交错是不确定的。

对于消息处理，大多数实现都提供模式匹配。这使开发人员能够区分不同类型的消息，并提供与消息类型相关的不同处理代码。从 actor 的角度看，接收消息是一个阻塞操作，而发送新消息则始终是非阻塞的。有些实现还提供了选择性接收语义。根据其行为，actor 可以等待邮箱中的特定信息，并暂时推迟其他信息的接收。

底层运行时平台必须为数量有限的 CPU 内核和资源分配可能数量巨大的 actor，并安排有待处理消息的 actor 的执行时间。大多数系统主要采用无锁实现，因为只有邮箱操作才需要原子行为。例如，Erlang 虚拟机会启动一个进程，并根据可用内核的数量生成一个线程池。内部调度器在进程队列中组织 actors，并抢先工作。当一个运行中的 actor 处理完一条消息或执行了一定数量的还原（即函数调用）后，调度器就会切换到下一个准备运行的 actor。对于 I/O 操作，Erlang 虚拟机会生成解耦的操作系统线程。缩减限制和后台 I/O 操作促进了公平性和及时性，因为任何 actor 都不能在较长时间内绑定 CPU 时间。

许多 actor 模型的实现提供了额外的功能，这些功能也是 actor 模型的延伸，即分布支持和容错。并发概念通常以单机为目标。actor 模型并没有为消息传递提供很多保证。异步、无限制的消息传递实际上类似于基于网络的通信。actor 的状态隔离不需要多个 actor 实例之间的共享访问。actor 使用地址指定，可以轻松提供位置透明度。`actor` 模型本质上是并行的，因此很容易扩展 actor 模型的实现，以支持分布式部署。例如，分布式 Erlang 系统利用运行 Erlang 虚拟机的多个节点，透明地提供分布式消息传递。

传统的、基于线程的并发给容错带来了困难。非确定性和不可预测的调度与共享状态和锁定相结合，需要非常复杂的复制和快照策略。actor 模型提供了其他基元，使复制变得更加容易。在 actor 邮箱中排队的隔离状态和传入消息与快照和日志非常相似。actor 的消息处理是单线程的，并提供了隐式让开点。Erlang 奉行“让崩溃发生”的理念。actor 孤立、无共享的特性允许单个 actor 发生故障而不影响其他任何行为体。此外，actor 模型本身也可用于容错，通过生成 actor 的层次树来进行监督。一旦某个 actor 崩溃，监管 actor 就会收到消息并做出反应。监管者可能会重新启动 actor、停止其他 actor 或通过向自己的监管者发送错误信息来升级。

actor 对状态具有隔离作用，可有效防止共享可变状态。此外，并发编程不需要锁。不过，在这种编程模型中，死锁和竞赛条件等并发问题仍未完全消除，因为不正确的应用程序可能会重新引入这些问题。两个 actor 互相等待一条消息，这代表了一种循环依赖关系。在实践中，可以通过使用超时来防止即将发生的死锁。一些开发人员可能会将 actor 发送消息的任意排序解释为传统的竞赛条件。然而，这是 actor 模型的一个特征属性，证明了异步性。因此，这些开发人员忽视了 actor 模型的基本思想，由此产生的“竞争条件 ”实际上是不恰当的应用程序设计的表现。

### Actor 编程

actor 模型的并发性与基于线程的锁或 STM 并发性截然不同。隔离的可变状态和异步消息传递产生了与线程不同的其他编程模式。

首先，我们必须明白，与线程相比，actors 代表了非常轻量级的基元。它们可以以最小的开销生成和销毁。因此，并行创建和使用大量实例是完全可行的。actor 还可以根据消息执行任意复杂的计算。actor 可以向自己发送消息，这样就可以使用消息模式来重现递归。此外，actor 还可以向地址已知的其他 actor 发送消息，因此基于 actor 的程序本质上是一个高度动态的 actor 网络（有向图）。因此，现有的基于消息的应用集成模式提供了一套全面的模式，也可用于 actor 并发编程。这包括用于路由、过滤、转换和组合的流行消息模式。

隔离可变状态并强制执行不可变消息可保证隐式同步。然而，异步消息传递和无全局状态的概念对协调性提出了挑战。应用程序可能需要在多个参与者之间达成共识或一致的状态视图。当多个参与者必须严格协调以提供不同的应用功能时，正确的消息传递就会变得非常苛刻。因此，许多实现提供了更高层次的抽象，根据复杂的消息流实现低层次的协调协议，但向开发人员隐藏了内部的复杂性。对于 Erlang 而言，OTP 是一个标准库，包含丰富的抽象、通用协议实现和行为。

另一种常见的方法是事务处理器。例如，多个 actor 可能需要以协调的方式修改其内部状态。在这种情况下，作为协调多个角色事务操作的专用角色的事务处理器，可以通过提供抽象事务逻辑来提供帮助。一些事务处理器还将 STM 概念应用于事务处理行为。

### 案例研究：Scala 中的并发性

Scala 是一种在 JVM 上运行的通用对象函数式语言。它与 Java 兼容，但提供了更强的表达能力、高级编程概念和函数式编程的许多功能。在并发性方面，Scala 实现了基于 actor 的并发模型，并支持值的显式不变性。不过，Scala 应用程序也可以使用 Java 编程语言的并发原语。

Erlang 会产生多个底层线程，并为运行的 actor 实现自定义调度程序，而 Scala 则会受到 JVM 的多线程影响。此外，Scala 的角色实现并不是语言核心的一部分，而是其标准库的一部分。这意味着 actor 库本身就是在 Scala 中实现的。Scala actor最初面临的一个挑战是 JVM 中的多线程限制。可能的线程数量有限，没有可用的协同调度，而且从概念上讲，线程没有 actor 那么轻量级。因此，Scala 提供了单一的角色概念，但却提供了两种不同的消息处理机制 [^Hal06][^Hal08]。

- **基于线程的 Actors**

  当使用 `receive` 原语时，actor 由一个专用线程提供内部支持。这显然限制了可扩展性，并要求线程在等待新消息时暂停和阻塞。

- **基于事件的 Actors**

  `react` 原语允许采用事件驱动的执行策略，它不会直接将 actor 与线程耦合。相反，一个线程池可用于多个 actor。这种方法使用延续闭包来封装 actor 及其状态。然而，这种机制有一些局限性，而且会掩盖控制流[^Hal08]。从概念上讲，这种实现方式与线程池支持的事件循环非常相似。actor 代表事件处理程序，消息则类似于事件。

一般来说，`react` 更受青睐，因为它不会将每个 actor 与专用线程耦合。因此，`react` 原始码能产生更好的可扩展性。

Scala 消息 actor 的语法遵循 Erlang 风格。消息应该是不可变的值，但目前还没有强制执行。通常会使用 case 类，这是一种特殊的封装类。当使用模式匹配来确定消息到达时的类型时，它们尤其有用。Scala 还通过提供远程 actor（通过 TCP/IP 通信并依赖于 Java 序列化）来支持 actor 的分发。

下面的列表展示了我们之前示例的网络应用中基于 actor 的解决方案。该解决方案是用 Scala 编写的，并使用了 [Play 网络应用程序框架](http://www.playframework.org/)。该框架并没有使用常规的 Scala 角色，而是使用了 [akka 库](http://www.akka.io/)提供的 actor 实现。如下图所示，应用程序启动了一个 actor，并注册了一个用于处理请求的方法。该方法会向 actor 发送一条异步的“访问”消息。通过使用 `?` 操作符，将返回一个代表最终回复的 `Future`。如果没有发生超时，则 actor 的回复一旦可用，就会被用作 `SimpleResult` 的响应体。如下表所示，`CoutingActor` 的内部结构非常简单。该 actor 提供了一个计数器变量，并通过递增该值来响应“访问”消息，然后将其发送回原始发送者。

基于 akka 行为器实现的 scala actor。该 actor 封装了一个计数器状态，并通过返回迄今为止的总访问次数来响应每个“访问”消息：

```scala
package actors

import akka.actor.Actor
import Actor._

class CoutingActor extends Actor {

	var count = 0;

	def receive = {
		case "visit" => 
			count = count+1
			sender ! ""+count 
	}
}
```

一个用 Scala 编写的简约并发网络应用程序，使用 Play 网络框架返回迄今为止处理的请求数：

```scala
package controllers

import akka.util.Timeout
import akka.pattern.ask
import akka.actor._
import akka.util.duration._
import actors.CoutingActor
import play.api._
import play.api.mvc._
import play.api.libs.concurrent._
import play.api.libs.iteratee.Enumerator

object Application extends Controller {

	val system = ActorSystem("counter")
	val actor = system.actorOf(Props[CoutingActor])

	def index = Action {
		AsyncResult {
			implicit val timeout= Timeout(5.seconds)
			(actor ? "visit").mapTo[String].asPromise.map { result =>
				SimpleResult(
					header = ResponseHeader(200, Map(CONTENT_TYPE -> "text/plain")), 
					body = Enumerator(result)
				)		   
			}
		}    
	}
}
```

### 并发应用逻辑的 Actors

当应用服务器使用 actor 模型时，每个传入的请求都代表一个新的 actor。为了实现请求操作的并行化，actor 会产生新的 actor，并通过消息分配工作。这就实现了并行 I/O 绑定操作和并行计算。通常情况下，单个请求流或多或少代表了多个 actor 之间复杂的消息流，使用的消息传递模式包括分散/收集、路由器、充实器或聚合器。

然而，使用 actor 实现请求逻辑与顺序请求逻辑实现明显不同。多个 actor 之间的必要协调以及异步消息传递所导致的不太明显的执行流，为并发提供了一个可以说不太舒适但却更现实的抽象。

actor 模型的另一个特点是可以通过添加新机器来扩展整个角色系统。例如，Erlang 使虚拟机能够催生分布式系统。在这种情况下，远程 actor 可以持有孤立的应用状态，但整个系统的所有其他角色都可以通过消息传递访问这些状态。

## 事件驱动并发

在第 4 章中,我们已经了解了事件驱动架构的概念。尽管事件驱动编程本身并不代表一种独特的并发模型,但事件循环、事件处理程序及其实现对并发编程有着深远的影响。事件和事件处理程序常常与消息和 actor 被混淆,因此区分它们的概念非常重要。基于 actor 的系统实现了 actor 模型及其所有特性和约束,而事件驱动系统仅将事件和事件处理作为构建模块,并摒弃了调用栈。我们现在来看一下事件驱动架构“宏观上”的原始理念,然后再研究事件驱动编程模型。

### 事件驱动架构

无论是在小型应用组件还是大型分布式架构中,事件驱动架构[^Hoh06]的概念都会产生特定的执行流程。传统系统是围绕调用栈的概念构建的,这依赖于几个假设。每当调用者调用一个方法时,它都会等待该方法返回,也许会得到一个返回值。最后,调用者在上下文恢复后继续执行下一个操作。被调用的方法也可能为自己执行其他方法。因此,**协调、连续性和上下文都是调用栈的内在特征**。命令式模型假定了一种顺序执行顺序,即一系列可能嵌套的调用。调用者预先知道哪些方法可用以及它们暴露的服务。程序基本上是执行指令和方法调用的路径。因此,调用栈对编程概念具有很强的形成作用,以至于许多开发人员认为它是理所当然的。

令人惊讶的是,事件驱动架构拒绝了调用栈的概念,因此失去了其内在特征。相反,这些架构促进了比调用/返回更具表现力的交互方式,并使各个实体之间的耦合更加松散。这个概念的基本原语是事件。事件发生是由外部刺激引起的,或者由系统内部实体发出的。事件随后可以被其他实体消费。这不仅解耦了调用方和被调用方,而且调用方也不需要知道谁负责处理该调用(或事件)。这种理念显然会导致职责的转移,但允许更加灵活的组合和流程。事件驱动架构本质上也是异步的,因为事件生产者和事件消费者之间没有强耦合,也没有同步事件交换。

从本质上讲,事件驱动模型代表了一种设计可组合且松散耦合系统的方法,具有富有表现力的交互机制,但没有调用栈。事件驱动架构并不代表或指定某种并发模型。不出意外，基于线程的事件循环和事件处理程序经常被用于事件驱动架构的实现，仅次于消息传递方法。

### 单线程事件驱动框架

有几个平台和框架使用基于事件循环和事件处理程序的事件驱动架构来实现可扩展的网络服务和高性能 Web 应用程序。流行的解决方案包括 [node.js](http://nodejs.org/)、[Twisted Python](http://twistedmatrix.com/)、[EventMachine (Ruby)](http://rubyeventmachine.com/) 和 [POE (Perl)](http://poe.perl.org/)。

这些系统使用的编程语言仍然提供调用栈。但是,这些系统并不使用调用栈在事件发射器和事件处理程序之间传输状态和上下文。

虽然一般来说可以应用多线程[^Zel03],但上述大多数框架和平台依赖于单线程执行模型。在这种情况下,只有一个事件循环和一个事件队列。单线程执行使并发推理变得非常简单,因为不存在对状态的并发访问,因此不需要锁。当单线程与异步、非阻塞 I/O 操作相结合时(见[第 4 章](webserver-architectures-for-highconcurrency.md)),只要大多数操作都是 I/O 绑定的,应用程序仍然可以在单个 CPU 内核上表现良好。大多数围绕数据库操作构建的 Web 应用程序实际上都是 I/O 绑定的,而计算密集型任务仍然可以外包给外部进程。当应用程序采用无共享设计时，可以通过生成多个应用程序实例来利用多个内核。

在[第 4 章](webserver-architectures-for-highconcurrency.md)中,我们已经看到单线程事件驱动编程不会受到上下文切换开销的影响,并且当协作式调度与自动栈管理相结合时,会达到一个很好的平衡点。我们之前也看到,事件驱动架构中缺少调用栈会放弃自由协调、连续性和上下文。

这些框架的事件驱动编程风格提供了不同的方式来构建应用程序代码并管理控制流。事件循环按顺序处理队列中的事件,执行与事件关联的回调。回调是先前注册用作某些事件类型的事件处理程序的函数。假设回调是短期运行的函数,不会长时间占用 CPU,因为这会阻塞整个事件循环。相反,回调通常是短小的函数,可能会派发后台操作,最终产生新事件。支持匿名函数和闭包是事件驱动编程语言的一个重要特性,因为一级函数用于定义回调,而闭包可以为上下文和连续性提供替代。由于闭包将状态绑定到回调函数,状态会保存在闭包中,并在回调在事件循环中执行时再次可用。单线程执行和回调的概念还提供了隐式协调,**因为回调永远不会并行执行**,每个发出的事件最终都会使用回调进行处理。可以安全地假设没有其他回调并行运行,事件处理程序可以放弃控制权,从而支持协作式调度。一旦回调执行完成,事件循环就会出队列下一个事件并应用它的回调。事件驱动框架和平台提供了隐式或显式事件循环、用于 I/O 操作和系统函数的异步 API,以及向事件注册回调的方式。

使用单个线程使得出现死锁的情况成为不可能。但是,当开发人员没有完全理解事件循环的含义时,类似于饥饿和竞态条件的问题仍然可能出现。只要回调正在执行,它就会消耗应用程序的唯一线程。当回调被阻塞时,无论是由于运行阻塞操作还是由于不返回(例如无限循环),整个应用程序都会被阻塞。当多个异步操作被派发时,开发人员不能对它们回调的执行顺序做任何假设。更糟糕的是,回调的执行可能会与来自其他事件的其他回调交织在一起。如果使用全局变量而不是闭包来保存回调之间的状态,对回调执行顺序的假设尤其是致命的。

### 案例研究：node.js 中的并发

Node.js 是一个建立在 Google Chrome 浏览器 V8 JavaScript 引擎之上的平台,包含用于异步非阻塞操作的事件库和一些 C/C++ 代码。它使用非阻塞 I/O 模型,为 JavaScript 中的事件驱动编程提供了一个轻量级环境。与其他事件驱动框架和平台相比,Node.js 由于几个原因而脱颖而出。与许多其他编程语言不同,JavaScript 没有内置的 I/O 机制或并发机制。这样可以为所有操作公开纯异步非阻塞 API,并防止意外使用阻塞调用(事实上,也有一些特殊用途的阻塞 API 调用)。JavaScript 对匿名函数、闭包和事件处理的良好语言支持,也为事件驱动编程提供了坚实的基础。事件循环由单线程支持,因此完全不需要同步。合并诸如计时器和 I/O 通知之类的多个事件源,并按顺序排队事件,都隐藏在平台内部。

Node.js 没有向开发人员公开事件循环。Node.js 应用程序由一系列可能提供异步行为的操作组成。对于每个异步操作,都应指定一个适当的回调函数。回调函数反过来可以分派进一步的异步操作。例如,Node.js Web 服务器使用单个异步函数来注册 HTTP 服务器,并传递一个回调函数。回调函数定义了每次收到新请求时要执行的函数。请求处理回调函数反过来可能会执行文件 I/O,这也是异步的。由于回调式风格,这导致了繁重的回调链和明显的控制反转。这种结果需要严格的编码规则或库的帮助,以保持代码可读性和可管理性,而不会丢失执行流程的跟踪。这些库之一是 [async](https://github.com/caolan/async),它大量使用了 JavaScript 的函数特性。它支持诸如瀑布、串行和并行执行的控制流模式,以及 `map`、`reduce`、`filter`、`some` 和 `every` 等函数概念,还有错误处理概念。所有这些抽象使得回调处理更加合理。尽管 Node.js 是一个相当新的平台,但已经有许多库和扩展可用,尤其是针对 Web 应用程序开发的。Node.js 最出色的库之一是 [socket.io](http://socket.io/)。它在服务器和浏览器之间提供 Web 实时通信机制,但抽象了底层传输。因此,开发人员可以在服务器端和客户端应用程序代码中使用发送函数和消息事件处理程序。底层通信使用 WebSocket,但在不可用时也支持诸如长轮询之类的几种回退方案。

使用 Node.js 平台编写的一个简单的并发 Web 应用程序,用 JavaScript 编写,返回到目前为止已处理的请求数量。

```js
var http = require('http');

var count = 0;

http.createServer(function (req, res) {
	res.writeHead(200, {'Content-Type': 'text/plain'});
	res.end((++count)+'\n');
}).listen(8080);
```

前面的列表介绍了在单线程事件驱动应用程序（本例中为 node.js）中如何处理共享应用程序状态。应用程序定义了一个全局计数变量。然后，创建一个服务器，并为请求处理提供回调。回调通过递增计数变量并返回其值来响应每个请求。由于采用了单线程执行模式，因此在访问或修改变量时无需同步。

### 事件驱动的并发应用程序逻辑

很明显,单线程的事件驱动应用服务器无法减少 CPU 密集型请求的延迟。我们分布式架构中的大多数平台组件,实际上大部分请求操作都是 I/O 密集型的。对于复杂的计算,我们还提供了一个解耦的后台工作线程池。因此,当应用程序逻辑主要用于分派工作任务、调用和请求到平台组件,并在无需高计算量的情况下组合结果时,事件驱动方式是一种合适的概念。[第 4 章](webserver-architectures-for-highconcurrency.md)已经阐释了事件驱动方式在 I/O 密集型并行性方面的优势。当共享的应用程序状态和发布/订阅协调机制被外包给平台组件时,这种机制很好地融入了事件驱动方式。实际上,如果应用程序状态可以隔离到单独的应用程序服务器(例如交互式 Web 应用程序的会话),事件驱动方式的另一个好处就更加显著了。单线程执行模型使得在请求之间访问和修改可变状态变得非常容易,因为不涉及真正的并发性。

## 其它方式和并发原语

我们现在已经了解了可用于并发应用程序逻辑编程的四个常见并发概念。不过，还有其他并发概念和语言基元可用于并发编程。现在，我们将简要介绍比较有趣的并发概念。我们将提示它们与前几个概念的关系，以及如何在实践中使用它们。

### Feature、Promises 和异步任务

Promises 和 Feature 通常描述了相同的理念,即通过提供一个代理实体来返回结果(一旦可用),从而将计算和最终结果解耦。在并发编程中,`promise` 和 `feature` 经常被用于异步后台任务。一旦任务被分派,就会返回代理实体,调用者的执行流程可以继续,与新的计算分离。代理实体以后可以被查询以返回解耦计算的结果。如果结果还不可用,代理实体要么阻塞,要么在非阻塞时提供通知。

`promise` 和 `feature` 还引入了一种同步机制,因为它们允许分派独立的计算,但一旦请求并最终返回结果,就与初始控制流同步。使用线程进行并发的许多编程语言中都有 `feature` 和 `promise`。在这种情况下,后台任务的执行被安排在另一个线程中,允许初始线程继续执行。基于 actor 的系统通常使用 actor 作为计算的代理实体,这本质上与 `feature` 相同。向另一个 actor 发送消息并等待它最终的响应也常常使用 `feature` 进行抽象。在事件驱动系统中,最终结果由事件表示,并由相关的回调处理。

在编程 Web 应用程序时,可以使用 `promise` 或 `feature` 来减少延迟。分散/聚集模式分派多个独立操作(分散),并等待所有操作产生结果(聚集)。例如,可以使用此模式并行化多个独立的数据库查询。可以通过将所有操作作为产生代理实体的后台任务分散,然后通过访问代理实体来收集所有结果来实现。实际上,这将一系列操作转换为操作的并行执行。数据流编程提供了类似的执行策略,但在实现中隐藏了 `feature` 的概念。

### 协程、纤程和绿色线程

协程(Coroutines)、纤程(Fibers)和绿色线程(Green Threads)是子程序的一种衍生。虽然子程序是按顺序直接执行的,但协程可以在代码中的不同点暂停和恢复执行。因此,协程是用于协作任务处理的原语,因为协程能够让出执行。我们已经在[第 4 章](webserver-architectures-for-highconcurrency.md)中确认了协作任务处理的优势,尤其是在大规模异步操作(如 I/O)并行时。

协程通常被用作低级原语,即作为实现高级并发概念的线程替代品。例如,基于 actor 的系统和事件驱动平台可能使用协程作为底层实现。

还有一些编程语言和语言扩展将协程或其变体引入高级编程语言。例如,[greenlet](http://codespeak.net/py/0.9.2/greenlet.html) 是 Python 的一个协程框架,被高性能事件循环框架(如 [gevent](http://www.gevent.org/))大量使用。

[Golang](http://golang.org/) 是 Google 开发的一种通用编程语言,支持垃圾回收和用于并发的同步消息传递(见下文)。Go 的目标使用场景与 C/C++ 类似。它不提供线程用于并发执行流,而是提供一种名为 `goroutine` 的原语,源自协程。`Goroutine` 是与调用者和其他运行的`goroutine` 并行执行的函数。运行时系统将 `goroutine` 映射到一组底层线程,这可能导致真正的并行执行。在其他情况下,多个`goroutine` 也可能由单个线程使用协作式调度来执行。因此,它们比传统的协程更强大,因为它们意味着并行执行和通过同步消息传递进行通信,而不仅仅是让出。

### Channel 和同步信息传递

消息传递是并发系统的一种理论模型,由于 Hoare 的 CSP 而广为人知。它也是并发编程概念的理论基础。

消息传递有两种不同的风格——同步和异步。我们已经认识了后者,因为 actor 模型本质上是建立在 actors 之间的异步消息传递之上的。异步消息传递将实体之间的通信解耦,允许发送者发送消息而无需等待接收者。特别是,发送者和接收者之间不需要同步来交换消息,两个实体都可以独立运行。另一方面,发送者无法知道何时消息实际被接收者接收和处理。

另一种变体,同步消息传递,使用显式消息交换。发送者和接收者都必须准备就绪并阻塞,同时消息正在交换。因此,同步消息传递产生了一种同步形式,因为消息交换是不同控制流的显式同步点。

这两种模型还有其他几个区别。在异步消息传递模型中,通信实体有标识,而同步消息传递模型中的实体是匿名的。同步消息传递使用显式的、命名的通道在实体之间进行通信,而异步消息传递没有中介。

Go 大量使用同步消息传递进行并发编程,非常类似于 Unix 中使用管道的方式(也是同步的)。通道(Channel)是一级语言原语,用于 `goroutine` 之间的数据交换。由于 `goroutine` 可以被调度到多个线程并可能实际并行运行,因此通道也是主要的同步原语,确保多个 `goroutine` 会在共同已知的状态下相遇。

### 数据流编程

使用声明式并发进行数据流编程是一种非常优雅但并不常见的方法来处理并发性。命令式编程基于描述一系列要执行的显式操作的思想。相反,数据流编程定义了必要操作之间的关系,从而产生了一个隐式的依赖关系图,即执行流。这允许运行时系统自动识别操作的独立步骤并在运行时并行化它们。协调和同步隐藏在运行时系统中,通常使用通道等待多个输入数据,然后启动下一步计算。虽然这种编程概念允许真正的并行性,但协调和同步工作由于声明式风格而被隐藏了。

Mozart/Oz [^Roy04]是一种支持多范式的编程语言,并且对数据流编程和声明式并发有很好的支持。[GPars](http://gpars.codehaus.org/) 是一个 Java 并发库,也提供了丰富的数据流并发原语。

数据流编程对于 Web 应用程序开发也很有意义。应用程序级别的请求处理可以被定义为一系列操作流。由于隐式并行化,独立的操作将并行执行,之后无需任何锁定即可同步。因此,这种风格有助于减少延迟。

## 总结

传统的 Web 应用程序主要是"尴尬地并行"的,因为请求完全是隔离的,可以很容易地独立执行。高度交互式和协作式的 Web 应用程序,以及实时 Web 应用程序,则需要更具挑战性的并发特性。一方面,这些应用程序需要协调不同并发请求之间的行为,并在它们之间进行通信。它们还在请求之间共享应用程序逻辑的公共状态。这就实现了诸如即时通知、异步消息传递和服务器发送事件等功能——这些都是现代 Web 应用程序(包括社交 Web 应用程序、多人浏览器游戏、协作式 Web 平台和移动应用程序的 Web 服务)的重要组成部分。另一方面,现代应用程序需要越来越低的延迟和极高的响应能力。这可以通过尽可能多地并行化请求所需的应用程序逻辑操作来解决。反过来,这又需要针对每个请求同步请求逻辑。因此,现代大型 Web 应用程序的应用程序逻辑本质上是并发的。因此,我们介绍并分析了用于编程并发系统的最流行的并发概念。

线程和锁的概念是基于多个执行流共享的可变状态。需要锁来实施互斥,防止竞态条件。反过来,锁又引入了死锁、活锁和资源饥饿的隐患。选择合适的锁粒度就变成了在竞态条件和死锁的危险之间、在退化的顺序执行和无法管理的非确定性之间进行权衡。非确定性和可变共享状态的组合使得基于锁的并发性和正确性变得极其难以推理。此外,基于锁的组件的组合无法保证无死锁。基于线程、锁和共享状态的并发编程仍然是必不可少的,它代表了所有更高级别并发抽象的低层次基础,不容忽视。然而,对于高层次应用程序编程来说,它通常是错误的抽象层次,因为它太难且太容易出错。

软件事务内存 (STM) 通过为并发代码引入事务操作来解决基于锁的并发性所带来的这些问题。事务对可变共享状态上的操作进行隔离,并且是无锁和可组合的。但是,事务代码不能包含任何副作用(例如没有 I/O 操作),因为它可能会被中止和重试。STM 在软件层中隐藏了事务处理的复杂性,这在运行时引入了一些计算开销。

Actor 模型代表了一种完全不同的方法,它隔离了状态的可变性。Actor 是独立的单线程实体,通过不可变的、异步和保证的消息传递进行通信。因此,Actor 封装了状态,并提供了一种拥抱基于消息传递的分布式计算的编程模型。

常见的事件驱动架构通过使用**单线程事件循环**来消除死锁的危险。事件循环从积压的事件中出队,并依次使用相关的事件处理程序(即回调)顺序执行每个事件。因此,应用程序逻辑被定义为一组事件处理程序,与纯顺序代码相比,这就产生了一种控制反转。当应用程序主要受 I/O 约束且事件处理程序不执行计算密集型操作时,这种概念可以非常好地利用单个 CPU 内核,并使并发推理变得非常简单。

我们还看到,数据流编程使用基于隐式依赖关系图的声明式并发。同步消息传递提供基于通道的数据交换点,也可用于同步和协调不同的执行流。协程表示协作任务处理的原语。Future 和 Promise 有助于解耦后台任务,并后续与其最终结果同步。

[^Sut05]: https://dl.acm.org/doi/pdf/10.1145/1095408.1095421

[^Lea00]: https://dl.acm.org/doi/10.1145/337449.337465

[^Hel07]: https://dsf.berkeley.edu/papers/fntdb07-architecture.pdf
[^Her93]: https://dl.acm.org/doi/10.1145/173682.165164
[^Ber81]: https://dl.acm.org/doi/10.1145/356842.356846
[^Ree78]: https://dl.acm.org/doi/10.5555/889815
[^Agh90]: https://dl.acm.org/doi/10.1145/83880.84528
[^Vin07]: https://dl.acm.org/doi/10.1109/MIC.2007.104
[^Hal08]: https://www.researchgate.net/publication/220994136_Actors_That_Unify_Threads_and_Events
[^Hal06]: https://dl.acm.org/doi/abs/10.1007/11860990_2
[^Hoh06]: https://www.enterpriseintegrationpatterns.com/docs/EDA.pdf
[^Zel03]: https://people.csail.mit.edu/nickolai/papers/zeldovich-async-mp.pdf
[^Roy04]: https://ia902308.us.archive.org/15/items/c-15_20211009/C15.pdf

