> 在计算机科学中，尤其是 .NET Runtime (CoreCLR) 的文档里，**Stub**（中文常译为“存根”，也有人叫它“桩”）是一个非常高频的词。
>
> 简单来说：**Stub 是一小段在运行时动态生成的、高度优化的机器码（汇编指令），它像是一个“中转站”或“胶水代码”，负责处理函数调用过程中的各种“杂活”。**
>
> 为了彻底理解，我们不用专业术语，用几个生活场景和具体的 CLR 场景来解释：
>
> ### 1. 形象类比：电影票的存根
>
> 为什么叫“存根”？就像电影票，你手里拿的那一小块（存根）虽然不是电影本身，但它上面写着：**你应该去几号厅看哪部电影**。 在代码里，Stub 就是那块“存根”，它告诉你真正要执行的代码在哪里，并且在带你去之前，先帮你检票、安检。
>
> ### 2. CLR 中 Stub 的三个核心用途（为什么需要它？）
>
> 在 .NET 这种高度动态的运行时里，Stub 主要干这三件事：
>
> #### A. 懒加载（JIT 编译的占位符）
>
> 当你第一次调用一个方法时，这个方法可能还没被编译成机器码（还是 IL 码）。
>
> - **做法：** CLR 会为这个方法先指派一个 **JIT Stub**（也叫 Precode Stub）。
> - 流程：
>   1. 你调用方法 A。
>   2. 实际上你跳到了 A 的 Stub。
>   3. Stub 检查发现：“咦，A 还没编译成机器码呢”。
>   4. Stub 调用 JIT 编译器：“快给 A 编译一下”。
>   5. JIT 编译完，Stub 把 A 的入口地址**改写**成真正的代码地址。
>   6. 以后再调用，就不再走这个 Stub 了。
>
> #### B. 跨界桥梁（P/Invoke 或 COM 互操作）
>
> 当你从 C# 调用一个 C++ 的 DLL 函数时，两边的规则不一样（比如 C# 用的是托管栈，C++ 是非托管栈；字符串格式也不同）。
>
> - **做法：** CLR 生成一个 **P/Invoke Stub**。
> - **职责：** 这个 Stub 负责“翻译”。它把 C# 的参数搬运到 C++ 能理解的地方，切换线程状态（进入非托管模式），等 C++ 执行完，再把结果搬回来。
>
> #### C. 虚函数调用的“导购员”（Virtual Stub Dispatch）
>
> 对于接口调用（比如 `IMyInterface.DoWork()`），运行时并不知道具体该跑哪个实现类的方法。
>
> - **做法：** CLR 使用 **Virtual Stub**。
> - **优化：** Stub 会缓存上一次调用的结果。它会想：“上次调用这个接口的是 `Class A`，那这次大概率还是 `Class A`”。如果猜对了，Stub 直接几行汇编就跳过去了，比查表快得多。如果猜错了，它才会去走复杂的查找逻辑。
>
> ### 3. Stub 到底长什么样？
>
> 如果你去看源码或者反汇编，一个 Stub 通常只有几行汇编指令。例如：
>
> Assembly
>
> ```
> mov rax, 0x12345678  ; 把真正的方法地址存进寄存器
> jmp rax              ; 跳过去执行
> ```
>
> 或者包含一些简单的判断逻辑（Cache Check）。
>
> ### 4. 为什么要用这么奇怪的翻译“存根”？
>
> 在中文里，“存根”通常指票据留存的部分，作为**凭证**和**索引**。
>
> - 它是**轻量**的（只有几个字大小）。
> - 它是**临时**的（一旦真正的代码准备好了，它可能就被替换掉）。
> - 它是**代理**（你以为在调方法，其实在调 Stub）。
>
> ### 总结
>
> 你以后看到 **Stub**，就把它脑补成 **“一小段负责跑腿、中转、或打掩护的底层汇编代码”**。
>
> 它之所以在 .NET 这种运行时里重要，是因为 .NET 有很多东西是**动态确定**的（比如 JIT、泛型、接口、多态）。Stub 就像是在杂乱的逻辑中架起的一座座**快速通道**，让 CPU 能以最高速度跳到该去的地方

> 为了理解这里的 Stub 到底是什么，我们需要先看它要解决的**核心痛点**。
>
> ### 1. 痛点：为什么接口调用很慢？
>
> 在 C# 中，调用类的方法（Virtual Call）相对简单，因为每个类都有自己的 `MethodTable`，查表就行。 但接口调用（Interface Call）很难：
>
> - 一个 `IList` 接口，当前实例可能是 `List<int>`，也可能是 `ArrayList`，还可能是你自定义的类。
> - 每个类实现的接口方法，在各自 `MethodTable` 里的位置（偏移量）都不一样。
> - **传统做法：** 每次调用接口都要进行复杂的全局搜索（查接口表、算偏移），非常耗时。
>
> ### 2. VSD 里的 Stub 是什么？
>
> VSD 的核心思想是：**“接口调用虽然有很多种可能，但在某个具体的代码位置，通常调用的都是同一种类型。”**
>
> 于是，CLR 在接口调用点放了一个 **Stub**。这个 Stub 在 VSD 中其实分为三种形态（或者说三个阶段的进化）：
>
> #### 第一阶段：查找存根 (Lookup Stub) —— “我是新生”
>
> 当你第一次运行到这行代码时：
>
> - 这里的 Stub 是一个 **Lookup Stub**。
> - 它的代码逻辑非常简单：直接跳转到内核里的“寻找者”（Resolver）。
> - **作用：** 它告诉运行时：“我不知道该调谁，请帮我找一下，顺便帮我进化一下”。
>
> #### 第二阶段：分派存根 (Dispatch Stub) —— “我有记忆了（缓存）”
>
> 当 Resolver 找到了真正的目标方法后，它会**改写**调用点的代码，把 Lookup Stub 替换成 **Dispatch Stub**。
>
> - 这段 Stub 包含以下汇编逻辑：
>   1. 检查当前对象的类型（MethodTable 地址）。
>   2. 把它与“上一次”调用的类型进行比较（这是一个硬编码在 Stub 里的地址）。
>   3. **如果一致（命中缓存）：** 直接跳转到目标方法。**这只需要几条 CPU 指令，快如闪电。**
>   4. **如果不一致（缓存失效）：** 跳转到第三阶段。
>
> #### 第三阶段：解析存根 (Resolve Stub) —— “我是专家”
>
> 如果这个调用点经常出现不同的类型（比如一会儿是 `List`，一会儿是 `Array`），Dispatch Stub 就会失效。
>
> - 此时 Stub 会进化成 **Resolve Stub**。
> - 它内部包含一个更高级的“小哈希表”。它会快速检查：这个点最近常用的 3-5 个类型分别对应哪个方法。
> - 如果还是找不到，才去调用最慢的全局搜索。
>
> ### 3. 直观对比：传统的查表 vs VSD 的 Stub
>
> - 传统查表（像查字典）：
>   1. 拿到对象 -> 2. 找到类 -> 3. 找到接口映射表 -> 4. 找到方法 -> 5. 执行。
> - VSD Stub（像安检口）：
>   1. Stub 直接问：“你还是上次来的那个人吗？”
>   2. 如果是，门直接打开（跳转执行），整个过程不到 1 纳秒。

虚拟存根分派
=====================

作者：Simon Hall（[@snwbrdwndsrf](https://github.com/snwbrdwndsrf)）- 2006

引言
============

虚拟存根分派（Virtual Stub Dispatching，VSD）是一种技术：用存根（stub）来完成虚方法调用，而不是使用传统的虚方法表（virtual method table）。过去，接口分派要求接口具有进程内唯一标识符，并且每个已加载的接口都要被加入一个全局的“接口虚表映射”。这项要求意味着：在 NGEN 场景中，必须在运行时还原所有接口以及所有实现了接口的类，从而导致启动时工作集（working set）显著增大。引入存根分派的动机，是为了消除相关的大量工作集，并把剩余的工作分摊到进程的整个生命周期中。

尽管 VSD 理论上既可以分派虚实例方法调用，也可以分派接口方法调用，但目前它只用于接口分派。

依赖关系
------------

### 组件依赖

存根分派代码相对独立于运行时的其他部分。它提供了一套 API 供依赖组件使用，而下面列出的依赖点构成了相对较小的表面积（surface area）。

#### 代码管理器（Code Manager）

VSD 实际上依赖代码管理器提供方法状态信息，尤其是：某个特定方法是否已经迁移到其最终状态。VSD 需要据此决定诸如存根生成与目标缓存等细节。

#### 类型与方法

MethodTable 保存指向分派映射（dispatch map）的指针，这些映射用于为任意给定的 VSD 调用点确定目标代码地址。

#### 特殊类型

对 COM 互操作类型的调用必须使用定制分派，因为它们都有专门化的目标解析方式。

### 依赖本组件的组件

#### 代码管理器（Code Manager）

代码管理器依赖 VSD 为 JIT 编译器提供接口调用的调用点目标（call site target）。

#### 类构建器（Class Builder）

类构建器使用分派映射代码暴露的 API，在类型构建期间创建分派映射；这些映射会在分派时被 VSD 代码使用。

设计目标与非目标
--------------------------

### 目标

#### 降低工作集

接口分派过去是通过一个较大且相对稀疏的 vtable 查找映射来实现的，该映射依赖进程范围的接口标识符。目标是通过按需生成分派存根来减少冷工作集（cold working set）：理论上，让相关调用点与它们的分派存根彼此更接近，从而提升工作集密度。

需要注意的是：由于 VSD 需要数据结构来跟踪系统运行过程中创建并回收的各种存根，因此在“每个调用点”维度上，VSD 的初始工作集更高；然而，当应用进入稳态（steady state）后，这些数据结构在简单分派时不再需要，因此会被换出到分页（paged out）。不幸的是，对客户端应用而言，这相当于更慢的启动时间——这也是后来禁用 VSD 用于虚方法的因素之一。

#### 吞吐量对齐

重要目标之一是：让接口与虚方法分派的摊销性能（amortized）与之前的 vtable 分派机制保持同一水平。

虽然对于接口分派很快就显而易见可以做到这一点，但对虚方法分派来说，它最终被证明会更慢——这也是后来禁用 VSD 用于虚方法的因素之一。

Token 表示与分派映射（Dispatch Map）的设计
-----------------------------------------------

分派 token 是在运行时分配的、机器字大小的值，其内部由一个二元组构成，用来表示“接口 + 槽位（slot）”。

该设计结合了分配到的类型标识符值与槽位号。分派 token 由这两个值组合而成。为了便于与运行时集成，实现还会以经典 v-table 布局的方式分配槽位号。这意味着：运行时仍然可以以完全相同的方式处理 MethodTable、MethodDesc 与槽位号；不同点在于，为了处理这种抽象，v-table 必须通过辅助方法访问，而不能直接访问。

术语 _slot_ 将始终在两种语境中使用：一是在经典 v-table 布局世界中作为一个 slot 索引值使用；二是映射机制创建、解释并加以使用。这意味着，如果你把经典的方法表布局想象成：先是虚方法 slot，后是非虚方法 slot（正如运行时此前的实现那样），那么这里的 slot 就是那个 slot 编号。理解这一区分很重要，因为在运行时代码中，slot 既可以表示经典 v-table 结构中的一个索引，也可以表示 v-table 本身内部指针所在位置的地址。现在的变化是：slot 仅表示一个索引值，而代码指针地址被包含在实现表（下文讨论）中。

动态分配的类型标识符值将在后文讨论。

### 方法表（Method Table）

#### 实现表（Implementation Table）

这是一个数组：对类型引入的每个方法体（method body），它都保存一个指向该方法入口点（entrypoint）的指针。其成员按如下顺序排列：

- 引入的（newslot）虚方法。
- 引入的非虚方法（实例与静态）。
- 重写的虚方法。

这种格式的原因是：它为经典 v-table 布局提供了自然延伸。因此，槽位映射（slot map，见下文）中的许多条目可以由该顺序以及诸如“该类的虚/非虚方法总数”等细节推导出来。

当虚实例方法的存根分派被禁用时（当前就是如此），实现表不存在，会被真正的 vtable 取代。此时，所有映射结果都将表示为 vtable 的槽位，而不是实现表中的索引。在阅读本文后续提到实现表的内容时，请牢记这一点。

#### 槽位映射（Slot Map）

槽位映射是一张表，包含零个或多个 <_type_, [<_slot_, _scope_, (_index | slot_)>]> 条目。_type_ 是上面提到的动态分配标识号：它要么是一个哨兵值，用于表示当前类（对虚实例方法的调用）；要么是当前类实现的某个接口的标识符（或通过其父类隐式实现）。子映射（用方括号括起）包含一个或多个条目。在每个条目中，第一个元素总是表示 _type_ 内的一个槽位。第二个元素 _scope_ 指示第三个元素应解释为实现表 _index_ 还是 _slot_ 号。_scope_ 可以是某个已知的哨兵值，表示下一个数字应被解释为虚槽位号，并且应当以 _this.slot_ 的方式进行虚解析。_scope_ 也可以标识当前类继承层次中的某个特定类；在这种情况下，第三个参数是对 _scope_ 所指示类的实现表的一个 _index_，并且它就是 _type.slot_ 的最终方法实现。

#### 示例

下面给出一个小型类结构（用 C# 建模），以及每个类对应的实现表与槽位映射结果。

![Figure 1](./asserts/virtualstubdispatch-fig1.png)

因此，观察该映射可以看到：槽位映射子映射的第一列对应于经典虚表视图中的槽位号（记住：System.Object 自己贡献了 4 个虚方法，为简洁起见此处省略）。方法实现的搜索总是自底向上进行。也就是说：如果我有一个类型为 _B_ 的对象，并且我希望调用 _I.Foo_，我会从 _B_ 的槽位映射开始查找 _I.Foo_ 的映射。若在 _B_ 中找不到，我会到 _A_ 的槽位映射中查找并在那里找到。它说明：_I_ 的虚槽位 0（对应 _I.Foo_）由虚槽位 4 实现。随后我回到 _B_ 的槽位映射中，查找虚槽位 4 的实现，并发现它由 _B_ 自己实现表中的槽位 1 实现。

> ## 最上面：interface I
>
> 左边（Classic Virtual Table）画的是接口的“经典视角”：
>
> - `I.Foo prestub`：接口方法调用的入口（可以理解为一个通用 stub，会触发后续查映射）
>
> 右边（Implementation Table）：
>
> - 这里只有 `I.Foo prestub`，因为接口自己没有真正实现代码，只是个“调用入口”。
>
> 右边（Slot Map）：
>
> - `ID for I : ( slot 0 , scope I , 0* )`
>
> 这句的含义是：**I 的 slot0 就对应 I 自己实现表 index0**（也就是那个 prestub）。
> 星号 `*` 表示“这条映射是可推导出来的，所以可以省空间/省存储”。
>
> > 这一部分主要是把“接口调用先落到 prestub”这件事表示出来。
>
> ## 中间：class A : I（A 引入 Foo 和 Bar）
>
> 左边（Classic Virtual Table）：
>
> - `A.Foo code ptr`
> - `A.Bar code ptr`
>
> 注意：这里省略了 `System.Object` 的 4 个虚方法槽位（图上文字也说了）。
> 所以你看到的 `A.Foo` 实际上在“全局虚槽位编号”里可能不是 0，而是往后排。
>
> 右边（Implementation Table）：
>
> - index0：`A.Foo code ptr`
> - index1：`A.Bar code ptr`
>
> 说明：A 自己引入了两个虚方法体（Foo/Bar）。
>
> 右边（Slot Map）分两块（很关键）：
>
> ### 2.1 `ID for A` 那块：
>
> - `(4, scope A, 0*)`
> - `(5, scope A, 1*)`
>
> 意思是：在“虚槽位编号”的意义下：
>
> - **虚槽位 4** 的实现来自 **A 的实现表 index0（A.Foo）**
> - **虚槽位 5** 的实现来自 **A 的实现表 index1（A.Bar）**
>
> 为什么是 4/5？因为 `Object` 的 4 个虚方法占了 0..3（被省略了），所以 A 的新虚方法从 4 开始。
>
> ### 2.2 `ID for I` 那块：
>
> - `(0, scope virtual, 4)`
>
> 这是最容易卡住的地方：它在说 **接口槽位到类虚槽位的映射**：
>
> - “I.slot0（也就是 I.Foo）”
>   先映射到 “虚槽位 4（也就是 A.Foo 这个虚槽位）”
>
> 也就是：
>
> > I.Foo ——(接口映射)→ 虚槽位 4（A.Foo 那个槽）
>
> 为什么不直接指向 A.Foo 的实现表 index0？
> 因为它想复用“虚分派”的机制：先定位到某个虚槽位，再看真正运行时对象是谁（A 还是 B），最后得到最终 override 的实现。
>
> ## 最下面：class B : A（B override Foo，并引入 Baz）
>
> 左边（Classic Virtual Table）：
>
> - `B.Foo code ptr`（override 了 A.Foo，所以把虚槽位 4 的内容换成 B.Foo）
> - `A.Bar code ptr`（没 override，所以还是 A.Bar）
> - `B.Baz code ptr`（新引入的虚方法，排在后面）
>
> 右边（Implementation Table）：
>
> - index0：`B.Baz code ptr`
> - index1：`B.Foo code ptr`
>
> 注意这里顺序：**先 newslot（Baz），再 override（Foo）**，符合文中规则。
>
> 右边（Slot Map）里 `ID for B`：
>
> - `(6, scope B, 0*)`
> - `(4, scope B, 1)`
>
> 含义：
>
> - 虚槽位 **6** 的实现来自 B 实现表 **index0**（B.Baz）
> - 虚槽位 **4** 的实现来自 B 实现表 **index1**（B.Foo，override 的那个）
>
> 这里没有 `ID for I` 的映射块，是因为 **B 没有改变“接口 I.slot0 映射到哪个虚槽位”** 这件事——它仍然是走父类 A 的映射：I.slot0 → 虚槽位 4。
>
> ## 用图走一遍：为什么调用 I.Foo 最终会到 B.Foo？
>
> 假设：
>
> ```
> I x = new B();
> x.Foo();
> ```
>
> 运行时查找：
>
> 1. 从 **B 的 Slot Map** 开始找 “ID for I, slot0”的映射
>    - B 里没有（图中确实没画）
> 2. 去父类 **A 的 Slot Map** 找
>    - 找到：`I.slot0 -> virtual slot 4`
> 3. 现在我们知道：调用应该走“虚槽位 4”
>    接下来回到“实际对象类型” **B** 的映射里查虚槽位 4：
>    - 在 B 的 `ID for B` 块里找到：`virtual slot 4 -> scope B, index1`
>    - B 的实现表 index1 是 `B.Foo`
>
> 因此最终执行 **B.Foo**。

### 额外用途

需要注意的是：该映射技术可用于实现 methodimpl 对虚槽位的重映射（即当前类的映射中包含一个“虚槽位映射”，类似于接口槽位映射到虚槽位的方式）。由于映射具备作用域（scoping）能力，也可以引用非虚方法。如果将来运行时希望支持用非虚方法来实现接口，这可能会很有用。

### 优化

槽位映射采用位编码，并利用典型接口实现模式中的 delta 值，从而显著减小映射大小。此外，新槽位（包括虚与非虚）可以由其在实现表中的顺序推导出来：如果实现表包含“新虚槽位 -> 新实例槽位 -> 重写”，那么合适的槽位映射条目就可以由实现表中的索引与父类继承的虚方法数共同推导出来。所有这类可推导的映射条目都用（\*）标注。当前数据结构布局采用如下模式，其中仅当无法由实现表顺序完全推导映射时，才会存在 DispatchMap。

	MethodTable -> [DispatchMap ->] ImplementationTable

> 运行时为了把“接口方法调用”和“虚方法调用”都快速定位到**最终要执行的那段代码**，维护了两类结构：
>
> 1. **Implementation Table（实现表）**：本类型“真正提供的那些方法体”的数组（存的是入口点指针）。
> 2. **Slot Map（槽位映射）**：把“某个 type（接口或本类）里的某个 slot”映射到“该去执行哪里”（实现表的某个 index，或某个虚槽位）。
>
> ### “slot（槽位）”是什么？
>
> 可以把 **slot** 理解成“一个方法在某个表里的编号”。
>
> - **接口 I** 里 `Foo()` 是第 0 个方法，所以叫 **I.slot0**。
> - **类的虚表（vtable）**里每个虚方法也占一个槽位：比如 `A.Foo`、`A.Bar` 等。
>
> ### Implementation Table（实现表）是什么？
>
> 它是“这个类型自己引入/提供的方法体”的顺序表。图中的文字也说了顺序是：
>
> 1. newslot 虚方法（新引入的虚方法）
> 2. newslot 非虚方法（实例/静态）
> 3. override 虚方法（重写的虚方法）
>
> 图右侧的 “Implementation Table” 方框，就是这个数组。
>
> ### Slot Map（槽位映射）是什么？
>
> 它是一张“查表规则”，键是：**(type-id, slot)**
> 值是：最终该跳到哪里（两种可能）：
>
> - `scope = virtual`：值是一个**虚槽位号**，表示“先把接口槽位映射到类的某个虚槽位”，然后再按虚分派规则找最终实现。
> - `scope = 某个类（A/B…）`：值是该类实现表里的 **index**，表示“直接就是这个类实现表的第几个方法体”。

类型 ID 映射（Type ID Map）
-----------

它将把类型映射到 ID：当遇到此前尚未映射的类型时，为其分配一个单调递增的值。当前，这些类型全部都是接口。

目前这通过 HashMap 实现，并且同时包含两种方向的查找条目。

分派 Token
---------------

分派 token 将是 <_typeID_,_slot_> 二元组。对于接口来说，type 是分配给该接口的接口 ID。对于虚方法来说，type 将是一个常量值，用于指示该槽位应当在被分派的类型内部以虚方式解析（即对 _this_ 的虚方法调用）。在多数情况下，这对值能够放入平台的机器字大小中。在 x86 上，它很可能是：每个值取低 16 位并拼接。可以更一般化地处理溢出问题，类似于运行时中的 _TypeHandle_ 既可以是一个 _MethodTable_ 指针，也可以是一个 <_TypeHandle,TypeHandle_> 对，并用一个哨兵位来区分两种情况。是否需要这样做尚未确定。

虚拟存根分派的设计
===============================

从分派 Token 到实现的解析
-------------------------------------------

给定一个 token 与一个类型，实现将通过把 token 映射到该类型的实现表索引来找到。实现表可从该类型的 MethodTable 到达。这个映射在 BuildMethodTable 中创建：它会枚举正在为其构建 MethodTable 的类型所实现的全部接口，并确定该类型实现或重写的每个接口方法。通过跟踪这些信息，在接口分派时，就可以根据 token 与目标对象确定目标代码——从目标对象可以获得 MethodTable 与 token 映射。

存根（Stubs）
-----

接口分派调用会经过存根。这些存根都是按需生成的，并且其最终目的都是：把 token 与对象匹配到一个实现，并把调用转发到该实现。

目前共有三类存根。下图展示了这些存根之间的一般控制流，下面会逐一解释。

![Figure 2](./asserts/virtualstubdispatch-fig2.png)

### 通用解析器（Generic Resolver）

这实际上只是一个 C 函数，作为所有存根的最终失败路径。它接收一个 `<_token_, _type_>` 二元组并返回目标。通用解析器还负责：在需要时创建分派存根与解析存根、当更好的存根可用时修补间接单元（indirection cell）、缓存结果，以及所有簿记（bookkeeping）工作。

### 查找存根（Lookup Stubs）

这些存根是最先被分配给某个接口分派调用点的存根，并在 JIT 编译某个接口调用点时创建。由于在第一次调用发生之前，JIT 并不知道将使用何种类型来满足某个 token，因此该存根会把 token 与 type 作为参数传给通用解析器。如有必要，通用解析器也会创建分派存根与解析存根，并回填（back patch）调用点，让其指向分派存根，从而不再使用查找存根。

每个唯一 token（即每个唯一的接口槽位）都会创建一个查找存根（也就是说，对同一接口槽位的多个调用点会使用同一个查找存根）。

### 分派存根（Dispatch Stubs）

当某个调用点被认为在行为上是单态（monomorphic）时，会使用分派存根。这意味着：某个特定调用点使用的对象通常都是同一类型（也就是，大多数时候，在同一调用点被调用的对象类型与上一次调用该点时一致）。分派存根会取出被调用对象的类型（MethodTable）并与其缓存的类型进行比较；若比较成功则跳转到其缓存的目标。在 x86 上，这通常是“比较、条件失败跳转、跳转到目标”的序列，并且能提供所有存根中最好的性能。如果类型比较失败，它会跳转到对应的解析存根（见下文）。

每个唯一的 <_token_,_type_> 二元组都会创建一个分派存根，但它只会在某个调用点的查找存根被触发时才惰性创建。

### 解析存根（Resolve Stubs）

多态（polymorphic）调用点由解析存根处理。这些存根使用键对 <_token_, _type_> 在全局缓存中解析目标：其中 _token_ 在 JIT 时已知，而 _type_ 在调用时确定。如果全局缓存中没有匹配项，那么解析存根的最终步骤就是调用通用解析器并跳转到其返回的目标。由于通用解析器会把 <_token_, _type_, _target_> 三元组插入缓存，因此后续使用相同 <_token_, _type_> 二元组的调用将能在缓存中成功找到目标。

当某个分派存根频繁失败时，该调用点会被判定为多态，并且解析存根会回填调用点，使其直接指向解析存根，从而避免总是失败的分派存根带来的开销。在同步点（目前是 GC 结束时），多态调用点会随机被提升回单态调用点，假设调用点的多态属性通常是暂时的。如果这个假设对某个调用点不成立，它会很快触发回填，从而再次被降级为多态。

每个 token 会创建一个解析存根，但它们都共享一个全局缓存。按 token 生成存根，使得可以使用基于 <_token_, _type_> 二元组中“不会变化的部分”预先计算出的哈希值，从而实现快速、有效的哈希算法。

### 代码序列

先前的接口虚表分派机制所产生的代码序列大致如下：

![Figure 3](./asserts/virtualstubdispatch-fig3.png)

而典型的存根分派序列是：

![Figure 1](./asserts/virtualstubdispatch-fig4.png)

其中 expectedMT、failure 与 target 都是编码在存根里的常量。

典型存根序列与旧的接口分派机制有相同数量的指令；更少的内存间接访问可能使其在更小的工作集贡献下执行得更快。它还会产生更小的 JIT 代码，因为大部分工作在存根中完成，而不是在调用点中完成。只有当调用点很少被调用时，这才有优势。注意：失败分支的布局方式使得 x86 分支预测会倾向于走成功路径。

当前状态
=============

目前，VSD 只对接口方法调用启用，而对虚实例方法调用不启用。原因有几项：

- **启动：** 由于需要生成大量初始存根，启动工作集与速度都会受到影响。
- **吞吐：** 虽然接口分派通常在 VSD 下更快，但虚实例方法调用会遭遇不可接受的性能下降。

由于禁用了 VSD 用于虚实例方法调用，每个类型都为虚实例方法保留了一个 vtable，上文描述的实现表也被禁用。分派映射仍然存在，以支持接口方法分派。

物理架构
====================

关于分派 token 与映射的实现细节，请参阅 [clr/src/vm/contractImpl.h](https://github.com/dotnet/runtime/blob/main/src/coreclr/vm/contractimpl.h) 与 [clr/src/vm/contractImpl.cpp](https://github.com/dotnet/runtime/blob/main/src/coreclr/vm/contractimpl.cpp)。

关于虚拟存根分派的实现细节，请参阅 [clr/src/vm/virtualcallstub.h](https://github.com/dotnet/runtime/blob/main/src/coreclr/vm/virtualcallstub.h) 与 [clr/src/vm/virtualcallstub.cpp](https://github.com/dotnet/runtime/blob/main/src/coreclr/vm/virtualcallstub.cpp)。
