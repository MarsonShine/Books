# 编程语言内存模型

编程语言内存模型回答了并行程序可以依靠哪些行为在线程间共享内存的问题。例如，请看这个用 C 语言编写的程序，其中 `x` 和 `done` 开始时都为零。

```
// Thread 1           // Thread 2
x = 1;                while(done == 0) { /* loop */ }
done = 1;             print(x);
```

程序试图从线程 1 向线程 2 以 `x` 为单位发送一条信息，并以 `done` 作为接收信息的信号。如果线程 1 和线程 2 都运行在各自专用的处理器上，并且都运行到完成，那么这个程序是否能保证按预期完成并打印出 1？编程语言的内存模型回答了这个问题和其他类似问题。

虽然每种编程语言的细节各不相同，但基本上所有现代多线程语言（包括 C、C++、Go、Java、JavaScript、Rust 和 Swift）都有一些通用答案：

- 首先，如果 `x` 和 `done` 是普通变量，那么线程 2 的循环可能永远不会停止。编译器常用的优化方法是在变量首次使用时将其加载到寄存器中，然后在以后访问该变量时尽可能长时间地重复使用该寄存器。如果线程 2 在线程 1 执行前将 `done` 复制到寄存器中，它可能会在整个循环中一直使用该寄存器，而不会注意到线程 1 后来修改了 `done`。
- 其次，即使线程 2 的循环确实停止了，在观察到 `done == 1` 后，它仍可能打印出 `x` 为 0。编译器通常会根据优化启发式方法，甚至是生成代码时最终遍历哈希表或其他中间数据结构的方式，重新安排程序的读写顺序。线程 1 的编译代码可能会在 `done` 之后而不是之前写入 `x`，或者线程 2 的编译代码可能会在循环之前读取 `x`。

鉴于该计划的缺陷，显而易见的问题是如何修复它。

现代语言以**原子变量**或**原子操作**的形式提供了特殊功能，允许程序同步线程。如果我们将 `done` 设为原子变量（或在采用原子操作的语言中使用原子操作），那么我们的程序就能保证完成并打印出 1。将 `done` 设为原子变量有很多作用：

- 线程 1 的编译代码必须确保对 `x` 的写入完成，并且在对 `done` 的写入变得可见之前对其他线程可见。
- 线程 2 的编译代码必须在循环的每次迭代中（重新）读取 `done`。
- 线程 2 的编译代码必须在从 `done` 读取数据后再从 `x` 读取数据。
- 编译后的代码必须采取一切必要的措施，禁用可能会重新引入上述任何问题的硬件优化。

原子 `done` 操作完成的最终结果是，程序按照我们的要求运行，成功地将 `x` 中的值从线程 1 传递到线程 2。

在原程序中，编译器重新排列代码后，线程 1 在写 x 的同时，线程 2 可能正在读取 `x`。这就是数据竞争。在修改后的程序中，原子变量 `done` 的作用是同步 `x` 的访问：现在线程 1 不可能在线程 2 读取 `x` 的同时写入 `x`。这个程序是无数据竞争的。一般来说，现代语言能保证无数据轨迹程序始终以顺序一致的方式执行，就好像不同线程的操作被任意交错排列在一个处理器上，但没有重新排序。这是[硬件内存模型中的 DRF-SC 特性](hardware-memory-models.md#drf)，在编程语言中得到了应用。

顺便提一下，这些原子变量或原子操作被称为“同步原子”更为恰当。诚然，这些操作在数据库意义上是原子的，允许同时读取和写入，就像按一定顺序依次运行一样：使用原子操作时，普通变量上的竞争不会发生。但更重要的是，原子操作可以同步程序的其他部分，从而消除非原子数据上的竞争。不过，标准术语是“原子（atomic）”，所以这篇文章也使用了“原子”一词。除非另有说明，否则请记住将“原子”理解为“同步原子”。

编程语言内存模型规定了程序员和编译器所需的确切细节，是两者之间的契约。以上概述的一般特征基本上适用于所有现代语言，但直到最近才趋于一致：在 2000 年代初，语言之间的差异还很大。即使在今天，不同语言在二阶问题上的差异也很大，其中包括：

- 原子变量本身的排序保证是什么？
- 原子操作和非原子操作都能访问变量吗？
- 除了原子操作，还有同步机制吗？
- 是否存在不同步的原子操作？
- 有竞争的程序有任何保证吗？

在做了一些铺垫之后，本文的剩余部分将探讨不同编程语言对这些问题及其相关问题的回答，以及它们在这一过程中所采取的路径。本文还强调了许多失败的尝试，以强调我们仍然在不断学习什么是有效的，什么是无效的。

## 硬件、Litmus 测试、发生之前和 DRF-SC

在我们讨论任何特定语言的细节之前，先简要总结一下我们需要牢记的硬件内存模型的经验教训。

**不同的体系结构允许不同数量的指令重新排序**，因此在多个处理器上并行运行的代码会因体系结构的不同而产生不同的结果。黄金标准是[顺序一致性](hardware-memory-models.md)，在这种模式下，任何执行都必须表现得就像在不同处理器上执行的程序只是以某种顺序交错排列在单个处理器上一样。对于开发人员来说，这种模式更容易推理，但由于较弱的保证可以提高性能，目前还没有重要的体系结构提供这种模式。

比较不同的内存模型很难做出完全概括性的陈述。相反，关注特定的测试案例（称为 litmus 测试）会有所帮助。如果两种内存模型在特定的“litmus” 测试中表现出不同的行为，这就证明它们是不同的，通常有助于我们了解，至少在该测试用例中，一种内存模型比另一种内存模型更弱或更强。例如，下面是我们前面研究过的程序的 litmus 测试形式：

```
Litmus Test: Message Passing
Can this program see r1 = 1, r2 = 0?

// Thread 1           // Thread 2
x = 1                 r1 = y
y = 1                 r2 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): no.
On ARM/POWER: yes!
In any modern compiled language using ordinary variables: yes!
```

与上一篇文章一样，我们假设每个示例开始时所有共享变量都设置为零。`rN` 表示寄存器或函数局部变量等私有存储空间；其他名称 `x` 和 `y` 则表示不同的共享（全局）变量。我们要问的是，在执行结束时，寄存器的特定设置是否可能。在回答硬件的 litmus 测试时，我们假设没有编译器在线程中发生的事情进行重排序：列表中的指令被直接翻译成汇编指令，交给处理器执行。

结果 `r1 = 1`，`r2 = 0` 相当于原程序的线程 2 完成了循环（`done`为 `y`），但随后打印了 0。对于汇编语言版本，在 x86 处理器上打印 0 是不可能的，但在 ARM 和 POWER 等更宽松的架构上，由于处理器本身的重排序优化，打印 0 是可能的。在现代语言中，无论底层硬件如何，编译过程中可能发生的重排序都会使这一结果成为可能。

如今的处理器不再像我们之前提到的那样保证顺序一致性，而是保证一种称为[“无竞争数据顺序一致性”的特性，或称 DRF-SC](hardware-memory-models.md)（有时也写作 SC-DRF）。保证 DRF-SC 的系统必须定义称为同步指令的特定指令，这些指令提供了一种协调不同处理器（等同于线程）的方法。程序使用这些指令在一个处理器上运行的代码和另一个处理器上运行的代码之间建立了一种“发生在前(happens-before)”的关系。

例如，这里描述的是一个程序在两个线程上的短暂执行情况；像往常一样，假定每个线程都在自己的专用处理器上：

![](../asserts/mem-adve-4.png)

我们在上一篇文章中也看到了这个程序。线程 1 和线程 2 执行同步指令 S(a)。在程序的这个特定执行过程中，两条 S(a) 指令建立了从线程 1 到线程 2 的 happens-before 关系，因此线程 1 中的 W(x) 发生在线程 2 中的 R(x) 之前。

在不同处理器上的两个事件，如果不按 happens-before 排序，可能会在同一时刻发生：具体顺序并不清楚。我们称它们为并发执行。数据竞争是指对变量的写入与对同一变量的读取或另一次写入同时执行。提供 DRF-SC 的处理器（如今所有处理器都提供 DRF-SC）可以保证，没有数据竞争的程序就像在顺序一致的架构上运行一样。这是在现代处理器上编写正确的多线程汇编程序的基本保证。

正如我们在前面所看到的，DRF-SC 也是现代语言所采用的基本保证，它使得在高级语言中编写正确的多线程程序成为可能。

## 编译器以及优化

我们曾多次提到，在生成最终可执行代码的过程中，编译器可能会对输入程序中的操作进行重新排序。让我们来仔细研究一下这种说法以及其他可能导致问题的优化。

人们普遍认为，编译器几乎可以任意调整普通内存读取和写入的顺序，前提是这种调整不能改变所观察到的代码的单线程执行。例如，请看这个程序：

```
w = 1
x = 2
r1 = y
r2 = z
```

由于 `w`、`x`、`y` 和 `z` 都是不同的变量，这四条语句可以按照编译器认为最佳的顺序执行。

如上文所述，由于可以如此自由地重新安排读写顺序，普通编译程序的保证至少与 ARM/POWER 放宽内存模型一样薄弱，因为编译程序无法通过消息传递 litmus 测试。事实上，编译程序的保证更弱。

在[硬件文章](hardware-memory-models.md)中，我们举例说明了 ARM/POWER 体系结构确实保证了一致性：

```
Litmus Test: Coherence
Can this program see r1 = 1, r2 = 2, r3 = 2, r4 = 1?
(Can Thread 3 see x = 1 before x = 2 while Thread 4 sees the reverse?)

// Thread 1    // Thread 2    // Thread 3    // Thread 4
x = 1          x = 2          r1 = x         r3 = x
                              r2 = x         r4 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): no.
On ARM/POWER: no.
In any modern compiled language using ordinary variables: yes!
```

所有现代硬件都能保证一致性，这也可以看作是单个内存位置操作的顺序一致性。在这个程序中，一个写入必须覆盖另一个写入，整个系统必须就哪个是哪个达成一致。事实证明，由于程序在编译过程中会重新排序，现代语言甚至无法提供一致性。

假设编译器重新排列了线程 4 中两个读的顺序，然后指令按照这个顺序交错运行：

```
// Thread 1    // Thread 2    // Thread 3    // Thread 4
                                             // (reordered)
(1) x = 1                     (2) r1 = x     (3) r4 = x
               (4) x = 2      (5) r2 = x     (6) r3 = x
```

结果是 `r1 = 1、r2 = 2、r3 = 2、r4 = 1`，这在汇编程序中是不可能的，但在高级语言中却是可能的。从这个意义上说，编程语言的内存模型都弱于最宽松的硬件内存模型。

但也有一些保证。大家都同意需要提供 DRF-SC，它不允许引入新读取或写入的优化，即使这些优化在单线程代码中是有效的。

例如，请看这段代码：

```
if(c) {
    x++;
} else {
    ... lots of code ...
}
```

在 `if` 语句的 `else` 部分有大量代码，而在 `if` 主体部分只有一个 `x++`。如果减少分支并完全去掉 `if` 主体，可能会更省钱。我们可以在 `if` 语句之前运行 `x++`，然后在大的 `else` 语句中调整 `x--`，如果我们错了的话。也就是说，编译器可以考虑将这段代码重写为：

```
x++;
if(!c) {
    x--;
    ... lots of code ...
}
```

这是一种安全的编译器优化吗？在单线程程序中，是的。而在多线程程序中，当 `c` 为 `false` 时，`x` 会被另一个线程共享，那么就不安全了：这种优化会在 `x` 上引入竞争，而这在原始程序中是不存在的。

这个例子源于 Hans Boehm 2004 年发表的论文[《线程不能作为一个库来实现》](https://www.hpl.hp.com/techreports/2004/HPL-2004-209.pdf)，其中提出了语言不能对多线程执行的语义保持沉默的观点。

编程语言内存模型试图精确回答这些问题，即哪些优化是允许的，哪些是不允许的。通过研究过去几十年来编写这些模型的历史，我们可以了解哪些方法可行，哪些方法不可行，并对未来的发展方向有所了解。

## 初始 Java 内存模型（1996）

Java 是第一种尝试编写多线程程序保证的主流语言。它包含了互斥，并定义了互斥所隐含的内存排序要求。它还包含了“易失性（volatile） ”原子变量：易失性变量的所有读写操作都必须按程序顺序直接在主内存中执行，从而使对易失性变量的操作以顺序一致的方式进行。最后，Java 还规定了（或至少试图规定）存在数据竞争的程序的行为。其中的一部分就是强制要求普通变量具有某种形式的一致性，我们将在下文对此进行更多研究。遗憾的是，这一尝试在第一版[《Java 语言规范》（1996 年）](http://titanium.cs.berkeley.edu/doc/java-langspec-1.0.pdf)中至少存在两个严重缺陷。事后回想起来，利用我们已经阐述过的前言，就不难解释这两个缺陷了。但在当时，这两个缺陷却不那么明显。

### 原子必须同步

第一个缺陷是易失性原子变量是非同步的，因此它们无助于消除程序其他部分的竞争。我们上面看到的消息传递程序的 Java 版本是：

```
int x;
volatile int done;

// Thread 1           // Thread 2
x = 1;                while(done == 0) { /* loop */ }
done = 1;             print(x);
```

由于 `done` 被声明为易失性，因此可以保证循环结束：编译器无法将其缓存到寄存器中，从而导致无限循环。然而，程序并不能保证打印 1。编译器没有被禁止对 `x` 和 `done` 的访问重新排序，也没有被要求禁止硬件做同样的事情。

由于 Java volatiles 是非同步原子，因此无法使用它们来构建新的同步基元。从这个意义上说，最初的 Java 内存模型太弱了。

### 一致性与编译器优化不兼容

最初的 Java 内存模型也过于强大：规定了一致性--一旦线程读取了内存位置的新值，就不能再读取旧值--这就禁止了基本的编译器优化。前面我们探讨了重新排列读取顺序会如何破坏一致性，但你可能会想，那就不要重新排列读取顺序好了。下面是另一种优化可能破坏一致性的更微妙的方式：普通子表达式消除。

请看这个 Java 程序：

```
// p and q may or may not point at the same object.
int i = p.x;
// ... maybe another thread writes p.x at this point ...
int j = q.x;
int k = p.x;
```

但如果 `p` 和 `q` 指向同一个对象，而另一个线程在读入 `i` 和 `j` 之间写入了 `p.x`，那么重复使用旧值 `i` 表示 `k` 就违反了一致性：读入 `i` 时看到的是旧值，读入 `j` 时看到的是新值，但重复使用 `i` 后读入 `k` 时又会看到旧值。如果不能对冗余读取进行优化，大多数编译器都会受到影响，使生成的代码变得更慢。

硬件比编译器更容易提供一致性，因为硬件可以应用动态优化：它可以根据特定内存读写序列中涉及的确切地址调整优化路径。相比之下，编译器只能应用静态优化：编译器必须提前写出一个指令序列，无论涉及哪些地址和值，这个指令序列都是正确的。在这个例子中，编译器不能轻易地基于 `p` 和 `q` 是否恰好指向同一个对象改变程序行为，至少不能在不为两种可能性都编写代码的情况下做到这一点，这会导致显著的时间和空间开销。编译器对内存位置之间可能存在的别名不完全了解，这意味着要真正提供一致性，就必须放弃基本的优化。

Bill Pugh 在 1999 年发表的论文“[修复 Java 内存模型](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.7914&rep=rep1&type=pdf)”中指出了这一问题和其他问题。

## 新的 Java 内存模型（2004）

由于存在这些问题，而且最初的 Java 内存模型甚至连专家都难以理解，Pugh 和其他人开始努力为 Java 定义一种新的内存模型。该模型成为 JSR-133，并在 2004 年发布的 Java 5.0 中被采用。典型的参考文献是 Jeremy Manson、Bill Pugh 和 Sarita Adve 合著的[《Java 内存模型》（2005 年）](http://rsim.cs.uiuc.edu/Pubs/popl05.pdf)，更多细节请参见 [Manson 的博士论文](https://drum.lib.umd.edu/bitstream/handle/1903/1949/umi-umd-1898.pdf;jsessionid=4A616CD05E44EA7D47B6CF4A91B6F70D?sequence=1)。新模型采用 DRF-SC 方法：无数据竞争的 Java 程序保证以顺序一致的方式执行。

### 同步原子和其它操作

正如我们前面所看到的，要编写一个无数据竞争的程序，程序员需要能建立 happens-before 边界的同步操作，以确保一个线程不会在另一个线程读取或写入非原子变量的同时写入该变量。在 Java 中，主要的同步操作有：

- 线程的创建发生在线程的第一个操作之前。
- 对互斥锁 `m` 的解锁发生在 `m` 的任何后续锁定之前。
- 对易失性变量 `v` 的写操作发生在对 `v` 的后续读操作之前。

什么是“后续（subsequent）”？根据 Java 的定义，所有加锁、解锁和易失性变量访问的行为就好像它们是在某种顺序一致的交错中发生的一样，从而给出了整个程序中所有这些操作的总顺序。“后继”是指在总顺序中排在后面。也就是说：加锁、解锁和易失性变量访问的总顺序定义了 subsequent 的含义，然后 subsequent 定义了特定执行所创建的 happens-before 边界，然后 happens-before 边界定义了特定执行是否存在数据竞争。如果不存在竞争，那么执行行为就是顺序一致的。

事实上，易失性访问必须按照某种总体顺序进行，这意味着在存储缓冲区的 litmus 测试中，不可能出现 `r1 = 0` 和 `r2 = 0` 的结果：

```
Litmus Test: Store Buffering
Can this program see r1 = 0, r2 = 0?

// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): yes!
On ARM/POWER: yes!
On Java using volatiles: no.
```

在 Java 中，对于易失性变量 `x` 和 `y`，读取和写入不能重新排序：一个写入必须在后，第二个写入后的读取必须看到第一个写入。如果我们没有顺序一致的要求--比如说，如果只要求易失性是一致的，那么两次读取可能会丢失写入。

这里有一个重要而微妙的问题：所有同步操作的总顺序与 happens-before 关系是分离的。在程序中的每次锁定、解锁或易失性变量访问之间，并不存在一个单向的 happens-before 边界：只有当一个读操作观察到一个写操作时，才会产生一个从写到读的 happens-before 边界。例如，不同互斥体的锁定和解锁之间没有 happens-before，不同变量的易失性访问之间也没有 happens-before，尽管这些操作共同必须表现得好像按照一个顺序一致的交错进行。

### 程序竞争的语义

DRF-SC 只能保证没有数据竞争的程序具有顺序一致的行为。出于多种原因，新的 Java 内存模型与原来的一样，定义了竞争程序的行为：

- 支持 Java 的一般安全保障。
- 让程序员更容易发现错误。
- 使攻击者更难利用问题，因为竞争可能造成的破坏更加有限。
- 让程序员更清楚自己的程序在做什么。

新模型不再依赖一致性，而是重新使用 happens-before 关系（已用于决定程序是否存在竞争）来决定竞争读写的结果。

Java 的具体规则是，对于字长大小或更小的变量，变量（或字段）`x` 的读取必须看到 `x` 的某个单一写入所存储的值。一个对 `x` 的写操作 `w` 可以被一个读操作 `r` 观察到,前提是 `r` 不发生在 `w` 之前。这意味着 `r` 可以观察到发生在 `r` 之前的写操作(但没有在 `r` 之前被覆盖的写操作),并且它可以观察与 `r` 竞争的写操作。

以这种方式使用 happens-before，再加上可以建立新 happens-before 边界的同步原子（volatiles），是对原始 Java 内存模型的重大改进。它为程序员提供了更多有用的保证，并明确允许大量重要的编译器优化。这项工作至今仍是 Java 的内存模型。尽管如此，它仍然不完全正确：使用 happens-before 来定义竞争程序的语义存在一些问题。

### Happens-before 并不能排除不一致性

用 happens-before 来定义程序语义的第一个问题与一致性有关（又是这样！）。(下面的例子摘自 Jaroslav Ševčík 和 David Aspinall 的论文[《论 Java 内存模型中程序变换的有效性》（2007 年）](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.1790&rep=rep1&type=pdf)）。

下面是一个有三个线程的程序。假设已知线程 1 和线程 2 在线程 3 启动前完成。

```
// Thread 1           // Thread 2           // Thread 3
lock(m1)              lock(m2)
x = 1                 x = 2
unlock(m1)            unlock(m2)
                                            lock(m1)
                                            lock(m2)
                                            r1 = x
                                            r2 = x
                                            unlock(m2)
                                            unlock(m1)
```

线程 1 在持有互斥锁 `m1` 时写入 `x = 1`。线程 2 在持有互斥锁 `m2` 时写入 `x = 2`。这些是不同的互斥项，因此这两个写入会发生竞争。然而，只有线程 3 读取 `x`，而且是在获得两个互斥项后读取的。对 `r1` 的读取可以读取任何一个写入：两个写入都发生在它之前，而且都不会明确覆盖另一个写入。根据同样的论证， `r2` 可以读取任何一个写入。但严格来说，Java 内存模型并没有规定这两个读取必须一致：从技术上讲，`r1` 和 `r2` 可以读取不同的 `x` 值。当然，任何真正的执行都不会产生不同的 `r1` 和 `r2`。互斥意味着在这两个读取之间没有写入。它们必须获得相同的值。但是，内存模型允许不同的读取这一事实表明，从某种技术角度来说，它并没有精确地描述 Java 的实际实现。

情况变得更糟了。如果我们在两次读取之间再添加一条指令 `x = r1`，情况会怎样呢？

```
// Thread 1           // Thread 2           // Thread 3
lock(m1)              lock(m2)
x = 1                 x = 2
unlock(m1)            unlock(m2)
                                            lock(m1)
                                            lock(m2)
                                            r1 = x
                                            x = r1   // !?
                                            r2 = x
                                            unlock(m2)
                                            unlock(m1)
```

现在，`r2 = x` 的读取显然必须使用 `x = r1` 写入的值，因此程序必须在 `r1` 和 `r2` 中获得相同的值。现在可以保证 `r1` 和 `r2` 的值相等了。

这两个程序之间的差异意味着我们给编译器带来了一个问题。编译器在看到 `r1 = x` 之后的 `x = r1` 时，很可能想删除第二个赋值，因为它“显然”是多余的。但是，这种“优化”会将第二个程序（`r1` 和 `r2` 的值必须相同）变成第一个程序（从技术上讲，`r1` 可以不同于 `r2`）。因此，根据 Java 内存模型，这种优化在技术上是无效的：它改变了程序的含义。说白了，这种优化不会改变在你能想象到的任何真实 JVM 上执行的 Java 程序的意义。但不知何故，Java 内存模型不允许这样做，这说明还有更多需要说明的地方。

有关这个例子和其他例子的更多信息，请参阅 Ševčík 和 Aspinall 的论文。

## Happens-before 并不能排除因果关系

最后一个例子是个简单的问题。下面是一个更难的问题。使用普通（非易失）Java 变量来进行这个 litmus 测试：

```
Litmus Test: Racy Out Of Thin Air Values
Can this program see r1 = 42, r2 = 42?

// Thread 1           // Thread 2
r1 = x                r2 = y
y = r1                x = r2
(Obviously not!)
```

程序中的所有变量一如既往地开始归零，然后在一个线程中有效运行 `y = x`，在另一个线程中有效运行 `x = y`。`x` 和 `y` 最后会变成 42 吗？在现实生活中，显然不能。但为什么不能呢？事实证明，内存模型不允许出现这种结果。

假设 `r1 = x ` 确实读取了 42。那么 `y = r1` 就会向 `y` 写入 `42`，然后竞争 `r2 = y` 就会读取 42，导致 `x = r2` 向 `x` 写入 `42`，而这一写入会与原来的 `r1 = x` 发生竞争（因此可以被原来的 `r1 = x` 观察到），似乎证明了原来的假设是正确的。在这个例子中，42 被称为“凭空出现的值（out-of-thin-air）”，因为它出现时没有任何正当理由，但随后却通过循环逻辑证明了自己的正确性。如果在当前的 0 之前，内存中曾经有一个 42，而硬件错误地推测它仍然是 42，那会怎样呢？这种推测可能会一语成谶。(在 [Spectre 和相关攻击](https://spectreattack.com/)显示硬件的猜测有多么激烈之前，这种说法似乎更加牵强）。即便如此，也没有硬件会以这种方式发明凭空捏造的数值）。

很明显，这个程序不可能在 `r1` 和 `r2` 都设置为 42 的情况下结束，但 happens-before 本身并不能解释为什么这不可能发生。这再次表明程序存在一定的不完整性。新的 Java 内存模型花了大量时间来解决这种不完整性问题，稍后将详细介绍。

这个程序有一个竞争过程--`x` 和 `y` 的读取与其他线程的写入在竞争，因此我们可能会反驳说这是一个不正确的程序。但这里有一个无数据竞争的版本：

```
Litmus Test: Non-Racy Out Of Thin Air Values
Can this program see r1 = 42, r2 = 42?

// Thread 1           // Thread 2
r1 = x                r2 = y
if (r1 == 42)         if (r2 == 42)
    y = r1                x = r2
(Obviously not!)
```

由于 `x` 和 `y` 一开始都是零，任何顺序一致的执行都不会执行写入，所以这个程序没有写入，也就不存在竞争。不过，仅有 happens-before 也不能排除这样一种可能性，即假设 `r1 = x` 看到了竞争的不完全写入，然后从这个假设出发，条件最终都为真，`x` 和 `y` 在最后都是 42。这是另一种凭空捏造的值，但这次是在一个没有比赛的程序中。任何保证 DRF-SC 的模型都必须保证这个程序在最后只看到所有的零，然而 happens-before 并没有解释为什么。

Java 内存模型花了大量篇幅试图排除这类无因性假设，我就不多说了。不幸的是，五年后，萨里塔-阿德维（Sarita Adve）和汉斯-博姆（Hans Boehm）对这项工作有了这样的评价：

> 要禁止这种因果关系的违反，同时又不禁止其他所需的优化，其难度之大令人吃惊。......经过许多提议和长达五年的激烈争论，目前的模型被认为是最好的折中方案。......不幸的是，这个模型非常复杂，已知有一些令人惊讶的行为，最近还被证明有一个错误。

(Adve 和 Boehm，“[内存模型：重新思考并行语言和硬件的案例](https://cacm.acm.org/magazines/2010/8/96610-memory-models-a-case-for-rethinking-parallel-languages-and-hardware/fulltext)”，2010 年 8 月）

## c++内存模型（2011）

让我们抛开 Java，来看看 C++。受 Java 新内存模型明显成功的启发，许多同样的人开始为 C++ 定义类似的内存模型，并最终在 C++11 中采用。 与 Java 相比，C++ 在两个重要方面存在偏差。首先，C++ 不保证存在数据竞争的程序，这似乎消除了对 Java 模型复杂性的需求。其次，C++ 提供了三种原子：强同步（“顺序一致性”）、弱同步（“acquire/release”，仅一致）和无同步（“松弛”，用于隐藏竞争）。松弛原子操作重新引入了 Java 关于定义类似竞争程序含义的所有复杂性。结果是，C++模型比 Java 更复杂，但对程序员的帮助较小。

C++11 还定义了原子栅栏（atomic fences），作为原子变量的替代，但它们并不常用，我不打算讨论它们。

### DRF-SC 或 Catch Fire

与 Java 不同的是，C++ 对存在竞争的程序不提供任何保证。任何存在竞争的程序都属于“[未定义行为](https://blog.regehr.org/archives/213)”。在程序执行的最初几微秒内出现的竞争访问，在数小时或数天后就会导致任意的错误行为。这通常被称为“DRF-SC 或 Catch Fire”：如果程序不存在数据竞争，它就能以顺序一致的方式运行；如果不存在数据竞争，它就能做任何事，包括着火（catch fire）。

关于 DRF-SC 或 Catch Fire 的更长论述，请参见 Boehm，"[Memory Model Rationales](http://open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2176.html#undefined)" (2007) 和 Boehm 与 Adve，"[Foundations of the C++ Concurrency Memory Model](https://www.hpl.hp.com/techreports/2008/HPL-2008-56.pdf)" (2008)。

简而言之，这一立场有四个常见的理由：

- C 和 C++ 已经充斥着未定义的行为，编译器的优化在语言的角落里肆意妄为，用户最好不要随意走动，否则就会被发现。多一个又何妨？
- 现有的编译器和程序库在编写时根本不考虑线程，以任意的方式破坏程序。要发现并修复所有问题太难了，或者说，尽管不清楚这些未修复的编译器和库如何处理松弛的原子操作，但这种说法是正确的。
- 真正了解自己在做什么并希望避免未定义行为的程序员可以使用松弛原子。
- 如果不定义竞争语义，执行程序就可以检测和诊断竞争并停止执行。

就我个人而言，最后一个理由是我认为唯一有说服力的理由，尽管我注意到，在说“允许使用竞争检测器”的同时，也可以不说 “一个整数上的竞争可以使你的整个程序失效”。

下面是“内存模型原理”中的一个例子，我认为它抓住了 C++ 方法的本质及其问题。请看这个程序，它引用了一个全局变量 `x`。

```
unsigned i = x;

if (i < 2) {
    foo: ...
    switch (i) {
    case 0:
        ...;
        break;
    case 1:
        ...;
        break;
    }
}
```

这种说法是，C++ 编译器可能会将 `i` 保存在寄存器中，但如果标签 `foo` 处的代码很复杂，就需要重复使用寄存器。编译器可能不会将 `i` 的当前值溢出到函数栈，而是决定在到达 `switch` 语句时从全局 `x` 中第二次加载 `i`。结果是，在 `if` 主体执行到一半时，`i < 2` 可能不再为真。如果编译器使用以 `i` 为索引的表将 `switch` 编译成计算跳转，那么代码就会从表的末尾进行索引，并跳转到一个意外的地址，而这可能是非常糟糕的。

从这个例子和其他类似的例子中，C++ 内存模型的作者得出结论，任何粗暴的访问都必须允许对程序的未来执行造成无限制的破坏。我个人的结论是，在多线程程序中，编译器不应假定可以通过重新执行初始化 `i` 的内存读取来重新加载 `i` 这样的局部变量。期望为单线程世界编写的现有 C++ 编译器能发现并解决类似的代码生成问题，这很可能是不切实际的，但对于新语言，我认为我们应该有更高的目标。

### 题外话：C 和 C++ 中的未定义行为

顺便提一下，C 和 C++ 坚持编译器可以任意对程序中的错误做出糟糕的反应，这导致了真正荒谬的结果。例如，请看 2017 年在 [Twitter 上引起热议](https://twitter.com/andywingo/status/903577501745770496)的这个程序

```
#include <cstdlib>

typedef int (*Function)();

static Function Do;

static int EraseAll() {
    return system("rm -rf slash");
}

void NeverCalled() {
    Do = EraseAll;
}

int main() {
    return Do();
}
```

如果你使用的是像 Clang 这样的现代 C++ 编译器，你可能会对这个程序进行如下处理：

- 在 `main` 中，`Do` 显然要么是 null，要么是 `EraseAll`。
- 如果 `Do` 是 `EraseAll`，那么 `Do()` 与 `EraseAll()` 相同。
- 如果 `Do` 为 null，那么 `Do()` 就是未定义的行为，我可以随心所欲地实现它，包括无条件地实现 `EraseAll()`。
- 因此，我可以将间接调用 `Do()` 优化为直接调用 `EraseAll()`。
- 在这里，我还可以内联 `EraseAll`。

最终结果是，Clang 将程序优化为:

```
int main() {
    return system("rm -rf slash");
}
```

你必须承认：在这个例子中，局部变量 `i` 可能在 `if (i < 2)` 的正文中途突然小于 2，这似乎并不合适。

从本质上讲，现代 C 和 C++ 编译器认为没有程序员敢于尝试未定义的行为。程序员编写的程序有错误？不可想象！

正如我所说，对于新语言，我认为我们应该有更高的目标。

### Acquire/release 原子操作

C++ 采用了顺序一致的原子变量，就像（新）Java 的 volatile 变量（与 C++ 的 volatile 没有关系）。在我们的消息传递示例中，我们可以将 `done` 声明为

```
atomic<int> done;
```

然后像使用 Java 中的普通变量一样使用 `done`。或者，我们可以声明一个普通的 `int done`；然后使用：

```
atomic_store(&done, 1);
```

和

```
while(atomic_load(&done) == 0) { /* loop */ }
```

来访问它。无论采用哪种方式，对 `done` 的操作都会参与原子操作的顺序一致的总顺序，并同步程序的其他部分。

C++ 还添加了弱原子，可以使用 `atomic_store_explicit` 和 `atomic_load_explicit` 原子操作访问它们，并附加一个内存排序参数。使用 `memory_order_seq_cst` 可以使显式调用等同于上述较短的调用。

弱原子调用被称为 acquire/release 原子调用，在这种原子调用中，后一个 acquire 所观察到的 `release` 操作会创建一条从 release 到 acquire 的 happens-before 边界。这个术语的目的是让人联想到互斥：release 类似于一个互斥锁的解锁，而 acquire 类似于对同一个互斥锁进行加锁。在 release 之前执行的写操作必须对之后执行的 acquire 操作之后的读操作可见，就像在解锁互斥锁之前执行的写操作必须对之后锁定同一互斥锁之后的读操作可见一样。

为了使用弱原子，我们可以将消息传递示例改为使用：

```
atomic_store(&done, 1, memory_order_release);
```

和

```
while(atomic_load(&done, memory_order_acquire) == 0) { /* loop */ }
```

它仍然是正确的。但并非所有程序都会这样。

回想一下，顺序一致性的原子操作要求程序中所有原子操作的行为都与执行的某个全局交错（总序）保持一致。而 acquire/release 原子操作则不需要这样。它们只要求对单个内存位置上的操作进行顺序一致的交错。也就是说，它们只要求一致性。结果是，使用多个内存位置的 acquire/release 原子操作的程序可能会观察到无法通过程序中所有acquire/release原子操作的顺序一致交错来解释的执行，可以说这违反了 DRF-SC（数据竞争自由-顺序一致性）！

为了说明两者的区别，这里再举一个存储缓冲区的例子：

```
Litmus Test: Store Buffering
Can this program see r1 = 0, r2 = 0?

// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): yes!
On ARM/POWER: yes!
On Java (using volatiles): no.
On C++11 (sequentially consistent atomics): no.
On C++11 (acquire/release atomics): yes!
```

为了说明两者的区别，下面再以存储缓冲区为例：

```
Litmus Test: Store Buffering
Can this program see r1 = 0, r2 = 0?

// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): yes!
On ARM/POWER: yes!
On Java (using volatiles): no.
On C++11 (sequentially consistent atomics): no.
On C++11 (acquire/release atomics): yes!
```

C++中的顺序一致性原子操作与 Java 的 volatile 原子一致。但是，acquire/release 原子操作不对 `x` 的排序和 `y` 的排序之间施加任何关系。特别是，允许程序表现为 `r1 = y` 发生在 `y = 1` 之前，而同时 `r2 = x` 发生在 `x = 1` 之前，允许 `r1 = 0，r2 = 0`，这与整个程序的顺序一致性相矛盾。这些程序之所以存在，可能只是因为它们在 x86 上是免费的。

请注意，对于给定的特定读取观察特定写入的集合，C++ 顺序一致性原子操作和 C++ acquire/release 原子操作会产生相同的 happens-before 边界。它们之间的区别在于，顺序一致性原子操作机制不允许某些特定读取观察特定写入的集合，但 acquire/release 原子机制允许。存储缓冲情况下导致 `r1 = 0、r2 = 0` 的集合就是这样一个例子。

### acquire/relase 的弱点的真实例子

在实际应用中，acquire/relase 原子操作不如提供顺序一致性的原子操作有用。下面是一个例子。假设我们有一个新的同步原语，即一个具有两个方法 `Notify` 和 `Wait` 的一次性条件变量。为简单起见，只有一个线程会调用 `Notify`，只有一个线程会调用 `Wait`。我们希望在另一个线程尚未等待时，`Notify` 是无锁的。我们可以使用一对原子整数来实现这一目的：

```
class Cond {
    atomic<int> done;
    atomic<int> waiting;
    ...
};

void Cond::notify() {
    done = 1;
    if (!waiting)
        return;
    // ... wake up waiter ...
}

void Cond::wait() {
    waiting = 1;
    if(done)
        return;
    // ... sleep ...
}
```

这段代码的重要之处在于，`notify` 在检查 `waiting` 之前设置 `done`，而 `wait` 在检查 `done` 之前设置 `waiting`，因此对 `notify` 和 `wait` 的并发调用不会导致 `notify` 立即返回而 `wait` 休眠。但如果使用 C++ 的 acquire/release 原子操作，就可以做到这一点。更糟的是，在某些架构（如 64 位 ARM）上，实现 acquire/release 原子操作的最佳方法是顺序一致的原子操作，因此您可能会编写在 64 位 ARM 上运行良好的代码，但在移植到其他系统时才发现代码不正确）。

基于这种理解，acquire/release 对于这些原子操作来说是一个不恰当的名称，因为顺序一致的原子也会执行同样多的 acquire 和 release 操作。它们的不同之处在于失去了顺序一致性。把它们叫做“一致性”原子可能更好一些。太迟了

### 松弛原子（relaxed atomics）

C++ 并没有止步于仅仅连贯的 acquire/release 原子操作。它还引入了非同步原子，称为松弛原子（`memory_order_relaxed`）。这些原子完全没有同步效果--它们不会创建任何 happens-before 边，也完全没有排序保证。事实上，松弛原子读/写与普通读/写没有任何区别，只是松弛原子上的竞争不被视为竞争，也不会引起着火（catch fire）。

修订后的 Java 内存模型的大部分复杂性都来自于定义数据竞争程序的行为。如果 C++ 采用 DRF-SC 或“着火”（Catch Fire）能有效地禁止带有数据竞争的程序，这就意味着我们可以抛开前面提到的那些奇怪的例子，从而使 C++ 语言规范最终比 Java 更简单，那该有多好。不幸的是，包含松弛原子结构最终保留了所有这些问题，这意味着 C++11 规范最终并不比 Java 规范简单。

```
Litmus Test: Non-Racy Out Of Thin Air Values
Can this program see r1 = 42, r2 = 42?

// Thread 1           // Thread 2
r1 = x                r2 = y
if (r1 == 42)         if (r2 == 42)
    y = r1                x = r2
(Obviously not!)

C++11 (ordinary variables): no.
C++11 (relaxed atomics): yes!
```

维克托-瓦菲阿迪斯（Viktor Vafeiadis）等人在论文[《常见编译器优化在 C11 内存模型中无效以及我们能做些什么》（2015）](https://fzn.fr/readings/c11comp.pdf)中指出，当 `x` 和 `y` 是普通变量时，C++11 规范保证该程序必须以 `x` 和 `y` 设为 0 结束。但如果 `x` 和 `y` 是松弛原子，那么严格来说，C++11 规范并不排除 `r1` 和 `r2` 最终都是 42 的可能性。(惊喜！）。

详细内容请参见论文，但从高层次来看，C++11 规范有一些试图禁止凭空值的正式规则，同时还有一些含糊的措辞来阻止其他类型的有问题值。这些正式规则是问题所在，因此 C++14 删除了它们，只留下了模糊的词语。引用删除这些规则的理由，C++11 的表述结果是“既不充分，因为它使得使用 `memory_order_relaxed` 的程序基本上无法进行推理；又严重有害，因为它可以说禁止了 ARM 和 POWER 等架构上所有合理的 `memory_order_relaxed` 实现”。

总的来说，Java 试图正式排除所有因果执行，但失败了。然后，借助 Java 的后见之明，C++11 尝试只正式排除某些因果执行，但也失败了。然后，C++14 又说什么也不正式。这不是正确的方向。

事实上，马克-巴蒂（Mark Batty）等人在 2015 年发表的一篇题为“[编程语言并发语义学问题](https://www.cl.cam.ac.uk/~jp622/the_problem_of_programming_language_concurrency_semantics.pdf)”的论文中给出了这样的清醒评估：

> 令人不安的是，在首款松弛内存硬件（IBM 370/158MP）问世 40 多年后，该领域仍未就任何包含高性能共享内存并发基元的通用高级语言的并发语义提出可信的建议。

即使是定义弱排序硬件的语义（忽略软件和编译器优化的复杂性），进展也并不十分顺利。2018 年，张思卓等人发表了一篇题为[《构建弱内存模型》](https://arxiv.org/abs/1805.07886)的论文，讲述了最近发生的一些事情：

> Sarkar 等人于2011年发布了 POWER 运行模型，Mador-Haim 等人于 2012 年发布了公理模型，该模型被证明与运行模型相匹配。然而，2014 年，Alglave 等人的研究表明，最初的运行模型以及相应的公理模型排除了在 POWER 机器上观察到的一种新行为。另一个例子是，2016 年，Flur 等人给出了 ARM 的运行模型，但没有相应的公理模型。一年后，ARM 发布了 ISA 手册修订版，明确禁止 Flur 模型所允许的行为，于是又提出了另一个 ARM 内存模型。显然，根据经验形式化弱内存模型既容易出错，又极具挑战性。

在过去十年中，一直致力于定义和规范化所有这些问题的研究人员都非常聪明、才华横溢、锲而不舍，我无意通过指出结果中的不足之处来贬低他们的努力和成就。我的结论很简单，那就是，即使没有竞争，指定线程程序确切行为的问题也是极其微妙和困难的。时至今日，即使是最优秀、最聪明的研究人员，似乎也仍然无法解决这个问题。即使不是这样，编程语言定义的最佳效果也是日常开发人员可以理解的，而无需花费十年时间研究并发程序的语义。

## C, Rust 和 Swift 内存模型

C11 也采用了 C++11 内存模型，使其成为 C/C++11 内存模型。

[2015 年的 Rust 1.0.0](https://doc.rust-lang.org/std/sync/atomic/) 和 [2020 年的 Swift 5.3](https://github.com/apple/swift-evolution/blob/master/proposals/0282-atomics.md) 都完全采用了 C/C++ 内存模型，包括 DRF-SC 或 Catch Fire 以及所有原子类型和原子栅栏。

这两种语言采用 C/C++ 模型并不奇怪，因为它们都是基于 C/C++ 编译器工具链（LLVM）构建的，并强调与 C/C++ 代码的紧密集成。

## 硬件题外话：高效的顺序一致性原子算法

早期的多处理器架构有多种同步机制和内存模型，可用性各不相同。在这种多样性中，不同同步抽象的效率取决于它们与体系结构所提供功能的映射程度。要构建顺序一致的原子变量抽象，有时唯一的选择就是使用比严格意义上必要的功能更多但成本更高的屏障（barrier），尤其是在 ARM 和 POWER 上。

由于 C、C++ 和 Java 都提供了相同的顺序一致性同步原子抽象，因此硬件设计人员有责任使该抽象高效。ARMv8 架构（包括 32 位和 64 位）引入了 `ldar` 和 `stlr` 加载和存储指令，提供了直接实现。在 2017 年的一次演讲中，Herb Sutter 声称 [IBM 曾批准他说](https://youtu.be/KeLBd2EJLOU?t=3432)，他们打算在未来的 POWER 实现中也为顺序一致性的原子提供某种更高效的支持，让程序员“更没有理由使用松弛的 atomics”。我无法确定这是否真的发生了，不过在 2021 年，POWER 的相关性已经大大低于 ARMv8。

这种趋同的结果是，顺序一致性原子现在已被很好地理解，并能在所有主要硬件平台上高效实现，使其成为编程语言内存模型的良好目标。

## Javascript 内存模型（2017）

你可能会认为，JavaScript 是一种出了名的单线程语言，不需要担心代码在多处理器上并行运行时的内存模型问题。我当然会这么想。但你我都错了。

JavaScript 拥有 Web Worker，它允许在另一个线程中运行代码。按照最初的设想， Worker 只能通过显式消息复制与 JavaScript 主线程通信。由于没有共享的可写内存，因此无需考虑数据竞争等问题。但是，ECMAScript 2017（ES2017）添加了 `SharedArrayBuffer` 对象，它允许主线程和 Worker 共享一个可写内存块。为什么要这样做？[在提案的早期草案中](https://github.com/tc39/ecmascript_sharedmem/blob/master/historical/Spec_JavaScriptSharedMemoryAtomicsandLocks.pdf)，列出的第一个原因是将多线程 C++ 代码编译成 JavaScript。

当然，共享可写内存还需要定义同步原子操作和内存模型。JavaScript 在三个重要方面偏离了 C++：

- 首先，它将原子操作限定为顺序一致性原子。其他原子操作可以编译成顺序一致性的原子操作，这样也许会降低效率，但不会降低正确性。
- 其次，JavaScript 并没有采用 DRF-SC 或 Catch Fire。相反，JavaScript 和 Java 一样，仔细定义了并发访问的可能结果。其原理与 Java 大同小异，尤其是在安全性方面。允许竞争读取返回任何值都允许（可以说是鼓励）实现返回不相关的数据，这可能会导致[运行时泄漏隐私数据](https://github.com/tc39/ecmascript_sharedmem/blob/master/DISCUSSION.md#races-leaking-private-data-at-run-time)。
- 第三，部分原因是 JavaScript 为竞态程序提供了语义，它定义了在同一内存位置使用原子操作和非原子操作时，以及使用不同大小的访问方式访问同一内存位置时会发生的情况。

精确定义竞态程序的行为会导致松弛内存语义以及如何禁止凭空值的读取等常见的复杂问题。除了这些与其他地方基本相同的挑战之外，ES2017 的定义还有两个有趣的 bug，它们是由于与新的 ARMv8 原子指令的语义不匹配而产生的。这些示例改编自 Conrad Watt 等人 2020 年的论文 "[Repairing and Mechanising the JavaScript Relaxed Memory Model](https://www.cl.cam.ac.uk/~jp622/repairing_javascript.pdf)"。

如前所述，ARMv8 增加了 `ldar` 和 `stlr` 指令，提供顺序一致性的原子加载和存储。这些指令针对的是 C++，而 C++ 并未定义任何数据竞争程序的行为。因此，不难理解，这些指令在竞态程序中的行为并不符合 ES2017 作者的预期，尤其是不符合 ES2017 对竞态程序行为的要求。

```
Litmus Test: ES2017 racy reads on ARMv8
Can this program (using atomics) see r1 = 0, r2 = 1?

// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                x = 2 (non-atomic)
                      r2 = x
C++: yes (data race, can do anything at all).
Java: the program cannot be written.
ARMv8 using ldar/stlr: yes.
ES2017: no! (contradicting ARMv8)
```

在这个程序中，所有读写操作都是顺序一致的原子操作，但 `x = 2` 除外：线程 1 使用原子存储写 `x = 1`，但线程 2 使用非原子存储写 `x = 2`。在 C++ 中，这属于数据竞赛，因此一切都无从谈起。在 Java 中，这个程序是写不出来的：`x` 必须声明为 `volatile` 或非 volatile；它不能只在某些时候被原子访问。在 ES2017 中，内存模型不允许 `r1 = 0，r2 = 1`。如果 `r1 = y` 读取 0，线程 1 必须在线程 2 开始之前完成，在这种情况下，非原子 `x = 2` 似乎会发生在 `x = 1` 之后，并覆盖 `x = 1`，导致原子 `r2 = x` 读取 2。这种解释似乎完全合理，但它并不是 ARMv8 处理器的工作方式。

事实证明，对于 ARMv8 指令的等效序列，对 `x` 的非原子写入可以在对 `y` 的原子写入之前重新排序，因此该程序实际上会产生 `r1 = 0、r2 = 1` 的结果。这在 C++ 中不是问题，因为竞赛意味着程序可以做任何事情，但对于 ES2017 来说却是个问题，因为 ES2017 将竞态行为限制为一组结果，其中不包括 `r1 = 0, r2 = 1`。

由于 ES2017 的明确目标是使用 ARMv8 指令来实现顺序一致的原子操作，因此 Watt 等人报告说，他们建议的修复措施将被纳入标准的下一次修订版中，这将会弱化竞态行为约束，使其足以实现这一结果（我不清楚当时的“下一次修订版”是指 ES2020 还是 ES2021）。

Watt 等人建议的修改还包括修复第二个 Bug，该 Bug 最早由 Watt、Andreas Rossberg 和 Jean Pichon-Pharabod 发现，在 ES2017 规范中，无竞争数据程序没有被赋予顺序一致的语义。该程序的语法如下：

```
Litmus Test: ES2017 data-race-free program
Can this program (using atomics) see r1 = 1, r2 = 2?

// Thread 1           // Thread 2
x = 1                 x = 2
                      r1 = x
                      if (r1 == 1) {
                          r2 = x // non-atomic
                      }
On sequentially consistent hardware: no.
C++: I'm not enough of a C++ expert to say for sure.
Java: the program cannot be written.
ES2017: yes! (violating DRF-SC).
```

在这个程序中，除了 `r2 = x` 外，所有读写操作都是顺序一致的原子操作。DRF-SC 意味着程序必须以顺序一致的方式执行，因此 `r1 = 1, r2 = 2` 是不可能的，但 ES2017 规范允许这样做。

因此，ES2017 对程序行为的规范同时存在太强（不允许竞态程序有真正的 ARMv8 行为）和太弱（允许无竞态程序有非顺序一致的行为）的问题。如前所述，这些错误已经得到纠正。即便如此，这也再次提醒我们，使用 happens-before 来精确指定无竞态程序和竞态程序的语义是多么微妙，将语言内存模型与底层硬件内存模型相匹配也是多么微妙。

令人欣慰的是，至少目前 JavaScript 除了顺序一致的原子外，还避免了添加其他原子，并抵制了 DRF-SC 和 Catch Fire。因此，JavaScript 的内存模型可以作为 C/C++ 的编译目标，但更接近 Java。

## 总结

纵观 C、C++、Java、JavaScript、Rust 和 Swift，我们可以得出以下结论：

- 它们都提供了顺序一致的同步原子，用于协调并行程序的非原子部分。
- 它们的目的都是保证使用适当的同步技术实现无竞态数据的程序，其行为就像以顺序一致的方式执行一样。
- 在 Java 9 引入 `VarHandle` 之前，Java 一直没有添加弱同步原子（acquire/release）。截至本文撰写时，JavaScript 也一直避免添加弱同步原子。
- 它们都为程序提供了一种执行“有意”数据竞争的方式，而不会使程序的其他部分失效。在 C、C++、Rust 和 Swift 中，这种机制是松弛的非同步原子，一种特殊形式的内存访问。在 Java 中，这种机制是普通内存访问或 Java 9 `VarHandle` “普通”访问模式。在 JavaScript 中，这种机制是普通内存访问。
- 这些语言都没有找到正式禁止“凭空产生的值”等悖论的方法，但都非正式地禁止了这些悖论。

与此同时，处理器制造商似乎已经认识到，顺序一致同步原子的抽象对于高效实现非常重要，并开始这样做：ARMv8 和 RISC-V 都提供了直接支持。

最后，为了理解这些系统并准确描述其行为，确实开展了大量的验证和形式分析工作。尤其令人鼓舞的是，Watt 等人在 2020 年给出了 JavaScript 重要子集的形式化模型，并使用定理验证器证明了编译到 ARM、POWER、RISC-V 和 x86-TSO 的正确性。

在第一个 Java 内存模型诞生 25 年后，经过数百年的研究努力，我们或许已经开始能够形式化整个内存模型。也许有一天，我们也能完全理解它们。

本系列的下一篇文章是[Go 内存模型](go-memory-model.md)。

## 致谢

与我有幸在谷歌共事的一长串工程师的讨论和他们的反馈让这一系列文章受益匪浅。在此向他们表示感谢。对于任何错误或不受欢迎的观点，我将承担全部责任。