# 深入理解缓存

这片主要是从CPU的层面讲如何利用的缓存的，以及缓存是如何运行的。

我们知道CPU里面是有高速缓存的，主要为了将热指令和数据提前缓存到里面提高CPU的运算力。而缓存的策略就是之前提到的[缓存层次结构-局部性原理](memory-hierarchy.md#内存管理与优化策略——局部性原理（Principle of Locatily）)。在讲CPU读取指令与数据如何利用缓存之前，必须要先知道CPU的缓存结构。

靠近CPU越近的，速度越快。其中以SRAM作为高速缓存（L1级缓存），面积是最小的，价格方面也是最贵的。其查询速度达到了0.5ns。

往下就是L2级缓存，查询速度达到了4ns。（注意：**此时L1，L2是每个CPU核都有独立的缓存块**）

再往下就是L3级缓存（注意：**L3是多个CPU核共享的缓存块，往下都是共享的**）。

再往下就是DRAM结构的主存了，查询速度已经变为了100ns。

那么整成一个如下表格：

| 存储器      | 存储结构 | 访问延时 | 说明        |
| ----------- | -------- | -------- | ----------- |
| L1 Cache    | SRAM     | 0.5～2ns | 核心CPU独享 |
| L2 Cache    | SRAM     | 4ns      | 核心CPU独享 |
| L3 Cache    | SRAM     | 10ns     | 整个CPU共享 |
| Memory 主存 | DRAM     | 100ns    |             |
| 硬盘        | SSD      | 150μs    |             |
| 硬盘        | HDD      | 10ms     |             |

那么CPU取指令/数据到寄存器时，首先是从L1缓存取的，如果发现没有命中缓存就会继续往下找L2缓存，同样如果没有就继续往下找L3、主存最后到硬盘。取到数据之后就会把数据从最底层的缓存回写到L1缓存。之后再取同样的指令/数据就会命中缓存直接µs级就能获取到信息了。

那么CPU又是如何知道目标信息是否在缓存中呢？

## 缓存映射

首先我们得从简单的直接缓存映射开始说起，什么是直接缓存映射，**首先CPU拿到数据的时候已知的就是目标数据的地址，于是就直接基于这个地址来分配cache的具体位置**。这种查找映射方式就被称为**直接缓存映射（direct mapped）**。而映射的规则也很简单：

```
addr % cache_number; 
其中 addr 为目标地址，cache_number 为缓存块的数据块数量
```

举个例子，假设我们的主存分为64个块，分别为0～63号。一共有8个缓存数据块。用户想要访问32号内存块。那么如果32号内存块在缓存中，那么它一定分布在第0号缓存块中（32%8 = 0）。这里面还有计算的小技巧：如果cache的块数是2的幂，则取模运算非常简单，只需要取地址的n次幂的低n位即可。那么还是以上面的例子说明，一个8个数据块的缓存就是2的3次幂，即使用地址的最低3位来查找。那么对32的二进制表示就是`100000`取低三位就是000，对应位置0的缓存块地址。如下图所示：

![](./asserts/1648824446124.jpg)

那么即使这样能找到具体的缓存块，但是像这样的取模算法会有很多数据会分布到相同缓存块中，那么CPU又是如何知道在缓存块的具体哪个位置呢？

这就需要用到缓存块其它的有效信息了：在每个缓存中都会存储一个**组标签（Tag）**。这个组标记会记录记录了当前地址的信息，这些信息可以用来确定目标数据项是否在cache中。组标签只需要记录地址的高位部分，用这个部分来表明请求字是否在cache中。如上面的32的低三位是000，而剩下的高位就是100。

除此之外，还需要一种方法能够判断cache中的数据块中是否保存了有效信息。如当处理器启动时，cache中没有有效数据，标签位都是无意义的。为了解决这个问题我们可以添加一个有效位（valid bit），用来表示该缓存块中的数据是否有效。如果有效位为0，那么即使组标签和缓存项中有数据，CPU都会选择直接访问内存，重新加载数据。

**CPU在读取数据的时候，并不是要读取一整个 Block，而是读取一个他需要的整数。这样的数据，我们叫作 CPU 里的一个字（Word）。具体是哪个字，就用这个字在整个 Block 里面的位置来决定。这个位置，我们叫作偏移量（Offset）。**

这个时候我们就要更改之前的说法了，我们之前是把内存的数据项的地址分为两部分，即地位部分表示的cache索引，高位部分表示的组标签。而现在就是要把内存数据项地址分成三部分：

1. 高位表示的组标签
2. 低位表示的cache索引
3. 以及数据块中用来定位请求字的具体位置的偏移量

整体结构图如下：

![](./asserts/cache-index.png)

那么CPU从内存中获取数据到缓存中所经过的步骤就可以总结为以下几步：

1. 根据内存数据项的地址低位得出cache的索引
2. 根据索引得出具体的缓存块，并通过缓存块上的有效位得知cache中的数据是否有效
3. 根据内存数据项的地址高位和cache块中的组标签，确认该cache中的数据就是这次要找的数据
4. 然后根据偏移量从Data Block中读取对应的实际数据。

整个cache的查找过程就是这样的了。实际上我们现代CPU几乎很少使用这种直接映射缓存方法了，实际上用的**组相连高速缓存（set associative cache）**。

像直接缓存映射这种方式，我们从上面的图可以看这种方式**一个数据块只能定位一个位置**。而组相连高速缓存是有多个缓存行（Cache Line）为一组（至少是2个缓存行）。**一个数据块可以放置组内的多个缓存行内**。组相连高速缓存里面有一个特例，就是数据块可以放在缓存的任意位置，这种就被称为“**全相连高速缓存**”。但是全相连会让每个cache都有一个比较器可以并行地进行比较。这些比较器增加了硬件开销，这就会导致缓存的量很少。

## 组相连高速缓存

**在一个组相连缓存中，每一个数据块可以存放的位置数量是固定（至少是2）的**。每个数据块有n个位置可放的组相连缓存就被称为**n路组相连缓存**。映射的过程其实跟直接缓存映射的过程几乎是一样的。

一个数据块通过低位来定位到具体的某一组的索引，然后就会在这个组中所有的数据块都要一一进行比较。前面我们知道直接缓存映射的公式是`addr % cache_number`。而组相连映射规则是`addr % group_number`。

> 组相连缓存映射的过程，我们其实可以借用哈希链表的思路去理解。首先我们通过目标数据地址计算出组索引，然后组索引后面就是一个链表，沿着这个链表一个一个比较是否命中目标数据项。

最后我们通过《计算机组成与设计》的图标和例子来加深一下映射规则的印象

![](./asserts/1648911021638.jpg)

已知目标数据地址为12。该cache被分为8个数据块：

- 直接映射：12 % 8 = 4。那么cache的数据块为4。然后根据具体的offset找到唯一的位置数据。
- 组相连：12 % 4 = 0。那么目标数据就在第0组，然后在这2个数据块中一一比较目标数据。
- 全相连：目标地址数据块可以放置任意缓存数据块中。

组相连有什么好处呢？这样会提高缓存命中率，更加灵活的替换策略。

> 关于替换策略的内容其实非常复杂，比如有利用[局部性原理](memory-hierarchy.md#内存管理与优化策略——局部性原理（Principle of Locatily）)的，也有最不常用策略（Least-Frequently-Used,LFU）、最近最少使用（Least-Recently-Used,LRU）等。

## 缓存一致性问题

//TODO





