# 并发编程

现实中哪些场景会涉及到并发呢？

访问缓慢的 I/O 设备：在进行 I/O 访问时，会执行异步操作，内核切换上下文执行其他程序。这样能充分发挥多核的优势，并行计算等。

OS 提供三种方法实现并发：

1. 进程；每个处理（即逻辑控制流）都是一个独立的进程，每个进程都有自己独立的虚拟内存区域
2. I/O 多路复用：在同一个进程下，显式调度自己的逻辑流，转换为状态机，所有的流都共享一个地址空间（因为都是在同一个进程下运行）
3. 线程：是进程上下文中的逻辑流，是进程的一个最小的执行单元，有内核调度，行为上是上面两种方式的结合体：像进程一样由内核调度，又想 I/O 多路复用一样共享同一个地址空间。

## 进程实现并发

每个处理都是一个进程，这个是有明显的优势的。因为每个进程都有自己独立的地址空间，这样就不会发生数据被其他进程访问修改覆盖的情况了。但同样也带了缺点：两个进程之间很难通信，这只能通过 IPC 机制实现，并且开销非常大，所以性能大打折扣，运行起来很缓慢。具体的执行图我画了一个草图如下：

![image-20201202232607781](asserts/process-cp.png)

## I/O 多路复用

I/O 多路复用其核心是用 select 函数，要求内核挂起一个进程，只有在一个或多个 I/O 事件发生后，才将控制权返回给应用程序。select 函数会检测到输入事件，会创建一个新的逻辑流（即状态机），再而继续执行状态转移，完成之后就删除状态机。

这里面细节很多，主要在于循环读取 select 函数检测两种不同类型的输入类型：

1. 新客户端的连接请求
2. 已存在的客户端的已建立连接描述符准备读取的请求

每个客户端请求都会创建一个状态机来进行状态转移。

优点：共用一个进程，所以共享数据很容易，并且不需要执行进程上下文切换来调度逻辑流。性能较之进程来说是非常高的。

缺点：编码非常复杂，并且无法利用多核 CPU 的优势。

## 线程并发编程

线程是一个进程的最小执行单元。一个线程包括（线程 ID、指针、数据、栈、程序计数器以及寄存器和条件码）。因为在同一个进程下， 所以共享进程中的虚拟内存。我们现在用的最多的实现并发手段就是基于线程。

这里面还要牵涉到并发问题，多个线程对共享变量读写造成对整个程序结果的影响。为了解决这个问题，引入了**信号量**

### 信号量

信号量是通过一个变量来控制解决多线程访问共享变量的一种方法。具体过程如下：

1. 访问共享变量，信号量 -1（即上锁）
2. 另一个新城过程访问这个变量，发现这个信号量 =0，则挂起线程（即等待）
3. 直到占有锁的线程处理完成逻辑并释放锁，将信号量 +1
4. 则挂起的线程就会受到通知知道这个信号量不等于 0，则相继占有锁，将信号量继续 +1（上锁）

信号量解决的场景有很多，大体上分为以下几种：

1. 生产者-消费者问题：对一个共享的含有 n 个槽的有效缓冲队列进行读写。

2. 读写者问题：读可以无限制读，不需要枷锁。而写操作需要独占锁。这个问题又裂变为两种问题：

   1. 读多写少，即读者优先
   2. 写多读少，即写着优先

   要注意，因为存在优先权利，所以就存在另一种操作可能永远不会执行的可能。

我们还好分清楚“并发程序”、”并行程序“之间的关系。**并行程序是并发程序的真子集**。

要注意，线程不是开的越多越好，在 CPU 核芯数一定的情况下，如 8 核 CPU，如果我们线程开到 8 个，就会发现时间计算能力提升的非常明显。一旦大于 8 个时就会发现提升的不明显了，因为由于开启的线程比核芯数高，内核会频繁的进行线程上下文切换。这个操作虽然较之与进程上下文切换开销大，但是本身这个操作的开销还是有一定影响的。

