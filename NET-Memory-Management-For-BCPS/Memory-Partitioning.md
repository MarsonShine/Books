# 内存分区

## 分区策略

垃圾回收堆（GC Heap）的容量可能增长至数十甚至数百GB。从内存分配器的角度来看这或许不成问题，但很难想象垃圾回收器能统一处理如此庞大的数据量。及时处理千兆级别的数据本就困难重重。在设计垃圾回收器整体架构时，最关键参数之一是其引入的开销——例如因垃圾回收导致线程活动暂停的时长，或其所消耗的CPU资源。理想情况下，暂停时间应短于毫秒级。然而根据第二章列出的内存访问延迟特性，读取千兆数据所需时间远超数毫秒。正因如此，所有垃圾回收器实现背后最核心的设计决策之一就是**内存分区策略**。

简而言之，必须将整个 GC 堆分割为更小的部分，才能实现独立操作。若策略得当，可极大加速垃圾回收器工作，因为实践证明程序运行期间无需对所有数据一视同仁。

现有分区策略通常基于已分配对象的某项特性：

- **大小**：可按对象大小划分堆区域。例如对小型对象与大对象区别处理，这在采用压缩回收时尤为重要。复制大对象会产生显著内存开销，因此可能仅压缩小对象区域，而对大对象采用清扫回收。
- **生命周期**：对象存活时长至关重要。直观而言，短暂存活的对象应与贯穿应用生命周期的对象区别对待。如第四章所示，某些字符串甚至永恒存在！虽然无法预知未来，但至少可区分新生对象与长期存活对象。不同生命周期的内存区域通常称为“代”（generations），以“年轻代/老年代”或连续数字命名。
- **可变性**：对象是否可变是关键特性。不可变对象创建后无法修改，值得与可变对象差异化管理。
- **类型**：可对特定类型对象特殊处理。例如为字符串、整型或其他特殊类、接口实现或特性维护独立堆区，效果因场景而异
- **种类**：对象可按多种方式分类。例如是否包含指针（外部引用）？若无则压缩时无需考虑；是否已被固定（pinning，第七章详述）？固定对象即便在压缩回收时也不移动，或应存入独立分区以避免移动开销。

微软 .NET 与 Mono 实现仅采用前两种策略。其垃圾回收器不关注对象类型或可变性，仅管理所需字节数（如“为新对象分配N字节”）。但随着 GC 设计演进，后续章节将看到对字符串字面量或固定数组的特殊优化。

下文将详细探讨这两种分区策略。惯例上以.NET实现为主，Mono或其他运行时仅作旁注。

## 大小分区

第一种策略是根据对象大小差异化管理。前文提及，主要原因在于压缩回收时的内存复制开销。由于无需划分过多体积区间，仅需设定单一阈值区分大小对象。GC 堆因此被划分为两个物理隔离的内存区域：

- **小对象堆（SOH）​**：存放所有小于85,000字节的对象
- **大对象堆（LOH）​**：存放所有大于等于85,000字节的对象

二者共享大部分逻辑与代码，但存在关键差异。需注意该阈值为85,000字节（非85×1024字节的85KiB或85kB）。此阈值可通过`LOHThreshold` 配置调高（不可调低）。

分区策略导致两堆区采用不同处理方式：

- **SOH**可采用压缩回收，因小对象内存复制开销更低（第七章将介绍SOH同时实现了清扫和原地压缩回收，计划阶段决定具体方式）
- **非内存受限环境**​（如无内存限制的容器中），​**LOH**默认采用清扫回收以避免大对象压缩成本（但用户可显式触发LOH压缩）

> Mono 6.12采用8,000字节阈值，更大对象存入“大对象空间”（LoS）。小对象先分配在新生代，存活后晋升至主堆。类似.NET，小对象空间可压缩，LoS仅执行清扫。

85,000字节阈值的选定源于工程实践与历史因素——基于.NET初期大量内部及外部场景测试得出的实验值。

该阈值针对对象的**浅层大小**（引用计为指针大小而非目标对象体积），故 LOH 常见对象多为数组和大字符串。含大数组字段的对象本身仍属小对象（字段仅是小型指针）。

另一实现细节是**内存对齐**：

- **SOH**：32位运行时4字节对齐，64位运行时8字节对齐
- **LOH**：始终8字节对齐（与运行时位数无关）

此设计主因双精度数组需 8 字节对齐（后文详述），且 8 字节对齐对大对象影响微乎其微。

### 小对象堆（SOH）

作为最活跃的内存区域，绝大多数对象体积小于85,000字节，故SOH对象数量通常比LOH高数个数量级。为缓解海量对象对GC性能的影响（如标记阶段遍历大对象图），该区域进一步按对象生命周期划分为“代”（后文详述）。

### 大对象堆（LOH）

LOH在GC实现中被标记为第3代，但逻辑上属于第2代——仅当第2代回收时才会处理。

设计假设大对象分配较罕见（多数程序无需大量短生命周期的大数据结构），但某些场景（如大型JSON字符串）可能导致性能问题（参见第六章“规则15——避免过量LOH分配”）。例外情况包括：

#### 大对象堆——双精度数组

32位运行时环境下（即便运行于64位机器），元素超1,000的双精度数组会存入LOH（如代码清单5-1所示）。由于每个双精度占8字节，这意味着LOH可能存放仅8,000字节的数组，打破85,000字节下限规则。

代码清单5-1：32位.NET运行时环境下，含1000+元素的双精度数组会分配至LOH，因此本示例程序将分别输出“0”和“2”

```csharp
double[] array1 = new double[999];
Console.WriteLine(GC.GetGeneration(array1)); // 输出 0
double[] array2 = new double[1000];
Console.WriteLine(GC.GetGeneration(array2)); // 输出 2
```

为何设定如此特殊的例外规则？如前所述，这源于**内存对齐**需求。双精度类型占8字节，对其非对齐访问的性能损耗远高于整型。64位环境中SOH和LOH均采用8字节对齐故无此问题，但32位SOH的4字节对齐可能导致性能隐患。

这些数组被存入**始终8字节对齐的LOH**（该设计主要为此场景服务），从而避免大型数组的非对齐访问开销。但为何不将所有双精度数组都分配至LOH？因为LOH不压缩的特性会导致**内存碎片化**——大量小对象将产生不连续内存空隙。仅对超阈值数组启用LOH分配，实质是在非对齐访问成本与碎片化之间取得的平衡。而1000个元素的阈值同样通过实验得出。

> 开发者仍需警惕32位运行时下双精度数组引发的碎片化问题。例如频繁创建/回收超1000个元素的双精度数组会导致LOH内存分散。此时应改用**可复用数组缓冲池**而非持续新建数组（详见场景6-1）。

> **数组的对齐与访问性能**
>
> 在 32 位运行时环境中：
>
> - **SOH（小对象堆）默认是 4 字节对齐**，也就是说，分配的对象起始地址以 4 字节为粒度对齐。
> - **双精度类型（`double`）占用 8 字节**，并要求 **8 字节对齐** 才能高效访问。虽然双精度本身的大小是 4 字节的倍数，但如果分配在 4 字节对齐的堆上，可能会导致非对齐访问。
>
> **非对齐访问的性能问题**
>
> 假如双精度数组分配在 SOH（4 字节对齐）上，可能会出现以下问题：
>
> - 当数组的起始地址非 8 字节对齐时，硬件需要额外操作（通常是两次内存读取和合并）来访问双精度元素。
> - 这种非对齐访问会带来显著的性能损耗，尤其在涉及大量数据计算的场景（如科学计算、数值分析等）中。
>
> **LOH（大对象堆）与 8 字节对齐**
>
> - **LOH 始终以 8 字节对齐**，因此分配到 LOH 的对象可以避免非对齐访问的问题。
> - 为了解决双精度数组在 SOH 上的性能隐患，.NET 的 32 位运行时采用了一种特殊规则：
>   - **当双精度数组的长度超过 1000 个元素（即 8000 字节）时，直接分配到 LOH**，从而避免潜在的非对齐访问。
>   - 这个规则是为双精度数组优化的特例，而非普适规则。

## 生命周期分区

如前所述，由于小对象堆（SOH）可能包含海量对象，故决策按对象生命周期将其分区管理，该设计称为**分代垃圾回收**——通过特定方式将具有相似生命周期的对象划分为不同代。生命周期定义方式主要有两种：

- **绝对时间**：以CPU时钟周期数等实时指标衡量对象存活时长。但存在根本性缺陷：“长生命周期”的临界值难以界定（1秒算长还是短？）答案完全取决于具体程序特性（对象分配频率/回收需求等），虽可设计自适应阈值计算机制，但会过度复杂化。
- **相对时间**：以经历垃圾回收的次数作为代划分依据。例如：对象每存活一次GC则年龄计数器+1，超过预设阈值即归为“老年代”

> 我们甚至可以想象一些不那么明显的方法来表示对象的生命周期。例如，如果收集器和分配器的设计方式使对象永远不会移动到较低的地址范围，那么对象的年龄就可以计算为其地址与内存中其他位置的差值。
>

值得注意的是，许多垃圾回收系统的描述一开始都会说.NET有一个分代垃圾回收系统（Generational GC）。但是，为什么分代垃圾回收有意义呢？为什么要根据对象的年龄对其进行拆分并采用不同的处理方式才有意义呢？这主要源于一个被称为 “分代假设 ”的观察结果。事实上，该假设有较弱（不那么普遍）和较强（更普遍）的版本。
它们共同构成了分代 GC 的基础。与人类生活相比，它们有点反直觉：

- 弱代假说（又称婴儿死亡率）： 观察发现，大多数年轻的物体寿命都很短。换句话说，程序分配的大部分对象很快就会闲置。这些都是由局部变量、临时（隐藏）分配和所有短命处理所代表的临时对象。各种计算机科学研究广泛证实了这一假设。
- 强代假说： 观察发现，一个对象存活的时间越长，它就越有可能继续存活下去。这包括各种长期存活的对象，如长期缓存、“管理器”、“助手”、对象池、业务工作流等。然而，研究并没有完全证实这一假设，因为对象的生命周期特征似乎要比这复杂得多。这种假设甚至没有一个通用的定义。

了解物体在不同年龄段的分布情况（见图 5-2）对我们大有裨益。如果大部分年轻对象死得快，就值得更频繁地回收它们的内存（把它们分成 “年轻 ”一代）。而如果老对象很少死亡，则值得更少地回收内存（将它们分成 “老 ”一代）。当然，也可以在它们之间创建任意数量的 “临时 ”中间代。

![](asserts/5-1.png)

图 5-2. 弱代假设和强代假设图示：根据年龄划分的存活（可触及）对象数量。一旦将对象划分为不同的代，就可以对它们分别进行处理。例如，只对最年轻或最年长的一代触发垃圾收集，或收集所有代，这通常被称为全垃圾收集。

当一个对象达到一定的生命周期阈值时，它就会被提升到下一代。换句话说，升级后的对象将被视为属于下一代，也就是更老的一代。这究竟是什么意思，为什么不同的 GC 实现之间会有很大差异？

其中一种可能是复制到内存的其他区域，就像第 1 章中提到的复制 GC（图 1-16）。想象一下图 5-3 中的代组织，我们有三个独立的内存区域，分别命名为 0、1 和 2 代。然后考虑以下示例步骤：
- 程序运行一段时间后，我们创建了对象 A、B 和 C，它们被分配到最年轻的一代 “0”（图 5-3a）。
- 一段时间后，发生了一次 GC - 假设对象 A 无法访问。因此，只有对象 B 和 C 被复制到 “1”代（图 5-3b）。
- 一段时间后，我们创建了对象 D，并将其分配到 “0”代（图 5-3c）。
- 过了一段时间，GC 再次发生--假设现在 B 已无法访问。因此，对象 C 和 D 被复制到了更早的代（图 5-3d）。
- 一段时间后，我们创建了对象 E - 它被分配到了 “0”代（图 5-3e）

![](asserts/5-3.png)

图 5-3. 复制 GC 时的世代，作为分离的内存区域。在另一种方法中，代可以通过地址边界进行逻辑定义。

这样，升级就只是移动这些边界，而不是对象本身（见图 5-4）。这种方法比复制快得多，因为更新这些逻辑边界几乎不花时间。此外，存活的对象可以压缩，也可以不压缩（不过，如果压缩的话会复杂得多）。想象一下图 5-4 中的代组织，其中有一个连续的内存块。然后考虑以下示例步骤：

- 程序运行一段时间后，我们创建了对象 A、B 和 C，此时只有一个最年轻的世代 “0”（图 5-4a）。第 1 代和第 2 代的边界被降级为零或很小（这取决于具体的实现细节）。
- 一段时间后，发生了一次 GC--我们再次假设对象 A 无法访问。我们还假设进行了一次简单的清扫收集。对象 A 的内存已被回收。由于对象 B 和 C 现在应该属于较早的 “1 代”，因此其边界被移到了对象 C 之后（图 5-4b），同时也调整了 “0 代 ”的边界。无需复制内存。
- 一段时间后，我们创建了对象 D - 它被分配到 “0”代（图 5-4c）。但这样做没有任何缺点。

- 一段时间后，又发生了一次全面的 GC--让我们再次假设 B 已无法到达，因此它的内存已被回收。代的边界必须再次调整。对象 D 现在属于 “1 代”，C 属于 “2 代”（图 5-4d）。第 0 代的边界也作了适当调整。
- 一段时间后，我们创建了对象 E - 它被分配到代 “0”（图 5-4e）。

![](asserts/5-4.png)

图 5-4. 代作为单个连续内存区域内的逻辑边界。由于代边界的变化，晋升只是属于不同代的一个事实

这是.NET 运行时处理代的高级视图。我们决定创建三个代，就像前面的例子一样，以连续的数字命名。因此，第 0 代是 “年轻 ”对象，第 2 代是 “年老 ”对象，而第 1 代则包含介于两者之间的对象。另一个决定因素是如何计算代与代之间的生命周期边界。对于 .NET GC 来说，这非常简单--一般来说，如果一个对象在垃圾回收中存活下来，它就会被提升到更老的一代。

> 这条规则也有例外，即降级（或干脆不升级）。为什么会出现这种情况，我们将在以后的章节中加以说明，因为这与各种收集器和分配器机制密切相关。
>

换句话说，当一个对象存活到第 N 代时，它现在属于第 N+1 代（我们说它已经晋升到第 N+1 代）。这也意味着，在经过一次第 0 代和一次第 1 代 GC 之后，它可能会进入第 2 代，并在那里待到不再需要它为止。

> Mono 作为 Microsoft .NET 的主要替代品，对小对象（如前面 LoH 描述中提到的小于 8000 字节）也有类似的组织结构。它只区分两代--“年轻的 ”称为 Nursery，“年老的 ”称为旧空间或主要堆。它还使用了前面描述的更简单的复制晋升机制--当 Nursery中的对象在垃圾回收中存活下来时，它就会被复制到旧一代。
>

分代垃圾回收有一个明显的缺点。由于分代假设是其构造的基础，如果在应用程序中不遵守分代假设，就会导致严重的不利行为，例如第 10 章中描述的 “规则 18--避免中年危机”。由此可以得出一个重要结论--在一个符合分代假设的健康系统中，分代越老，垃圾回收的频率就越低。你可能还对分代的大小很感兴趣。这是确认应用程序是否存在内存泄漏的最简单方法。可以使用性能计数器、GC 事件机制或 .NET 计数器来观察代的大小（见表 5-1）。它们都是在垃圾回收发生后测量堆的状态：

- 由于传统原因，`\.NET CLR Memory(processname)\Gen 0` 堆大小计数器显示的不是真正的第 0 代大小，而是一种称为分配预算的东西（最简单的说法是，在对某一代触发 GC 之前分配到该代的字节数）。因此，查看这个计数器可能会产生误导。
- 请记住，无论基础数据刷新频率如何，性能监控器的最高采样率都是一秒。因此，如果在一秒钟内发生多次垃圾回收，您会看到数值的增长大于 1。

表5-1. 使用性能监视器和 `dotnet-counters` 进行的基本代际大小测量（其中 `processname` 对应您的进程实例名称）

| 代       | GC（GCHeapStats_V2事件） | 性能计数器（.NET CLR Memory(processname)）或.NET计数器（使用dotnet-counters） |
| -------- | ------------------------ | ------------------------------------------------------------ |
| 0        | GenerationSize0          | 第0代堆大小（“分配预算”）                                    |
|          |                          | 第0代大小（字节）                                            |
| 1        | GenerationSize1          | 第1代堆大小                                                  |
|          |                          | 第1代大小（字节）                                            |
| 2        | GenerationSize2          | 第2代堆大小                                                  |
|          |                          | 第2代大小（字节）                                            |
| 3（LOH） | GenerationSize3          | 大对象堆大小                                                 |
|          |                          | 大对象堆大小（字节）                                         |
| 4（POH） | GenerationSize4          | 固定对象堆大小                                               |
|          |                          | 固定对象堆大小（字节）                                       |

不过这些注意事项并不构成严重问题，因为最频繁进行垃圾回收的第0代和第1代通常体积很小，不会引发任何问题。

> 对位于LOH或POH中的对象调用 `GC.GetGeneration` 会返回2。在CLR内部，信息记录方式有两种：按代（从0到4）或按对象堆（0、1或2）。后者对应小对象堆（SoH(0)）、大对象堆（LoH(1)）或固定对象堆（PoH(2)）。您可以参考实现代索引与对象堆索引转换的 `gen_to_oh()` 辅助函数。

### 场景5-1——我的程序健康吗？随时间变化的代大小

**描述**：您希望在 Web 应用程序执行过程中观察各代（Generation）堆的大小变化。理想情况下，您希望在预生产环境的负载测试中以**非侵入式**的方式进行监测，以帮助检测代码中潜在的内存泄漏。本次测试的应用是一个标准的 nopCommerce 4 安装实例——一个基于 ASP.NET 开发的通用开源电子商务平台（您也可以参考**场景5-2**，该场景在稍有不同的条件下进行了类似的测试）。

**分析**：我们跳过负载测试的技术准备部分，假设已具备适当的流程和工具。本次负载测试的执行频率约为每秒 7 个请求，持续 170 分钟。这段时间应足以检测是否存在内存泄漏。nopCommerce 通过 .NET Windows Server Hosting 托管在 IIS 上，并采用进程外托管（out-of-process hosting）。这意味着，虽然应用程序池对应一个 `w3wp.exe` 进程，但它仅将请求转发给自托管的 .NET Framework Web 应用程序。在本例中，该进程名为 `Nop.Web.exe`。

首先，您可以根据第 4 章中的方案 4-1 检查应用程序的总体内存使用情况。这包括观察来自 Process(Nop.Web) 的 Working Set - Private、Private Bytes、Virtual Bytes 计数器和 Total committed Bytes 计数器。

其次，最简便的观测方式是使用性能监视器（Performance Monitor）工具监控表5-1所列计数器。观测结果如图5-5所示，表5-2提供了简要的数值摘要。需注意，图中各代内存大小采用不同比例尺以便清晰呈现。通过分析可知：

- **第0代大小（细实线）**在4,194,300字节至6,291,456字节之间持续波动。如前所述，该数值并非实际代大小，而是其分配预算（allocation budget）。不过仍可将其视为稳定性指标——若存在内存增长，该计数器数值也会同步上升。
- **第1代大小（虚线）**因其过渡性质波动剧烈。由于未呈现上升趋势，测量结果印证了应用程序的健康状态。
- **第2代大小（粗实线）**呈现锯齿状波动模式——对象最终会进入最老代际，并定期被垃圾回收。垃圾回收器会尽可能延迟完全回收，因此老年代对象堆积属于正常现象。对于Web应用而言，大量对象的可达性与用户会话生命周期及数据缓存机制相关，故此类锯齿模式无需担忧。**但若第2代大小的峰值呈现持续上升趋势，则可能预示潜在问题**，此时应延长观测周期以确认增长模式。建议同步监控 `\.NET CLR Memory(Nop.Web)\% Time in GC` 计数器（详见场景7-1）来评估垃圾回收对整体进程的开销。需注意：该性能计数器仅在垃圾回收完成后更新，因此当GC频繁发生时其数据才具有参考价值。

另需强调的是，第0代和第1代内存占用量通常极小，其波动无需过度关注。这是典型场景——任何内存泄漏都会表现为最老代际的持续增长（即越来越多的长生命周期对象被持有）。

![](asserts/5-5.png)

图5-5. 在近三小时的ASP.NET应用程序负载测试中，各代内存大小的性能监视器视图

表5-2. 图5-5所示测量数据的简要摘要

| 代   | 最小       | 最大        |
| ---- | ---------- | ----------- |
| 0    | 4,194,300  | 6,291,456   |
| 1    | 18,268     | 7,384,704   |
| 2    | 52,654,336 | 447,385,748 |
| LOH  | 36,000     | 38,826,368  |

对比ETW数据与性能计数器的采集结果也颇具意义。如前所述，性能计数器每秒仅采样一次，而ETW数据则是全量采集（`GCHeapStats_V2`事件会在每次GC结束时触发）。图5-6 a、b、c通过更短的20秒时间跨度（以便更清晰地展示差异）呈现了这种区别。ETW 代大小数据通过 PerfView 采集（选择低开销的“GC Collect Only”选项），随后将 `GCHeapStats_V2` 事件数据导出至 CSV 文件。性能计数器数据通过性能监视器的“数据收集器集”机制记录（支持将会话保存至文件而非实时绘制，包括CSV文本格式）。通过对比可见：

1. **性能计数器数据确实每秒采样一次**。由于测试期间网站负载较高，垃圾回收发生频率远高于采样间隔，因此 ETW 能提供更密集的数据点。
2. **第0代数据差异显著**（图5-6a）。这是前文提到的历史遗留机制所致。若需精确追踪第0代大小变化，必须采用 ETW 数据。
3. **第1代数据部分吻合**（图5-6b）。虽然部分性能计数器采样点与 ETW 数据重合，但两者间仍存在大量动态变化未被记录。这种差异在多数场景下可以接受——当应用 GC 频率低于1次/秒时，性能计数器采样完全够用。但高频 GC 场景需注意该局限性。
4. **第2代数据高度一致**（图5-6c）。由于完全 GC 发生频率较低，性能计数器几乎不会遗漏关键数据点。

![](asserts/5-6.png)

图 5-6. 利用从 ETW 导出的 CSV 数据和性能计数器数据创建代大小图表

总体评价是积极的。可以认为该应用程序运行状况良好。通过对相关性能计数器的长期观察，未发现任何特别值得警惕的问题。在当前场景中，仅展示了 ETW 数据的一小部分区域，用以说明 ETW 与性能计数器在测量结果上的差异。即便分析完整的 ETW 数据，也不会发现任何异常情况。不过，仍需采取进一步措施来测量垃圾回收（GC）的总体开销（参见第七章的Scenario 7-1）。

### **记忆集（Remembered Sets）**

前文已介绍过，小对象堆（SOH）中的对象会按代划分，这意味着垃圾回收（GC）可以分别针对不同代执行。GC 可能选择仅回收“年轻代”（young generation）或仅回收“老年代”（old generation）。不过，这种描述是一种过度简化，后续章节将深入探讨其复杂性。

回顾第1章描述的通用垃圾回收机制，您可能记得回收器使用的**标记阶段**（Mark phase）。该阶段负责通过从根对象出发、遍历对象图来确定对象可达性。在此过程中，GC会追踪已访问对象中包含的**外向引用**（outgoing references）。当遍历涵盖应用程序中所有对象的完整对象图时，这一机制运作良好。但如果仅需回收对象图的子集（例如仅回收年轻代），会发生什么？

图5-7展示了一个三代垃圾回收器的场景随时间演变的示例：

- 第0代包含对象A、B、C和D。对象A直接由根引用（可能被栈上的局部变量持有），其字段引用了对象B；对象C仅被老年代中的对象引用；对象D无任何引用指向（完全不可达）。
- 第1代包含对象E、F和G。对象E直接由根引用，其字段引用了年轻代的对象C；对象F无引用指向（另一个完全不可达对象）；对象G被年轻代的对象D引用。
- 第2代未展示对象以避免图示冗余——无论“更老代”指代第1代或第2代，其机制原理相同。

![](asserts/5-7.png)

图 5-7. 在简单的示例中使用两代的跨代引用分析

图5-7展示了应用程序中常见的引用类型。跨代引用在此完全有效：

-  新生代指向老年代：新创建的对象可能引用已存在的旧对象（如对象D和G）
-  老年代指向新生代：较早创建的对象可能持有新创建对象的引用（如对象E和C）

从标记阶段的角度看，必须处理这类跨代引用。虽然可以遍历整个对象图来判定A、B、C、D、E、F、G的可达性，但全图遍历会违背分代设计的初衷。因此我们采用仅标记“新生代”的初始方案——即只遍历年轻代对象，具体来说就是从根出发持续遍历，直到遇到非年轻代对象为止。但这种方法显然会导致错误：

从根集合出发，仅对象A和B被标记。即使对象E被根引用，也会因其位于老年代而被忽略。对象C由于未被根或其他新生代对象引用而不会被访问——尽管它被E引用，但该引用未被察觉。最终对象C和D被视为不可达：D确实可回收，但仍在被E使用的对象C却被错误回收！这清楚表明必须妥善处理老年代指向新生代的跨代引用，这些引用在判定新生代对象可达性时必须纳入考量。

**为解决这个问题，引入了记忆集（remembered sets）技术。本质上，记忆集是独立维护的对象间引用集合。在.NET中，它是专门记录老年代指向新生代引用的跨代数据结构，这些信息将在标记阶段使用。**

在我们的示例场景中，执行新生代垃圾回收时，遍历过程会同时从根集合和记忆集记录的引用（包含E→C的引用）出发，从而获得正确的标记结果。

请注意，如果仅回收年轻代，对象D会被正确垃圾回收，而对象G会暂时处于未被引用状态。等到后续执行老年代垃圾回收时，它将被标记为不可达对象。因此，对象D和G最终都会被回收。

 然而，若尝试仅执行老年代垃圾回收，我们会遇到相同问题——回收器无法感知到G正被D引用。这就需要为老年代到年轻代的跨代引用再建立一个记忆集（remembered set）。但正如后文所述，实现记忆集并非易事，因此.NET采用了更简单的方案。微软官方文档明确指出：“回收某个代意味着要回收该代及其所有更年轻代的对象”。这引出了.NET内存管理最重要的规则之一：垃圾回收可能以下列形式触发：

- 仅回收第0代
- 回收第0代和第1代
- 回收所有代（0、1、2代）及大对象堆（完全回收）

那么如何维护记忆集？何时添加或移除其中的引用？通用解决方案是在引用关系建立时进行记录，这主要发生在字段赋值时（参见代码清单5-2）。

**代码清单5-2** 以公共字段赋值为例展示老年代到年轻代的跨代引用（假设对象e比对象c存活在更老的代）

```csharp
E e = new E();
...
C c = new C();
e.SomeField = c;  // 此处将建立跨代引用
```

代码清单5-2的最后一行是记录新引用关系的理想位置。但我们需要以更全局的视角看待这个问题——C#中定义的字段只是语言规范规定的引用存储方式之一，记忆集机制不应与特定语言绑定。未来可能出现其他存储引用的方式（无论是C#还是新语言）。

因此，该机制实际通过运行时层面的底层技术实现——即第1章提到的写屏障（write barrier）概念。写屏障代码被注入到“Mutator.Write”操作中（参见第1章代码清单1-7），每当执行内存写入时都会触发该操作。由于这是极其频繁的操作，任何额外处理都可能带来巨大开销，因此必须谨慎设计写屏障。幸运的是，只有满足以下条件时才需要触发写屏障：

- 写入的值是托管对象引用
- 写入目标地址位于托管堆，且是有效对象的字段
- 目标地址所在代比被引用对象所在代更老

最终我们可能得到如代码清单5-3所示的实现逻辑：检查上述条件并在满足时记录引用。执行标记阶段时，记忆集中的引用应与其他根引用一同处理。

清单5-3. 支持记忆集的写屏障极简伪代码示意

```c#
Mutator.Write(address, value)
{
  *address = value;
  if (AreWriteBarrierConditionMeet(address, value))
  {
    RememberedSet.AddOrUpdate(address, value);
  }
}
```

这是阐释.NET运行时可能实现方式的通用概念。显然，每次执行都检查这些条件会带来巨大开销。但仔细思考后，我们会发现许多优化可能——主要源于这些条件可以在即时编译（JIT）期间预先判断。JIT编译器通过IL代码能明确知晓是否正在将托管对象引用存储到另一个托管对象的字段中。在生成汇编代码时，JIT可根据是否需要写屏障来生成对应版本的 `Mutator.Write`。这正是.NET运行时采用的方法。

> 若想深入了解细节，可从.NET Core源码中的 `CodeGen::genCodeForTreeNode`方法入手（针对GT_STOREIND操作数的情况）。该方法会调用 `CodeGen::genCodeForStoreInd`，后者通过 `gcIsWriteBarrierCandidate` 判断是否需要写屏障。若判定需要，则调用 `CodeGen::genGCWriteBarrier` 方法。该方法会生成调用两个辅助函数之一的汇编代码：`CORINFO_HELP_ASSIGN_REF`（当JIT编译器确认目标位于托管堆内时使用）或`CORINFO_HELP_CHECKED_ASSIGN_REF`（反之）。这两个辅助函数对应的汇编实现分别是 `JIT_WriteBarrier` 和 `JIT_CheckedWriteBarrier`，位于 `.\src\vm\amd64\JitHelpers_Fast.asm` 文件中。请注意，这些操作都发生在JIT编译期间，运行时仅会调用 `JIT_WriteBarrier` 或 `JIT_CheckedWriteBarrier` 函数（对应前述两个辅助函数）。另需说明，此描述仅针对x64运行时，x86架构的写屏障处理逻辑类似但路径不同，此处不再赘述。

让我们通过.NET应用程序来深入观察写屏障机制。从清单5-4的简单C#代码开始，该代码创建两个对象并将后者赋值给前者的字段。

清单5-4. 演示.NET写屏障的示例代码

```csharp
ClassA someClass = new ClassA();  
ClassB otherClass = new ClassB();  
someClass.FieldB = otherClass;  
```

清单5-4的代码可能被编译为如清单5-5所示的CIL代码（已简化但保留关键细节）。`ClassA` 和 `ClassB` 的实例保存在评估栈中，随后调用 `stfld` 指令——该指令将评估栈顶的值存储到栈次顶对象（通过元数据令牌描述的字段）中。

清单5-5. 由清单5-4示例代码编译生成的CIL代码

```
newobj ClassA::.ctor
newobj ClassB::.ctor
stfld ClassA::FieldB
```

在进行JIT编译时，这段代码可能会被转换为如清单5-6所示的汇编代码。具体生成的代码形态取决于运行时版本等诸多因素，但当前示例足以说明问题。可以看到，`stfld` 指令被转换成了 `JIT_WriteBarrier` 函数调用（此处未使用 `checked` 版本，因为JIT编译器明确知道操作的是托管对象）。

清单5-6. x64机器上JIT编译后的CIL代码

```
; 以下指令对应ClassA对象的内存分配及构造函数调用
mov rcx,7FFCC4BA6600h (MT: ClassA)
call coreclr!JIT_TrialAllocSFastMP_InlineGetThread (00007ffd`241d2130)
mov rdi,rax ; rdi保存ClassA引用
mov rcx,rdi
call System_Private_CoreLib+0xc04060 (00007ffd`22e44060) (System.Object..ctor(), mdToken:0000000006000103)
; 以下指令对应ClassB对象的内存分配及构造函数调用
mov rcx,7FFCC4BA67B8h (MT: ClassB)
call coreclr!JIT_TrialAllocSFastMP_InlineGetThread (00007ffd`241d2130)
mov rsi,rax ; rsi保存ClassB引用
mov rcx,rsi   call System_Private_CoreLib+0xc04060 (00007ffd`22e44060) (System.Object..ctor(), mdToken: 0000000006000103)
; 以下指令调用写屏障，存储引用并更新记忆集
lea rcx,[rdi+8] ; rcx包含ClassA对象中FieldB字段的地址
mov rdx,rsi ; rdx包含ClassB引用
call coreclr!JIT_WriteBarrier (00007ffd`2403fae0)
```

在深入分析 `JIT_WriteBarrier` 函数之前，还需要了解另一种重要技术——卡表（card tables）。

### 卡表（Card Tables）

您可能会注意到，单纯记录每个引用到记忆集的方法存在严重缺陷。在图5-7的简单场景中，记忆集确实很小（实际上仅包含单个引用）。但对于存在数百、数千甚至数百万对象相互引用的真实应用呢？更糟糕的是，.NET采用三代堆结构，导致可能的跨代引用数量更为庞大。加之对象引用变更本就是高频操作，若将记忆集简单实现为所有跨代引用的原始集合，必然会产生难以承受的开销。

正如常见的技术权衡方案，解决这个问题需要做出妥协。为了降低集合管理开销，系统不再精确追踪单个引用，而是改用固定大小的内存块进行跟踪——这种技术被称为卡表（card tables）。

为说明其原理，让我们将时间倒回图5-7所示场景之前（见图5-8a）。此时对象E尚未持有指向对象C的跨代引用。卡表的核心思想很简单：将老年代划分为固定大小的连续内存块（每块包含固定字节数）。在图5-8a示例中可以看到四个完整区块和第五个区块的部分空间：第一区块恰好不包含任何对象；第二区块仅含单个对象；第三区块包含某个对象的部分数据（对象可能跨越区块边界）；第四区块包含同一对象的剩余部分及另一对象的部分数据，以此类推。

每个内存区块在卡表数据结构中对应一个卡表项。初始状态下所有卡片均为“干净”状态（可通过单比特值0表示）。干净卡片意味着对应内存区域内不存在老年代到年轻代的跨代引用。

![](asserts/5-8a.png)

图5-8a. 卡表机制管理老年代到年轻代的跨代引用。此时展现的是图5-7场景发生前的瞬间状态，所有卡片均保持干净状态（尚未存在此类引用）

图5-8b则展示了将对象C赋值给对象E字段后的应用状态。系统定位到包含对象E的对应卡片，将该卡片整体标记为“脏”状态（通常通过将二进制值置为1来实现，这一过程称为“设置卡片”）

![](asserts/5-8b.png)

图5-8b. 卡表管理老年代到年轻代的跨代引用。当对象C被赋值给对象E的字段后，卡表中对应的卡片已被置位（标记为“脏”状态）

在下次垃圾回收（GC）时，该卡片集合内的所有对象均被视为可能的附加根。换言之，当发生新生代垃圾回收时，系统会同时从根对象和比当前回收代更老代中已标记卡片集合内的所有对象出发遍历对象图（通过这种方式，在我们的示例中对象C因其引用来自卡片集合中的对象E而被判定为可达）。

> 细心的读者可能会问：如果修改对象F的最后一个字段（该字段位于第四张卡片内），而对象F起始于第三张卡片，此时实际会标记哪张卡片？由于写屏障必须尽可能轻量级，系统仅会标记第四张卡片（因其对应被修改的地址）。随后在标记阶段，通过第9章描述的砖表(brick table)技术，可以定位到该卡片起始地址对应的对象（本例中即对象F）。

显然这会带来一定开销。由于单个老代到新生代的引用，必须遍历卡片内所有对象及其引用。这是性能与精度之间的权衡，可通过调整卡片大小来平衡。若卡片小到仅能容纳单个对象，就会退化为记忆集方案（每个引用单独追踪）；若卡片大到覆盖整个代，则相当于全量遍历对象图。

在.NET运行时中，单张卡片对应256字节（64位系统）或128字节（32位系统）。每张卡片由单个比特位标志表示——只要该128/256字节内存区域内有引用被写入，对应比特位就会被置位。这些比特位按字节分组，因此单个字节代表8×256字节（2048字节）的内存区域。卡片进一步以32个比特为单位组成“卡字”（card word），即4字节宽的DWORD类型（无符号长整型），故单个卡字对应8192字节内存空间。图5-9展示了64位平台下的组织结构（图示说明略）。

> 卡字的基本操作大小类型是 DWORD，DWORD是CPU高效处理的数据宽度（如x86架构），能提升标记和扫描速度。

![](asserts/5-9.png)

图5-9 .NET运行时中的卡表组织结构（64位版本）。卡表中的每个比特位代表256字节内存空间，这些比特位按字节分组（因此每个字节代表2,048字节内存区域），字节又进一步组合成卡字（card word），每个卡字对应的内存区域是单个字节的4倍大小。多个卡字进一步组合成卡表

> 卡字是卡表的更细粒度实现，具体表现为：
>
> 1. **位图表示**：卡字通常是一个 32 位或 64 位的整数(取决于平台)，每一位对应一个卡区域
> 2. **批量处理**：用一个字(word)同时管理多个卡，提高访问效率
> 3. **缓存友好**：通过合并多个卡的状态，减少缓存未命中率
>
> 在实际实现中，卡表可能被组织为卡字的数组，每个卡字管理 32 或 64 个卡区域(取决于字长)。

基于上述知识，我们现在可以深入分析前文提及的 `JIT_WriteBarrier` 函数。值得注意的是，`JIT_WriteBarrier` 代码的内存区域仅作为占位符使用，实际会运行时被替换为具体实现（显然在程序执行暂停时完成替换）。该占位符大小等于最大函数实现版本，以确保其他版本均可适配。我们将分析最简版本（见代码清单5-7），但所有版本差异极小，分析其一即可充分理解（详见下文注释说明）。

