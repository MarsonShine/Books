# 内存分配

在前三章中，我们对内存进行了广泛的理论性概述，并介绍了一些底层知识。从第四章开始，您逐渐深入了解了.NET中内存管理的具体实现。截至目前，您主要学习了部分.NET内部机制（第四章）以及内存的结构化组织方式（第五章）。基于已掌握的知识，本章将进入本书最重要的主题——.NET垃圾回收器（Garbage Collector）的工作原理与使用准则。随着内容逐渐深入核心，除了实现细节外，您将接触到更多诊断实践和代码层面的实用知识。

我们首先探讨任何程序运行都不可或缺的机制——内存分配。这一机制为应用程序中创建的对象提供内存空间。无论您如何优化代码，程序始终需要创建对象。即使是最简单的控制台程序，在执行用户代码的第一行之前，就已创建了大量辅助对象。鉴于其关键性和高频使用特性，本章将展示.NET如何极致优化分配器的效率。

您可能还记得第一章简要提到的“分配器”概念——“负责管理动态内存分配与释放的实体”。其中定义的`Allocator.Allocate(amount)` 方法用于提供指定大小的内存。在这个抽象层级上，分配器并不关心对象类型，仅负责提供正确的字节数（后续由运行时进行正确填充）。

## 内存分配导论

显然，我们抽象的 `Allocator.Allocate(amount)` 方法只是冰山一角。本章将深入探讨这个单一方法的实现细节及相关实践技巧。

回顾第二章可知，操作系统提供原生分配机制。C/C++等非托管环境直接依赖这些机制，通过 `malloc/free` 或 `new/delete` 等接口获取内存（Windows称为堆API，Linux使用 `mmap/sbrk` 组合调用）。而.NET环境在操作系统与托管程序之间增加了抽象层。大多数情况下，.NET等托管环境会预分配连续内存块，并在内部实现自有分配机制。这种方式比每次创建对象都向操作系统申请内存高效得多——系统调用开销较大，后续您将看到更简洁的替代方案。

如前一章所述，GC托管堆由段（segment）或.NET 7引入的区域（region）构成。本章讨论的对象分配即发生于此。虽然前文未明确说明，但您可能已推知以下分配规则：

- 小对象堆（SOH）中的对象在Generation 0分配
- 大对象堆（LOH）直接分配（因其未分代），物理存储于LOH所属的段/区域
-  通过 `GC.AllocateUninitializedArray` 和 `GC.AllocateArray` API在固定对象堆（POH）直接分配，固定化数组将存入POH区域
-  非GC堆用于特殊场景（如只读字面量字符串）

《运行时手册》总结道：“每次分配大对象时都会扫描整个大对象堆，而小对象分配仅考虑临时段”。

.NET实现了两种主流分配策略（第一章已提及）：**顺序分配（sequential allocation）**和**空闲列表分配（free-list allocation）**。下面我们结合.NET实现具体解析。

## 指针碰撞分配

分配器持有内存段资源。段内最简单的内存分配方式就是移动表示“当前已分配内存末端”的指针（称为分配指针）。只需将该指针移动待创建对象大小的字节数，即完成了内存分配！图6-1演示了这一原理：假设已有若干对象存在（图6-1a），分配指针指向对象存储末端。当请求为对象A分配内存时，分配器将指针推进指定字节数（图6-1b），并返回指针原位置作为对象地址。

![](asserts/6-1.png)

图6-1 简单顺序分配器实现

代码清单6-1的伪代码展示了这种简单高效的技术。正如后续内容所示，这正是CLR内部采用的分配策略之一。如此简洁的函数用汇编代码只需寥寥数条指令即可实现，效率极高。

代码清单6-1 基础指针碰撞分配器实现

```c
PTR Allocator.Allocate(amount) 
{
    PTR result = alloc_ptr;
    alloc_ptr += amount;
    return result;
}
```

这种分配方式亦称**指针碰撞分配（bump pointer allocation）**：通过“碰撞”移动分配指针来提供内存。该策略具有两大特性：

- 其一，顾名思义这是顺序算法——分配内存时指针始终单向移动。这种特性可带来良好的数据局部性。当程序批量创建对象时，这些对象往往代表相互关联的数据结构，因此相邻存储有利于性能（如第二章所述，CPU架构能充分利用时间局部性与空间局部性）。
- 其二，该模型假设内存空间无限大。虽然现实中的RAM容量有限（通常仅数十GB），但通过指针左侧的“魔法操作”（如回收闲置对象并压缩内存碎片），顺序分配仍具实用价值。这正是垃圾回收机制的核心作用——回收闲置对象后，分配指针将回退重置。

关于对象A存储区域的内存初始化问题：新对象需要零值化内存（对象构造函数负责初始化特定字段，这属于执行引擎而非垃圾回收器的职责）。若在 `Allocate` 方法中添加清零操作（如代码清单6-2所示），将引入不可忽视的性能开销。

代码清单6-2 带内存清零的顺序分配器实现

```c
PTR Allocator.Allocate(amount) 
{
    PTR result = alloc_ptr;
    ZeroMemory(alloc_ptr, amount);
    alloc_ptr += amount;
    return result;
}
```

为优化高频操作，.NET采用预清零内存策略。代码清单6-1代表快速路径，仅在必要时回退到代码清单6-2的清零操作。预清零还能提升CPU缓存效率——访问预清零内存会“预热”缓存。

系统通过**分配界限指针（allocation limit）**标识预清零内存区域边界，该区域称为**分配上下文（allocation context）**（见图6-2）。分配上下文是通过指针碰撞实现快速分配的核心区域。

![](asserts/6-2.png)

图6-2 分配上下文位于分配指针与分配界限之间，包含即用型零值化内存

当分配上下文空间不足时触发回退机制（代码清单6-3）。CLR的回退机制包含复杂处理流程（后续章节详述SOH/LOH分配时会展开），基础方案是扩展分配上下文或创建新上下文。典型扩展单位为分配量子（allocation quantum），默认情况下至少扩展一个量子单位（若请求量更大则相应扩展）。

代码清单6-3 带分配上下文的增强型指针碰撞分配器

```c
PTR Allocator.Allocate(amount) 
{
    if (alloc_ptr + amount <= alloc_limit) {
        // 快速路径：直接移动指针
        PTR result = alloc_ptr;
        alloc_ptr += amount;
        return result;
    } else {
        // 慢速路径：调整分配上下文（至少扩展一个量子单位）
        if (!try_allocate_more_space()) {
            throw OutOfMemoryException;
        }
        PTR result = alloc_ptr;
        alloc_ptr += amount;
        return result;
    }
}
```

如前章所述，GC通过两阶段段构建机制预备内存：先保留大块内存，再按需提交物理页。但提交新页时仅部分页面会立即清零，因此分配上下文可能未完全利用已提交内存（见图6-3）。这是内存预备成本与性能收益的平衡——例如SOH默认分配量子为8KB，而每次段扩展提交16个物理页（通常64KB）。

> 虽然默认分配量子为8KB，但在特定情况下会动态调整。当前CLR实现会根据分配速率和活跃上下文数量，在1,024至8,096字节区间自适应调整。

![](asserts/6-3.png)

图6-3. 段内的分配上下文——创建于当前分配末尾
通过这种方式，分配上下文可以持续增长，而无需每次向操作系统申请提交内存页。如图所示，这种内存获取方式经过精心设计，远比简单的逐对象分配高效得多。

分配上下文并非只能位于段内已提交内存的末端。它也可以创建在现有对象之间的空闲空间中（见图6-4）。这种情况下，分配指针将指向空闲空间的起始位置，分配限制指针则指向其末端。

![](asserts/6-4.png)

 图6-4. 段内的分配上下文——创建于空闲空间内部

最关键的特性在于分配上下文具有线程亲和性。这意味着应用程序中每个执行.NET代码的托管线程都拥有专属的分配上下文。正如《运行时之书》所述：“分配上下文与内存块的线程亲和性确保了特定内存块永远只被单个线程写入。因此只要当前分配上下文未耗尽，对象分配就无需加锁。”

这对性能至关重要。若分配上下文由线程共享，Allocate方法就必须进行同步操作，从而引入额外开销。而通过为每个线程配备独立上下文，就能使用简单的指针递增技术，无需担心其他线程会并发修改其分配指针或限制指针。该机制基于线程本地存储（TLS）实现，每个线程的 `ThreadLocalInfo` 结构体中存储着包含分配上下文的 `Thread` 类实例。Java开发者会将此技术称为线程本地分配缓冲区（TLAB）。

> 注意：在单逻辑处理器的机器上，只会存在单个全局分配上下文。因此访问必须同步，因为不同线程可能访问这个唯一的全局上下文。不过这种情况下同步成本极低，因为任意时刻只能有一个线程运行。而在Linux系统上，即使只有一个可用核心，也永远不会使用全局分配上下文。

多个分配上下文的存在使得图6-3和图6-4的简化示意图变得复杂。应用程序中存在多个托管线程时，更典型的场景是单个段内存在多个分配上下文（见图6-5）。随着程序运行，有些会位于段末端，有些则会复用对象间的空闲空间。

![](asserts/6-5.png) 图6-5. 段内多个分配上下文——每个线程对应一个

分配上下文存在于包含第0代和第1代的短暂段中。因此图6-5展示的短暂段结构中，“objects”部分会被划分为第1代和第0代（若程序初始阶段对象较少，可能还包含第2代）。

图6-6再次总结了短暂段的内存组织结构。请牢记——代只是段内部可移动的逻辑分界。

![](asserts/6-6.png)图6-6. 短暂段组织结构概要

对于区域（region）模式，上述描述仍然适用，区别在于分配上下文位于 `gen0` 区域，且起始处没有 `segment_info` 结构。注意单个区域仅包含同代对象。

原始的指针递增分配技术存在一个缺陷：若对已分配对象执行清扫式垃圾回收，会产生内存碎片。在分配指针左侧将出现大量空闲内存空洞（见图6-7a）。原始的实现（非.NET所用方案）无法识别这些碎片，只能持续消耗新内存。显然，任何成熟的GC实现都不会在清扫堆内存后不尝试利用这些空闲空间。最简单的解决方案是触发压缩式垃圾回收，使存活对象紧密排列，从而整体回退分配上下文（见图6-7b）。但相比依赖压缩，还存在更优解。

![](asserts/6-7.png)图6-7. 指针递增分配与碎片问题：(a)清扫式GC产生碎片；(b)压缩式GC通过回退分配上下文回收内存，但需要大量内存拷贝

为减少碎片，.NET实现在空闲空间内部创建分配上下文（见图6-4和图6-5，复用碎片形成的空洞是理想方案）。GC会间歇性启动压缩，随后所有分配上下文将在段末端自然重组（见图6-8）。

![](asserts/6-8.png)图6-8. 压缩式垃圾回收器工作后可能重组所有分配上下文——(a)初始状态下三个分配上下文分散在段内；(b)压缩后GC分配段将获得最优重组

## 空闲链表分配

空闲链表分配的核心思想非常简单。当运行时要求垃圾回收器分配指定字节数的内存时，它会遍历空闲链表以寻找足够容纳所需字节数的空闲间隙。如第1章所述，可采用两种主要的空闲链表扫描策略：

- 最佳适配（Best-fit）：寻找最符合需求空间的空闲内存间隙（即大于等于所需尺寸的最小内存块），以尽可能减少内存碎片。朴素实现需要扫描整个空闲项列表，但更优方案是采用后文介绍的桶式管理。
- 首次适配（First-fit）：只要找到合适的空闲内存间隙就立即停止扫描。这种方法时间效率高，但在碎片化控制方面远非最优。

微软.NET实现采用桶式管理来维护不同尺寸的空闲间隙链表：既能实现快速扫描，又不会过度牺牲碎片优化效果。通过控制桶的数量（即不同尺寸范围的空闲间隙分类数量），可以在性能与碎片减少之间取得平衡。若只存在单个桶（所有尺寸的空闲间隙都归入其中），就退化为朴素的首次适配策略；反之若设置大量桶（以极精细的间隙尺寸粒度划分），则近似最佳适配策略。后文将会看到，各代堆采用的桶数量各不相同。

堆内存中的空闲空间同样需要标记表示。当扫描堆遇到空闲空间时，必须知晓该区域大小才能确定如何跳转到下一个有效对象。虽然可以通过查询空闲链表中的对应条目实现，但这并非理想方案——需要在堆和空闲链表之间来回跳转，会产生显著开销。实际上，系统会在每个空闲空间起始位置直接存储一个伪对象（dummy object）。该伪对象形似常规数组，但具有特殊的“空闲对象”方法表（见图6-9）。与方法表指针相邻存储的是空闲空间的“元素”数量（类似于普通数组的结构）。由于“空闲对象”数组的单个元素尺寸定义为1字节，因此元素数量值即为以字节表示的空闲空间大小。这样在堆扫描过程中，只需读取空闲对象的长度值即可跳过该区域，定位到下一个有效对象。

> 过程解析：
>
> 上述过程可以想象一下，当你在一本书中划掉某些段落后，如何记住这些空白处有多长，以便将来可能重新利用这些空间？.NET垃圾回收器面临类似的挑战。
>
> ### 空闲空间标记的挑战
>
> 当对象被回收后，堆内存中会出现"空洞"（空闲空间）。垃圾回收器在扫描堆时需要知道：
>
> 1. 这里是空闲空间（不是有效对象）
> 2. 这个空闲空间有多大（需要跳过多少字节才能到达下一个真实对象）
>
> ## 常规思路与问题
>
> 一种方法是维护一个单独的"空闲链表"，记录所有空闲空间的位置和大小。但这种方式有个明显缺点：
>
> ```
> 扫描堆 -> 遇到空间 -> 去查空闲链表 -> 找到对应条目 -> 返回堆继续扫描
> ```
>
> 这样的“跳来跳去”会导致CPU缓存失效，严重降低性能。
>
> ### 实际解决方案
>
> .NET采用了一个聪明的方法：**把空闲空间本身伪装成一个特殊的“假对象”**。
>
> 具体做法：
>
> 1. 在每个空闲空间的起始位置，构造一个看起来像数组的“伪对象”
> 2. 这个“伪对象”有两个关键部分：
>    - 指向特殊“空闲对象方法表”的指针（告诉GC：“我是空闲空间！”）
>    - 一个表示“元素数量”的整数值（实际就是空闲空间的字节数）
>
> 布局图如下：
>
> ```
> 真实对象布局:  [方法表指针] [其他字段...]
> 空闲对象布局:  [特殊方法表指针] [空间大小] [........未使用区域........]
>               ↑              ↑        ↑
>               告诉GC这是空闲块 告诉GC这块有多大 这部分可被重新分配
> ```
>
> 这种设计的妙处在于：
>
> 1. **无需额外查表**：GC看到特殊方法表指针就知道“这是空闲块”
> 2. **一次读取就能跳过**：紧挨着方法表指针的就是空间大小，读取后立即跳过
> 3. **与正常对象处理流程一致**：GC可以用统一的方式处理所有内存块
>
> ### 例子
>
> 假设内存中有这样的布局：
>
> ```
> [对象A][空闲区域200字节][对象B][空闲区域100字节][对象C]
> ```
>
> GC扫描时会看到：
>
> ```
> [对象A][空闲对象头部|200][对象B][空闲对象头部|100][对象C]
> ```
>
> 当扫描到第一个空闲对象头部时，GC检测到特殊方法表，立即知道这是空闲块，并直接跳过200字节找到对象B，非常高效。

此外，某些代际的空闲对象会采用名为“undo”的特殊元素取代常规对象头（这对“空闲对象”实属冗余）。如后文所述，该元素在处理链表时会临时保存其他空闲链表项的地址。

![](asserts/6-9.png)图6-9. 表示GC堆上空闲空间的“自由对象”结构。对于某些代，还使用了“撤销”或指向前一个“自由对象”的指针等额外元素。

> 注意：若对与“自由对象”相关的.NET Core代码感兴趣，可从 `gc_heap::make_unused_array` 方法入手，该方法负责准备自由对象。如您所见，它会调用使用静态全局指针 `g_pFreeObjectMethodTable` 作为新方法表的 `SetFree` 方法。随后通过调用 `allocator::thread_item(gap_start, size)` 或 `allocator::thread_item_front(gap_start, size)`方法将间隙添加到空闲列表。此操作仅针对大于最小对象尺寸两倍的间隙执行，这有助于通过忽略小项目来降低列表管理开销。

每个代的分配器维护一个桶列表（见图6-10）。首个桶表示尺寸小于第一个桶大小（编码在 `first_bucket_bits` 字段中）的空闲项目列表。后续每个桶的尺寸翻倍，最后一个桶用于存储无上限的大尺寸项目。每个桶维护对应空闲项目列表的描述信息，特别是其头部。

如图6-10所示，列表本身在GC堆上的“自由对象”之间实现为双链表（第2代情况下）或单链表（其他代）。这使得在列表操作期间能快速遍历，因为至少堆的部分内容已在缓存中。在此维护单独列表并无必要。

双链版本的空闲列表已在.NET 6中引入。它仅用于第2代，因为该设计旨在解决一个特定问题：在此版本之前，所有代的空闲列表在并发清扫阶段（第11章详述）开始时会被重置。但当第2代进行并发清扫时，SOH中可能发生常规分配，从而触发“前台GC”。若该GC收集第1代并执行压缩操作，可能会尝试将晋升对象分配到第2代的间隙中。但由于列表已被清空，GC无法重用空闲空间，直到列表完全重建。这可能导致第2代不必要地增长，因为晋升对象需要被“分配”到某处——即该代末尾。

自.NET 6起，第2代空闲列表在GC开始时不再重置。但如今列表可能变得更大，因此采用更高效的数据结构（如双链表）对其中元素的链接与解链操作更为有利。

![](asserts/6-10.png)图6-10. CLR中基于桶的空闲列表实现：(a)单链版本（用于第0、1代和UOH），(b)双链版本（用于第2代)

> 您可能会惊讶于每个代都有独立分配器，因为此前明确说明对象分配仅发生在SOH的第0代、LOH或POH中。但当GC将存活对象从一代晋升到下一代时，实际上也是在"分配"到下一代。

每代都有独立的桶数量和大小配置，如表6-1所示。可见两个短暂代仅为所有尺寸维护单个桶。第2代配置在32位和64位运行时中存在差异。例如在64位运行时中，GC会为小于256B、512B、1kB、2kB、4kB、8kB的尺寸维护桶，最后一个桶用于大于8kB的项目。

表6-1. 每代的空闲列表桶配置

| 区域         | 首桶尺寸     | 桶数量 |
| ------------ | ------------ | ------ |
| 第0代和第1代 | Int.Max      | 1      |
| 第2代        | 256B（64位） | 12     |
|              | 128B（32位） | 12     |
| LOH          | 64kB         | 7      |
| POH          | 256B         | 19     |

基于分桶空闲列表的分配相当简单（见代码清单6-4）。从首个合适桶开始，尝试在对应空闲列表中寻找匹配的空闲项目。从空闲项目分配所需内存后，可能仍有剩余空闲内存。若该剩余空间大于两个对象的最小尺寸（即64位平台为48字节），则会用剩余部分创建新空闲项目并添加到列表；否则，该小内存区域将被计为不可用碎片。

代码清单6-4. 空闲列表分配的伪代码实现

```c#
PTR Allocator.Allocate(amount)
{ 
	foreach (bucket in buckets) 
	{ 
	  if (amount < bucket.BucketSize) // 跳过项目过小的桶 { foreach (freeItem in bucket.FreeItemList) 		{ 
	    if (size < freeItem.Size) 
	    {  
	        UnlinkItem(freeItem); 
	        ZeroMemory(freeItem.Start, amount); 
	        if (RemainingFreeSpaceBigEnough()) 
	      	    LinkRemainingFreeSpace(freeItem, amount); 
	        return freeItem.Start; 
	     }
	   }
	 }
}
```

> 注意代码清单6-4中的内存清零操作仅适用于用户分配项目（需创建全新状态），但在晋升期间为老代分配时可省略（晋升对象内容将覆盖该空间）。这正是.NET的实现方式。此外，对于第0代和第1代，若空闲项目无法满足所需尺寸则会被丢弃（成为不可用碎片）。这意味着这两代中每个空闲项目仅会被检查一次。这是在维护空闲列表成本与允许碎片化成本之间的又一折衷方案。两个最年轻的代经常被压缩，因此空闲列表会频繁重建。

前文提及的“自由对象”中的 Undo 元素由垃圾回收器在计划阶段使用——具体而言，当决定使用老代中的某个空闲项目进行分配时（即用于存放从年轻代晋升的对象）。若找到合适项目，GC会通过指针操作（类似经典单链表操作）从空闲列表“解链”该空闲项目（见图6-11）：

- 被移除项目的地址存储在前一项目的“undo”字段中（若存在前一项目）；
- 前一项目的“next”指针改为指向被移除项目所指向的下一可用空闲项目。

![](asserts/6-11.png)图6-11. 单链表情况下的空闲列表项目解链操作。在计划阶段结束时，垃圾回收器可能决定执行清扫式回收而非压缩式回收。采用清扫式回收时，老年代保持原状，因此需要撤销那些计划中的分配操作。通过使用存储在“undo”字段中的空闲项目地址，可恢复原始列表。

> 空闲链表就像一串串联起来的空房子，每个房子（空闲内存块）都知道下一个空房子在哪里：
>
> ```
> [空闲块A] → [空闲块B] → [空闲块C] → ... → null
> ```
>
> 每个空闲块包含：
>
> - 一个“next”指针（指向链表中的下一个空闲块）
> - 一个“undo”字段（这是关键，稍后解释）
> - 块的大小信息
>
> ### 分配过程与“解链”操作
>
> 当GC需要给从年轻代晋升的对象分配空间时，它会从老年代的空闲链表中寻找合适大小的块。找到后，需要从链表中移除这个块（称为“解链”）：
>
> 解链前：
>
> ```
> [块A] → [块B] → [块C] → [块D]
> ```
>
> 假设要移除块C，解链后：
>
> ```
> [块A] → [块B] → [块D]  [块C]（已分离，准备分配给新对象）
> ```
>
> ### “Undo”机制的作用
>
> 这就是“Undo”元素发挥作用的地方！在实际执行解链操作时：
>
> 1. GC会在块B的“undo”字段中**记录被移除块C的地址**
> 2. 然后修改块B的“next”指针，让它指向块D
>
> ```
> 修改后的块B：[next指向D, undo记录了C的地址]
> ```
>
> ### 为什么需要“Undo”机制？
>
> 垃圾回收分为多个阶段，其中“计划阶段”会做出一些临时决策。有时候，GC可能先计划使用压缩式回收（移动对象以消除碎片），但后来决定改用清扫式回收（只标记可用空间，不移动对象）。
>
> 如果发生这种变化：
>
> 1. 老年代应保持原状
> 2. 那些已经从空闲链表中移除准备分配的块需要**放回原位**
>
> 撤销过程：
>
> 1. GC查看块B的“undo”字段，找到被移除的块C
> 2. 重新调整块B的“next”指针指回块C
> 3. 块C的“next”指针仍然指向块D
> 4. 结果：链表恢复原状
>
> ```
> 恢复后：[块A] → [块B] → [块C] → [块D]
> ```
>
> ### 总结
>
> “Undo”机制是.NET垃圾回收器的一个巧妙设计，允许GC在做出最终决策前尝试不同的内存管理策略，同时保留“反悔”的能力。这种灵活性对于平衡内存利用率和GC暂停时间至关重要。

不过您将在第7章中更详细地了解计划阶段、压缩阶段与清扫阶段之间的关联机制。

## 创建新对象

了解了两种基本的内存分配技术后，我们现在可以探讨它们在.NET内存分配中的协同工作机制，包括小对象堆（SOH）、大对象堆（LOH）和固定对象堆的分配原理。

当我们在C#中通过 `new` 运算符创建非数组引用类型对象时（如代码清单6-5所示），该操作会被编译为 CIL 指令 `newobj`（见代码清单6-6）。

代码清单6-5. C#中的对象创建示例

```
 var obj = new SomeClass();
```

代码清单6-6. 公共中间语言中的对象创建示例

```
newobj instance void SomeClass::.ctor()
```

JIT 编译器会根据不同条件为 `newobj` 指令生成对应的函数调用。最常见的情况是使用某种分配辅助函数，其决策逻辑如图6-12所示。这些决策基于JIT编译期间或运行时启动阶段已知的条件。图中可见两种主要选择：

- 若对象超过大对象阈值（将被放入LOH）或具有终结器（详见第12章的特殊方法），则使用通用但稍慢的 `JIT_New` 辅助函数。
- 否则将使用更快的辅助函数——具体版本取决于运行平台和GC模式。

![](asserts/6-12.png)

图6-12. JIT编译期间选择分配辅助函数的决策树（函数名称源自.NET Core源码)

需特别注意，该决策树仅在JIT编译阶段使用，最终会生成对应的分配辅助函数调用。因此在程序正常运行时不会产生额外开销，仅需调用预先确定的辅助函数。

> 注：创建数组时会生成CIL指令 `newarr`，该指令存在多个优化版本（例如专为一维对象数组或一维值类型数组设计的版本）。但由于底层分配机制本质上相同，为简洁起见此处不再赘述。

若需深入研究.NET分配机制，可从处理 `CEE_NEWOBJ` 操作码的JIT编译器逻辑入手（参见 `importer.cpp::Compiler::impImportBlockCode` 方法）。该方法会根据创建对象类型（数组、字符串、值类型或引用类型）做出不同处理。对于字符串和数组之外的引用类型，会调用 `CEEInfo::getNewHelper` 来执行图6-12中的部分决策逻辑。较慢的通用辅助函数对应 `CORINFO_HELP_NEWFAST` 常量，而更快的版本对应 `CORINFO_HELP_NEWSFAST`。这些辅助函数的具体实现由运行时启动阶段的 `InitJITHelpers1` 方法决定，这解释了图6-12决策树的剩余部分。

### 小对象堆分配

小对象堆的分配主要基于指针碰撞（bump pointer）技术。核心目标是通过前文所述的分配上下文机制，以指针碰撞方式完成大多数对象分配。仅当该方式失败时才会执行较慢的备用路径（后文详述）。

SOH最快的分配辅助函数仅需数行汇编代码（见代码清单6-7）。根据图6-12的决策树，在Server GC模式下或多逻辑处理器机器上，所有不含终结器的SOH对象都会使用该版本。

> 单处理器机器专用版本名为 `JIT_TrialAllocSFastSP`，包含锁机制以确保全局单一分配上下文的安全访问。

这段高效代码仅通过若干比较和加法指令即可完成（如注释所示）。在理想情况下，“分配”内存只需递增已提交且初始化的分配指针值，这正是“NET中内存分配成本极低”说法的由来。

代码清单6-7. 最高效的分配辅助函数

```assembly
; As input, rcx contains MethodTable pointer
; As result, rax contains the address of the new object
LEAF_ENTRY JIT_TrialAllocSFastMP_InlineGetThread, _TEXT
    ; Read object size into edx
    mov edx, [rcx + OFFSET__MethodTable__m_BaseSize]
    ; m_BaseSize is guaranteed to be a multiple of 8.
    ; Read Thread Local Storage address into r11
    INLINE_GETTHREAD r11
    ; Read alloc_limit into r10
    mov r10, [r11 + OFFSET__Thread__m_alloc_context__alloc_limit]
    ; Read alloct_ptr into rax
    mov rax, [r11 + OFFSET__Thread__m_alloc_context__alloc_ptr]
    add rdx, rax ; rdx = alloc_ptr + size
    cmp rdx, r10 ; is rdx smaller than alloc_limit
    ja AllocFailed
    ; Update alloc_ptr in TLS
    mov [r11 + OFFSET__Thread__m_alloc_context__alloc_ptr], rdx
	; Store the MT under alloc_ptr address (setting up the new object)
    mov [rax], rcx
    ret
AllocFailed:
	jmp JIT_NEW ; fast-path failed, jump to slow-path
LEAF_END JIT_TrialAllocSFastMP_InlineGetThread, _TEXT
```

如果当前分配上下文小于所需大小，最快的基于汇编的分配器会回退到调用更通用的 `JIT_NEW` 辅助函数（该函数也用于带终结器的对象或大对象堆中的分配）。这个通用辅助函数包含慢路径分配代码。正是这种必须放弃快速路径的情况，使得“分配是廉价的”这一说法并不总是成立。慢路径是一个相当复杂的状态机，它试图找到合适的位置来存储所需大小的对象。

慢路径有多复杂？它从 `a_state_start` 状态开始，当之前描述的快速分配失败时触发。该状态无条件转入 `a_state_try_fit` 状态，调用 `gc_heap::soh_try_fit` 方法（见图6-13）。随后整个复杂的流程便开始了！存在多种可能的决策路径，以下是其中最重要的几种：

- 慢路径首先尝试利用**短暂段(ephemeral segment)**中现有的未使用空间（见图6-13描述的 `soh_try_fit` 方法）。具体会：
  - 尝试通过空闲列表找到适合新分配上下文的空闲间隙（回顾图6-4）
  - 尝试在已提交内存中找到足够空间
  - 尝试从保留内存中提交更多内存
- 如果上述方法均失败，则会触发垃圾回收。根据条件不同，可能会多次触发回收。
- 如果所有尝试均失败，分配器将无法分配请求的内存，从而触发 `OutOfMemoryException`。

你可以在.NET的 `gc_heap::allocate_soh` 方法中找到小对象堆慢路径代码。

> 由于小对象堆分配触发GC（最常见情况）在CLR事件数据中通常标记为 `AllocSmall` 原因。

![](asserts/6-13.png)图6-13展示了 `soh_try_fit` 方法的决策树

需要重点注意的是，与指针碰撞分配的快速路径相比，慢路径可能变得极其复杂（包括尝试适配空闲列表项甚至触发多次GC）。因此，“分配是廉价的”这一结论仅在特定条件下成立。开发者应当理解分配的真实成本，通过限制不必要的对象分配、避免盲目使用高分配量的库来优化性能。即使不触发GC，慢路径本身也可能代价高昂。在性能关键代码中，最佳实践是彻底避免分配（这也引出了性能优化第14条准则——避免分配）。

还需注意，带终结器的对象会使用更通用的分配辅助函数，且终结机制会带来额外开销（第12章详述）。这使得第25条准则——避免使用终结器显得尤为重要。

### 大对象堆与固定对象堆分配

令人惊讶的是，CLR在大对象堆（LOH）和固定对象堆（POH）的分配上共享了大量代码。主要区别在于：显然POH中的对象不可移动（无法执行压缩）。查看.NET源代码时，你会发现许多函数和变量名包含“uoh”（User Old Heap的缩写），这个名称源于LOH和POH中的对象都由用户代码分配，并被标识为老年代（gen 2）的一部分。描述分配位置的 `GC_ALLOC_FLAGS` 标志定义了三个常量，它们直观展现了LOH与POH的相似性：

```
GC_ALLOC_LARGE_OBJECT_HEAP =32,
GC_ALLOC_PINNED_OBJECT_HEAP =64,
GC_ALLOC_USER_OLD_HEAP = GC_ALLOC_LARGE_OBJECT_HEAP | GC_ALLOC_PINNED_OBJECT_HEAP,
```

分配过程中的主要差异是：LOH中的对象必须对齐内存边界，而POH不需要。此外，即使分配超过LOH阈值大小的固定数组，仍会置于POH而非LOH。其余代码逻辑则完全一致。

在用户旧堆（UOH）中分配时，第一步是查找空闲列表中是否有足够空间。若未找到，则使用段末尾空间的简化指针碰撞技术。虽然分配上下文会在函数间传递，但其仅用于跟踪对象分配地址。UOH分配没有快速路径，因此不采用基于分配上下文的优化——对于LOH而言，85,000字节的最小尺寸远大于典型分配上下文大小，清零如此大块内存的开销会使分配上下文优化的收益微乎其微；对于POH分配，虽然固定缓冲区通常也较大（且共享代码库的维护价值），使得分配上下文优化同样不具吸引力。

因此，UOH分配器始终采用与SOH慢路径相似的统一路径：

- 首先尝试利用现有未使用空间（见图6-14描述的 `uoh_try_fit`方法）

  - 在每个包含LOH或POH的段中，尝试在空闲列表中找到适合对象的空闲间隙

  - 尝试在已提交内存中寻找足够空间

  - 尝试从保留内存提交更多内存

- 若上述方法均失败，则触发垃圾回收（可能多次）

- 最终若仍失败，将引发 `OutOfMemoryException`

> UOH分配逻辑实现在.NET的 `gc_heap::allocate_uoh`方法中，其流程如图6-14所示。

![](asserts/6-14.png)

如你所见，用户旧堆（UOH）的状态机比小对象堆（SOH）更为复杂。但需特别注意：尽管UOH不使用分配上下文，分配器仍需确保对象创建后的初始状态清零，这意味着必须对内存进行归零操作。对于大型对象而言，内存清零的代价可能非常显著——结合第4章所述的内存访问延迟（表4-2），清零一个数MB大小的对象可能需要数十毫秒，这对应用程序而言可能是相当长的时间。

因此必须牢记：UOH中的对象分配成本远高于SOH，这引出了第15条准则——避免过度UOH分配。**创建可复用对象池是解决该问题最简单的方案。**

> 注意 .NET垃圾回收器持续改进，运行时新版本常引入重要优化。例如自.NET 4.5（及.NET Core 1.0）起，LOH分配器通过前文所述的分桶策略显著提升了空闲列表利用率。

一个有趣的问题是：.NET中可创建的最大对象尺寸是多少？自.NET诞生起，该限制始终是 `2GB`。虽然实践中很少创建如此巨大的对象，但某些场景可能需要更大的数组。在.NET 4.5之前无法突破此限制，而4.5版本新增的 `gcAllowVeryLargeObjects` 配置项（见代码清单6-8）允许创建接近64位有符号长整型上限（减去微小偏移量）的对象。虽然该设置支持创建超过 `2GB` 的数组，但其他对象尺寸限制仍保持不变：

- 数组元素数量上限仍为 `UInt32.MaxValue`（2,147,483,591）
- 单维数组最大索引：字节数组及单字节结构数组为 2,147,483,591（0x7FFFFFC7），其他类型为 2,146,435,071（0X7FEFFFFF）

- 字符串等非数组对象的最大尺寸不变

代码清单6-8 启用 `gcAllowVeryLargeObjects` 的配置（默认禁用）

```
<configuration>
	<runtime>
		<gcAllowVeryLargeObjects enabled="true" />
	</runtime>
</configuration>
```

如此巨大的对象将分配至何处？毫无疑问会被分配至LOH段——因其远超大型对象阈值。运行时很可能为此创建全新段，因为现有段几乎不可能容纳如此庞大的对象。请注意：由于内存访问延迟，分配此类巨型对象可能需要数秒时间！

> 如第4、5章所述，字符串字面量和运行时类型分配在NGHC（非GC堆）中。第15章将详述未公开API及其在此处分配对象的危险性。若需探查冻结对象的分配位置，可追踪 `SystemDomain::GetFrozenObjectHeapManager` 调用路径，最终会定位到运行时类型和静态装箱实例的分配点。

## 堆平衡机制

如前所述，服务器模式下的GC管理多个堆——每个逻辑处理器对应一个托管堆。多托管堆意味着存在多个短暂段和多个大对象堆段，同时应用程序中存在多个托管线程。这两者如何关联？线程如何与堆绑定？

这需要先解答另一个问题：堆如何与逻辑处理器绑定？理解该机制需结合第4章CPU与内存协作的知识。CLR致力于让托管堆尽可能“靠近”特定逻辑CPU核心（从访问时序角度），并避免同步开销，因此做出以下设计决策：

- 当操作系统支持获取当前线程执行核心信息时（Windows及多数Linux/macOS版本均支持），每个逻辑CPU固定绑定一个托管堆且永不更改。该设计通过提升局部性最大化CPU缓存效率，避免缓存一致性协议开销
- 若操作系统不支持核心信息，则执行微基准测试来经验性确定特定核心访问速度最快的堆
- 若机器采用 `NUMA` 架构（第2章提及），堆绑定将限制在单个 `NUMA` 组内

> 若对微基准测试实现感兴趣，可从 `heap_select::access_time` 静态函数开始研究

当托管线程开始分配内存时，会被绑定到其当前执行处理器对应的堆。图6-15展示了GC托管堆、线程与逻辑核心的典型关系：运行于两个逻辑处理器的线程，正在消耗采用“all-at-once”策略构建的托管内存（见前章）。第一个CPU绑定 SOH₁ 和 LOH₁ 段，第二个CPU绑定 SOH₂ 和 LOH₂ 段（段间完全隔离）。注意处理器虽然操作进程地址空间中的特定内存区域（通过段概念隔离），但内存中并不存在操作系统或硬件层面的魔法隔离机制。不过这种隔离设计能有效利用缓存，因为每个CPU频繁且独占地操作这些段。

运行在 CPU#1 的线程（标记为 T₁ 和 T₂）其分配上下文位于 SOH₁ 内，而第二个CPU上的线程（示例中为 T₃）则使用第二个堆，以此类推。由于LOH不使用分配上下文，图中未作体现。

![](asserts/6-15.png)

图6-15展示了逻辑处理器、线程与GC托管堆的绑定关系示意图

当线程创建时，由操作系统决定其执行的逻辑处理器。这在所有托管线程内存分配量相近时运行良好，但某些情况下可能出现部分线程分配量显著高于其他线程的现象，这将导致如图6-16所示的堆不平衡状态：线程3和4的内存分配量远超线程1和2（导致 SOH₂ 剩余空间急剧减少）。这种状态会引发三个主要问题：

- SOH₂ 将很快面临内存不足，触发GC并最终需要创建新SOH段
- CPU缓存利用率失衡
- 负责回收SOH₁的线程将承担更多工作

![](asserts/6-16.png)

图6-16 多线程分配不均导致的堆不平衡状态

GC在通过慢路径分配时会执行堆平衡检查。若检测到不平衡，将为高分配线程重新分配堆——即将其分配上下文迁移至其他堆。这显然会违反前文所述的设计原则（线程在某个逻辑核心上执行却使用其他核心绑定的堆），因此GC会立即要求操作系统将该线程迁移至对应逻辑CPU执行。目前该行为仅通过Windows的 `SetThreadIdealProcessorEx` 函数实现（其他操作系统可能缺乏等效API）。堆平衡后的状态如图6-17所示。

![](asserts/6-17.png)

图6-17 图6-15场景的堆平衡结果

自.NET 4.5起，LOH堆也实现了平衡机制，这显著提升了分配性能。由于LOH平衡技术与SOH相同，此处不再赘述。

#### 固定对象堆(POH)分配API

自.NET 5起，只有数组能被分配到固定对象堆(Pinned Object Heap)。唯一的方式是使用GC类中的两个方法——`AllocateArray` 或 `AllocateUninitializedArray`，并将其 `pinned` 参数设为true。这些固定数组的元素类型只能是纯值类型（不包含任何引用类型字段），包括布尔值、数值以及仅包含值类型字段的结构体。若尝试分配不符合要求的类型数组，代码虽能编译通过，但运行时会抛出 `ArgumentException`。该限制在.NET 8中被移除。

## 内存不足异常(OutOfMemoryException)

从分配器的决策树可见，有时确实无法分配所需内存。这种情况常被误解，让我们深入剖析细节。

首先，何时会抛出 `OutOfMemoryException`？这是前文所述分配路径的最后选择，意味着：

- 垃圾回收器在分配期间已被触发（可能多次，包括完全压缩式GC），因此SOH碎片化不应是主因。除非问题极其特殊且波动，否则再次触发GC几乎无济于事。内存不足异常绝非因.NET运行时忘记回收内存所致。不过，若LOH分配时出现该异常，可考虑显式触发LOH压缩（见第7章）并再次执行GC。

- 分配器无法准备指定大小的内存区域，原因有二：
  - 虚拟内存耗尽：分配器无法保留足够大的内存区域（如创建新段）。主要由虚拟内存碎片化导致，32位运行时尤甚。碎片化会导致内存使用效率低下，因此即使系统显示有充足空闲RAM，仍可能抛出异常。切记表2-5所示的严格虚拟地址空间限制——32位运行时在64位系统上仅能支配2-3GB虚拟地址空间，即便物理内存充足。
  - 物理后备存储耗尽（包括RAM和页面/交换文件）：分配器无法提交更多内存（如扩展现有段）。需注意操作系统统筹管理所有进程内存，当系统整体内存使用（含磁盘交换）接近极限时，即使显示有空闲RAM，系统仍会拒绝运行时提交内存的请求。

由此可得两个重要结论：

- 手动触发GC通常无法缓解内存不足异常（除非在分配大对象时显式触发LOH压缩）
- 出现内存不足异常时系统显示有空闲RAM属正常现象

若遭遇内存不足异常，除修复内存泄漏外，可采取以下优化措施：

- **减少对象分配**：分析内存使用，消除不必要分配（本章后续将揭示许多隐藏的分配来源）
- **使用对象池**：通过对象复用降低碎片化，现有池方案可直接使用或自行实现
- **启用VM保留模式**：如第5章所述（对32位运行时尤为重要）
- **编译为64位**：简单有效的解决方案，通常能大幅扩展虚拟地址空间

### 场景6-1：内存不足异常

**问题描述**：某.NET生产环境进程间歇性崩溃并抛出`OutOfMemoryException`，其他环境无法复现。由于问题发生频率极低，难以附加监控工具，且无法预测下次异常发生时间，导致无法捕获完整内存转储进行分析。

**分析方案**：好消息是，Windows平台（.NET Framework和.NET Core）可配置在 `OutOfMemoryException` 发生时自动捕获完整内存转储！具体步骤如下：

1. **安装ProcDump监控工具**
   - 通过命令`procdump -i <转储文件存储目录> -ma`全局安装（如图6-18所示）
   - 调查完成后务必用 `procdump -u` 卸载，否则机器上所有崩溃进程都会生成转储文件，可能导致磁盘空间耗尽

![](asserts/6-18.png)

图 6-18. 在系统范围内安装 `procdump`工具可在发生 `OutOfMemoryException` 时自动生成内存转储文件

- 进程现已被监控，发生`OutOfMemoryException`时将自动生成完整转储
- 用 WinDbg 打开转储文件，执行`!analyze -v`命令（见代码清单6-9），可获取异常详细信息

代码清单6-9：WinDbg分析内存转储——内存不足异常信息

```plaintext
> !analyze -v
***********************************************************************
*                                                                     *
*                        Exception Analysis                           *
*                                                                     *
***********************************************************************
...
STACK_TEXT: 
02b7ee0c 273b25dd TestOOM!TestOOM.Program.TestOOM+0x3d  
02b7ee1c 273b1992 TestOOM!TestOOM.Program.Main+0x82
...
FAULTING_SOURCE_LINE: C:\Book\code\TestOOM\Program.cs  
FAULTING_SOURCE_FILE: C:\Book\code\TestOOM\Program.cs  
FAULTING_SOURCE_LINE_NUMBER: 89  
FAULTING_SOURCE_CODE:  
86: List<byte[]> bytes = new List<byte[]>();  
87: while (true)  
88: {  
> 89:     bytes.Add(new byte[1024 * 1024 * 1024]);  
90: }  
91: }
```

如代码清单6-9所示：`STACK_TEXT` 段显示触发异常的线程调用栈。若编译时包含符号文件（PDB），`FAULTING_SOURCE_CODE` 段会直接定位到引发异常的源代码行（本例为第89行的大数组分配）

对于 .NET Framework，你可以使用 `!analyzeoom` 命令可获取 GC 相关的 OOM 信息（代码清单6-10）。注意：该SOS命令暂不支持.NET Core。

代码清单6-10：WinDbg中analyzeoom命令显示的GC相关OOM信息

```plaintext
0:000> !analyzeoom  
Managed OOM occured after GC #2 (Requested to allocate 0 bytes)  
Reason: Didn't have enough memory to allocate an LOH segment  
Detail: LOH: Failed to reserve memory (1090519040 bytes)
```

您可以继续采用本书提到的其他基于内存转储的分析方法，包括检查内存段（segments）和堆（heaps）状态。需要特别注意的是：触发内存不足异常的代码可能并非问题的直接根源——它可能只是恰好在分配器无法为新对象找到合适内存空间时执行的线程。实际的内存瓶颈可能隐藏在别处。因此，建议重点分析转储文件中以下内容：

- 数量最多的对象类型
- 体积最大的对象实例
- 对象在各代堆中的分布情况

> 注意：在抛出内存不足异常前，CLR需要先分配异常对象实例。但在内存耗尽的情况下，运行时采用了巧妙的机制：系统启动时会预分配 `OutOfMemoryException` 实例（通过 `SystemDomain::CreatePreallocatedExceptions` 函数），当无法新建异常对象时直接复用该预分配实例。该机制同样适用于 `StackOverflowException` 和 `ExecutionEngineException` （具体实现可参考  `GetBestOutOfMemoryException`函数代码）。

