# 内存分配

在前三章中，我们对内存进行了广泛的理论性概述，并介绍了一些底层知识。从第四章开始，您逐渐深入了解了.NET中内存管理的具体实现。截至目前，您主要学习了部分.NET内部机制（第四章）以及内存的结构化组织方式（第五章）。基于已掌握的知识，本章将进入本书最重要的主题——.NET垃圾回收器（Garbage Collector）的工作原理与使用准则。随着内容逐渐深入核心，除了实现细节外，您将接触到更多诊断实践和代码层面的实用知识。

我们首先探讨任何程序运行都不可或缺的机制——内存分配。这一机制为应用程序中创建的对象提供内存空间。无论您如何优化代码，程序始终需要创建对象。即使是最简单的控制台程序，在执行用户代码的第一行之前，就已创建了大量辅助对象。鉴于其关键性和高频使用特性，本章将展示.NET如何极致优化分配器的效率。

您可能还记得第一章简要提到的“分配器”概念——“负责管理动态内存分配与释放的实体”。其中定义的`Allocator.Allocate(amount)` 方法用于提供指定大小的内存。在这个抽象层级上，分配器并不关心对象类型，仅负责提供正确的字节数（后续由运行时进行正确填充）。

## 内存分配导论

显然，我们抽象的 `Allocator.Allocate(amount)` 方法只是冰山一角。本章将深入探讨这个单一方法的实现细节及相关实践技巧。

回顾第二章可知，操作系统提供原生分配机制。C/C++等非托管环境直接依赖这些机制，通过 `malloc/free` 或 `new/delete` 等接口获取内存（Windows称为堆API，Linux使用 `mmap/sbrk` 组合调用）。而.NET环境在操作系统与托管程序之间增加了抽象层。大多数情况下，.NET等托管环境会预分配连续内存块，并在内部实现自有分配机制。这种方式比每次创建对象都向操作系统申请内存高效得多——系统调用开销较大，后续您将看到更简洁的替代方案。

如前一章所述，GC托管堆由段（segment）或.NET 7引入的区域（region）构成。本章讨论的对象分配即发生于此。虽然前文未明确说明，但您可能已推知以下分配规则：

- 小对象堆（SOH）中的对象在Generation 0分配
- 大对象堆（LOH）直接分配（因其未分代），物理存储于LOH所属的段/区域
-  通过 `GC.AllocateUninitializedArray` 和 `GC.AllocateArray` API在固定对象堆（POH）直接分配，固定化数组将存入POH区域
-  非GC堆用于特殊场景（如只读字面量字符串）

《运行时手册》总结道：“每次分配大对象时都会扫描整个大对象堆，而小对象分配仅考虑临时段”。

.NET实现了两种主流分配策略（第一章已提及）：**顺序分配（sequential allocation）**和**空闲列表分配（free-list allocation）**。下面我们结合.NET实现具体解析。

## 指针碰撞分配

分配器持有内存段资源。段内最简单的内存分配方式就是移动表示“当前已分配内存末端”的指针（称为分配指针）。只需将该指针移动待创建对象大小的字节数，即完成了内存分配！图6-1演示了这一原理：假设已有若干对象存在（图6-1a），分配指针指向对象存储末端。当请求为对象A分配内存时，分配器将指针推进指定字节数（图6-1b），并返回指针原位置作为对象地址。

![](asserts/6-1.png)

图6-1 简单顺序分配器实现

代码清单6-1的伪代码展示了这种简单高效的技术。正如后续内容所示，这正是CLR内部采用的分配策略之一。如此简洁的函数用汇编代码只需寥寥数条指令即可实现，效率极高。

代码清单6-1 基础指针碰撞分配器实现

```c
PTR Allocator.Allocate(amount) 
{
    PTR result = alloc_ptr;
    alloc_ptr += amount;
    return result;
}
```

这种分配方式亦称**指针碰撞分配（bump pointer allocation）**：通过“碰撞”移动分配指针来提供内存。该策略具有两大特性：

- 其一，顾名思义这是顺序算法——分配内存时指针始终单向移动。这种特性可带来良好的数据局部性。当程序批量创建对象时，这些对象往往代表相互关联的数据结构，因此相邻存储有利于性能（如第二章所述，CPU架构能充分利用时间局部性与空间局部性）。
- 其二，该模型假设内存空间无限大。虽然现实中的RAM容量有限（通常仅数十GB），但通过指针左侧的“魔法操作”（如回收闲置对象并压缩内存碎片），顺序分配仍具实用价值。这正是垃圾回收机制的核心作用——回收闲置对象后，分配指针将回退重置。

关于对象A存储区域的内存初始化问题：新对象需要零值化内存（对象构造函数负责初始化特定字段，这属于执行引擎而非垃圾回收器的职责）。若在 `Allocate` 方法中添加清零操作（如代码清单6-2所示），将引入不可忽视的性能开销。

代码清单6-2 带内存清零的顺序分配器实现

```c
PTR Allocator.Allocate(amount) 
{
    PTR result = alloc_ptr;
    ZeroMemory(alloc_ptr, amount);
    alloc_ptr += amount;
    return result;
}
```

为优化高频操作，.NET采用预清零内存策略。代码清单6-1代表快速路径，仅在必要时回退到代码清单6-2的清零操作。预清零还能提升CPU缓存效率——访问预清零内存会“预热”缓存。

系统通过**分配界限指针（allocation limit）**标识预清零内存区域边界，该区域称为**分配上下文（allocation context）**（见图6-2）。分配上下文是通过指针碰撞实现快速分配的核心区域。

![](asserts/6-2.png)

图6-2 分配上下文位于分配指针与分配界限之间，包含即用型零值化内存

当分配上下文空间不足时触发回退机制（代码清单6-3）。CLR的回退机制包含复杂处理流程（后续章节详述SOH/LOH分配时会展开），基础方案是扩展分配上下文或创建新上下文。典型扩展单位为分配量子（allocation quantum），默认情况下至少扩展一个量子单位（若请求量更大则相应扩展）。

代码清单6-3 带分配上下文的增强型指针碰撞分配器

```c
PTR Allocator.Allocate(amount) 
{
    if (alloc_ptr + amount <= alloc_limit) {
        // 快速路径：直接移动指针
        PTR result = alloc_ptr;
        alloc_ptr += amount;
        return result;
    } else {
        // 慢速路径：调整分配上下文（至少扩展一个量子单位）
        if (!try_allocate_more_space()) {
            throw OutOfMemoryException;
        }
        PTR result = alloc_ptr;
        alloc_ptr += amount;
        return result;
    }
}
```

如前章所述，GC通过两阶段段构建机制预备内存：先保留大块内存，再按需提交物理页。但提交新页时仅部分页面会立即清零，因此分配上下文可能未完全利用已提交内存（见图6-3）。这是内存预备成本与性能收益的平衡——例如SOH默认分配量子为8KB，而每次段扩展提交16个物理页（通常64KB）。

> 虽然默认分配量子为8KB，但在特定情况下会动态调整。当前CLR实现会根据分配速率和活跃上下文数量，在1,024至8,096字节区间自适应调整。

![](asserts/6-3.png)

图6-3. 段内的分配上下文——创建于当前分配末尾
通过这种方式，分配上下文可以持续增长，而无需每次向操作系统申请提交内存页。如图所示，这种内存获取方式经过精心设计，远比简单的逐对象分配高效得多。

分配上下文并非只能位于段内已提交内存的末端。它也可以创建在现有对象之间的空闲空间中（见图6-4）。这种情况下，分配指针将指向空闲空间的起始位置，分配限制指针则指向其末端。

![](asserts/6-4.png)

 图6-4. 段内的分配上下文——创建于空闲空间内部

最关键的特性在于分配上下文具有线程亲和性。这意味着应用程序中每个执行.NET代码的托管线程都拥有专属的分配上下文。正如《运行时之书》所述：“分配上下文与内存块的线程亲和性确保了特定内存块永远只被单个线程写入。因此只要当前分配上下文未耗尽，对象分配就无需加锁。”

这对性能至关重要。若分配上下文由线程共享，Allocate方法就必须进行同步操作，从而引入额外开销。而通过为每个线程配备独立上下文，就能使用简单的指针递增技术，无需担心其他线程会并发修改其分配指针或限制指针。该机制基于线程本地存储（TLS）实现，每个线程的 `ThreadLocalInfo` 结构体中存储着包含分配上下文的 `Thread` 类实例。Java开发者会将此技术称为线程本地分配缓冲区（TLAB）。

> 注意：在单逻辑处理器的机器上，只会存在单个全局分配上下文。因此访问必须同步，因为不同线程可能访问这个唯一的全局上下文。不过这种情况下同步成本极低，因为任意时刻只能有一个线程运行。而在Linux系统上，即使只有一个可用核心，也永远不会使用全局分配上下文。

多个分配上下文的存在使得图6-3和图6-4的简化示意图变得复杂。应用程序中存在多个托管线程时，更典型的场景是单个段内存在多个分配上下文（见图6-5）。随着程序运行，有些会位于段末端，有些则会复用对象间的空闲空间。

![](asserts/6-5.png) 图6-5. 段内多个分配上下文——每个线程对应一个

分配上下文存在于包含第0代和第1代的短暂段中。因此图6-5展示的短暂段结构中，“objects”部分会被划分为第1代和第0代（若程序初始阶段对象较少，可能还包含第2代）。

图6-6再次总结了短暂段的内存组织结构。请牢记——代只是段内部可移动的逻辑分界。

![](asserts/6-6.png)图6-6. 短暂段组织结构概要

对于区域（region）模式，上述描述仍然适用，区别在于分配上下文位于 `gen0` 区域，且起始处没有 `segment_info` 结构。注意单个区域仅包含同代对象。

原始的指针递增分配技术存在一个缺陷：若对已分配对象执行清扫式垃圾回收，会产生内存碎片。在分配指针左侧将出现大量空闲内存空洞（见图6-7a）。原始的实现（非.NET所用方案）无法识别这些碎片，只能持续消耗新内存。显然，任何成熟的GC实现都不会在清扫堆内存后不尝试利用这些空闲空间。最简单的解决方案是触发压缩式垃圾回收，使存活对象紧密排列，从而整体回退分配上下文（见图6-7b）。但相比依赖压缩，还存在更优解。

![](asserts/6-7.png)图6-7. 指针递增分配与碎片问题：(a)清扫式GC产生碎片；(b)压缩式GC通过回退分配上下文回收内存，但需要大量内存拷贝

为减少碎片，.NET实现在空闲空间内部创建分配上下文（见图6-4和图6-5，复用碎片形成的空洞是理想方案）。GC会间歇性启动压缩，随后所有分配上下文将在段末端自然重组（见图6-8）。

![](asserts/6-8.png)图6-8. 压缩式垃圾回收器工作后可能重组所有分配上下文——(a)初始状态下三个分配上下文分散在段内；(b)压缩后GC分配段将获得最优重组

## 空闲链表分配

空闲链表分配的核心思想非常简单。当运行时要求垃圾回收器分配指定字节数的内存时，它会遍历空闲链表以寻找足够容纳所需字节数的空闲间隙。如第1章所述，可采用两种主要的空闲链表扫描策略：

- 最佳适配（Best-fit）：寻找最符合需求空间的空闲内存间隙（即大于等于所需尺寸的最小内存块），以尽可能减少内存碎片。朴素实现需要扫描整个空闲项列表，但更优方案是采用后文介绍的桶式管理。
- 首次适配（First-fit）：只要找到合适的空闲内存间隙就立即停止扫描。这种方法时间效率高，但在碎片化控制方面远非最优。

微软.NET实现采用桶式管理来维护不同尺寸的空闲间隙链表：既能实现快速扫描，又不会过度牺牲碎片优化效果。通过控制桶的数量（即不同尺寸范围的空闲间隙分类数量），可以在性能与碎片减少之间取得平衡。若只存在单个桶（所有尺寸的空闲间隙都归入其中），就退化为朴素的首次适配策略；反之若设置大量桶（以极精细的间隙尺寸粒度划分），则近似最佳适配策略。后文将会看到，各代堆采用的桶数量各不相同。

堆内存中的空闲空间同样需要标记表示。当扫描堆遇到空闲空间时，必须知晓该区域大小才能确定如何跳转到下一个有效对象。虽然可以通过查询空闲链表中的对应条目实现，但这并非理想方案——需要在堆和空闲链表之间来回跳转，会产生显著开销。实际上，系统会在每个空闲空间起始位置直接存储一个伪对象（dummy object）。该伪对象形似常规数组，但具有特殊的“空闲对象”方法表（见图6-9）。与方法表指针相邻存储的是空闲空间的“元素”数量（类似于普通数组的结构）。由于“空闲对象”数组的单个元素尺寸定义为1字节，因此元素数量值即为以字节表示的空闲空间大小。这样在堆扫描过程中，只需读取空闲对象的长度值即可跳过该区域，定位到下一个有效对象。

> 过程解析：
>
> 上述过程可以想象一下，当你在一本书中划掉某些段落后，如何记住这些空白处有多长，以便将来可能重新利用这些空间？.NET垃圾回收器面临类似的挑战。
>
> ### 空闲空间标记的挑战
>
> 当对象被回收后，堆内存中会出现"空洞"（空闲空间）。垃圾回收器在扫描堆时需要知道：
>
> 1. 这里是空闲空间（不是有效对象）
> 2. 这个空闲空间有多大（需要跳过多少字节才能到达下一个真实对象）
>
> ## 常规思路与问题
>
> 一种方法是维护一个单独的"空闲链表"，记录所有空闲空间的位置和大小。但这种方式有个明显缺点：
>
> ```
> 扫描堆 -> 遇到空间 -> 去查空闲链表 -> 找到对应条目 -> 返回堆继续扫描
> ```
>
> 这样的“跳来跳去”会导致CPU缓存失效，严重降低性能。
>
> ### 实际解决方案
>
> .NET采用了一个聪明的方法：**把空闲空间本身伪装成一个特殊的“假对象”**。
>
> 具体做法：
>
> 1. 在每个空闲空间的起始位置，构造一个看起来像数组的“伪对象”
> 2. 这个“伪对象”有两个关键部分：
>    - 指向特殊“空闲对象方法表”的指针（告诉GC：“我是空闲空间！”）
>    - 一个表示“元素数量”的整数值（实际就是空闲空间的字节数）
>
> 布局图如下：
>
> ```
> 真实对象布局:  [方法表指针] [其他字段...]
> 空闲对象布局:  [特殊方法表指针] [空间大小] [........未使用区域........]
>               ↑              ↑        ↑
>               告诉GC这是空闲块 告诉GC这块有多大 这部分可被重新分配
> ```
>
> 这种设计的妙处在于：
>
> 1. **无需额外查表**：GC看到特殊方法表指针就知道“这是空闲块”
> 2. **一次读取就能跳过**：紧挨着方法表指针的就是空间大小，读取后立即跳过
> 3. **与正常对象处理流程一致**：GC可以用统一的方式处理所有内存块
>
> ### 例子
>
> 假设内存中有这样的布局：
>
> ```
> [对象A][空闲区域200字节][对象B][空闲区域100字节][对象C]
> ```
>
> GC扫描时会看到：
>
> ```
> [对象A][空闲对象头部|200][对象B][空闲对象头部|100][对象C]
> ```
>
> 当扫描到第一个空闲对象头部时，GC检测到特殊方法表，立即知道这是空闲块，并直接跳过200字节找到对象B，非常高效。

此外，某些代际的空闲对象会采用名为“undo”的特殊元素取代常规对象头（这对“空闲对象”实属冗余）。如后文所述，该元素在处理链表时会临时保存其他空闲链表项的地址。

![](asserts/6-9.png)图6-9. 表示GC堆上空闲空间的“自由对象”结构。对于某些代，还使用了“撤销”或指向前一个“自由对象”的指针等额外元素。

> 注意：若对与“自由对象”相关的.NET Core代码感兴趣，可从 `gc_heap::make_unused_array` 方法入手，该方法负责准备自由对象。如您所见，它会调用使用静态全局指针 `g_pFreeObjectMethodTable` 作为新方法表的 `SetFree` 方法。随后通过调用 `allocator::thread_item(gap_start, size)` 或 `allocator::thread_item_front(gap_start, size)`方法将间隙添加到空闲列表。此操作仅针对大于最小对象尺寸两倍的间隙执行，这有助于通过忽略小项目来降低列表管理开销。

每个代的分配器维护一个桶列表（见图6-10）。首个桶表示尺寸小于第一个桶大小（编码在 `first_bucket_bits` 字段中）的空闲项目列表。后续每个桶的尺寸翻倍，最后一个桶用于存储无上限的大尺寸项目。每个桶维护对应空闲项目列表的描述信息，特别是其头部。

如图6-10所示，列表本身在GC堆上的“自由对象”之间实现为双链表（第2代情况下）或单链表（其他代）。这使得在列表操作期间能快速遍历，因为至少堆的部分内容已在缓存中。在此维护单独列表并无必要。

双链版本的空闲列表已在.NET 6中引入。它仅用于第2代，因为该设计旨在解决一个特定问题：在此版本之前，所有代的空闲列表在并发清扫阶段（第11章详述）开始时会被重置。但当第2代进行并发清扫时，SOH中可能发生常规分配，从而触发“前台GC”。若该GC收集第1代并执行压缩操作，可能会尝试将晋升对象分配到第2代的间隙中。但由于列表已被清空，GC无法重用空闲空间，直到列表完全重建。这可能导致第2代不必要地增长，因为晋升对象需要被“分配”到某处——即该代末尾。

自.NET 6起，第2代空闲列表在GC开始时不再重置。但如今列表可能变得更大，因此采用更高效的数据结构（如双链表）对其中元素的链接与解链操作更为有利。

![](asserts/6-10.png)图6-10. CLR中基于桶的空闲列表实现：(a)单链版本（用于第0、1代和UOH），(b)双链版本（用于第2代)

> 您可能会惊讶于每个代都有独立分配器，因为此前明确说明对象分配仅发生在SOH的第0代、LOH或POH中。但当GC将存活对象从一代晋升到下一代时，实际上也是在"分配"到下一代。

每代都有独立的桶数量和大小配置，如表6-1所示。可见两个短暂代仅为所有尺寸维护单个桶。第2代配置在32位和64位运行时中存在差异。例如在64位运行时中，GC会为小于256B、512B、1kB、2kB、4kB、8kB的尺寸维护桶，最后一个桶用于大于8kB的项目。

表6-1. 每代的空闲列表桶配置

| 区域         | 首桶尺寸     | 桶数量 |
| ------------ | ------------ | ------ |
| 第0代和第1代 | Int.Max      | 1      |
| 第2代        | 256B（64位） | 12     |
|              | 128B（32位） | 12     |
| LOH          | 64kB         | 7      |
| POH          | 256B         | 19     |

基于分桶空闲列表的分配相当简单（见代码清单6-4）。从首个合适桶开始，尝试在对应空闲列表中寻找匹配的空闲项目。从空闲项目分配所需内存后，可能仍有剩余空闲内存。若该剩余空间大于两个对象的最小尺寸（即64位平台为48字节），则会用剩余部分创建新空闲项目并添加到列表；否则，该小内存区域将被计为不可用碎片。

代码清单6-4. 空闲列表分配的伪代码实现

```c#
PTR Allocator.Allocate(amount)
{ 
	foreach (bucket in buckets) 
	{ 
	  if (amount < bucket.BucketSize) // 跳过项目过小的桶 { foreach (freeItem in bucket.FreeItemList) 		{ 
	    if (size < freeItem.Size) 
	    {  
	        UnlinkItem(freeItem); 
	        ZeroMemory(freeItem.Start, amount); 
	        if (RemainingFreeSpaceBigEnough()) 
	      	    LinkRemainingFreeSpace(freeItem, amount); 
	        return freeItem.Start; 
	     }
	   }
	 }
}
```

> 注意代码清单6-4中的内存清零操作仅适用于用户分配项目（需创建全新状态），但在晋升期间为老代分配时可省略（晋升对象内容将覆盖该空间）。这正是.NET的实现方式。此外，对于第0代和第1代，若空闲项目无法满足所需尺寸则会被丢弃（成为不可用碎片）。这意味着这两代中每个空闲项目仅会被检查一次。这是在维护空闲列表成本与允许碎片化成本之间的又一折衷方案。两个最年轻的代经常被压缩，因此空闲列表会频繁重建。

前文提及的“自由对象”中的 Undo 元素由垃圾回收器在计划阶段使用——具体而言，当决定使用老代中的某个空闲项目进行分配时（即用于存放从年轻代晋升的对象）。若找到合适项目，GC会通过指针操作（类似经典单链表操作）从空闲列表“解链”该空闲项目（见图6-11）：

- 被移除项目的地址存储在前一项目的“undo”字段中（若存在前一项目）；
- 前一项目的“next”指针改为指向被移除项目所指向的下一可用空闲项目。

![](asserts/6-11.png)图6-11. 单链表情况下的空闲列表项目解链操作。在计划阶段结束时，垃圾回收器可能决定执行清扫式回收而非压缩式回收。采用清扫式回收时，老年代保持原状，因此需要撤销那些计划中的分配操作。通过使用存储在“undo”字段中的空闲项目地址，可恢复原始列表。

> 空闲链表就像一串串联起来的空房子，每个房子（空闲内存块）都知道下一个空房子在哪里：
>
> ```
> [空闲块A] → [空闲块B] → [空闲块C] → ... → null
> ```
>
> 每个空闲块包含：
>
> - 一个“next”指针（指向链表中的下一个空闲块）
> - 一个“undo”字段（这是关键，稍后解释）
> - 块的大小信息
>
> ### 分配过程与“解链”操作
>
> 当GC需要给从年轻代晋升的对象分配空间时，它会从老年代的空闲链表中寻找合适大小的块。找到后，需要从链表中移除这个块（称为“解链”）：
>
> 解链前：
>
> ```
> [块A] → [块B] → [块C] → [块D]
> ```
>
> 假设要移除块C，解链后：
>
> ```
> [块A] → [块B] → [块D]  [块C]（已分离，准备分配给新对象）
> ```
>
> ### “Undo”机制的作用
>
> 这就是“Undo”元素发挥作用的地方！在实际执行解链操作时：
>
> 1. GC会在块B的“undo”字段中**记录被移除块C的地址**
> 2. 然后修改块B的“next”指针，让它指向块D
>
> ```
> 修改后的块B：[next指向D, undo记录了C的地址]
> ```
>
> ### 为什么需要“Undo”机制？
>
> 垃圾回收分为多个阶段，其中“计划阶段”会做出一些临时决策。有时候，GC可能先计划使用压缩式回收（移动对象以消除碎片），但后来决定改用清扫式回收（只标记可用空间，不移动对象）。
>
> 如果发生这种变化：
>
> 1. 老年代应保持原状
> 2. 那些已经从空闲链表中移除准备分配的块需要**放回原位**
>
> 撤销过程：
>
> 1. GC查看块B的“undo”字段，找到被移除的块C
> 2. 重新调整块B的“next”指针指回块C
> 3. 块C的“next”指针仍然指向块D
> 4. 结果：链表恢复原状
>
> ```
> 恢复后：[块A] → [块B] → [块C] → [块D]
> ```
>
> ### 总结
>
> “Undo”机制是.NET垃圾回收器的一个巧妙设计，允许GC在做出最终决策前尝试不同的内存管理策略，同时保留“反悔”的能力。这种灵活性对于平衡内存利用率和GC暂停时间至关重要。

不过您将在第7章中更详细地了解计划阶段、压缩阶段与清扫阶段之间的关联机制。

## 创建新对象

了解了两种基本的内存分配技术后，我们现在可以探讨它们在.NET内存分配中的协同工作机制，包括小对象堆（SOH）、大对象堆（LOH）和固定对象堆的分配原理。

当我们在C#中通过 `new` 运算符创建非数组引用类型对象时（如代码清单6-5所示），该操作会被编译为 CIL 指令 `newobj`（见代码清单6-6）。

代码清单6-5. C#中的对象创建示例

```
 var obj = new SomeClass();
```

代码清单6-6. 公共中间语言中的对象创建示例

```
newobj instance void SomeClass::.ctor()
```

JIT 编译器会根据不同条件为 `newobj` 指令生成对应的函数调用。最常见的情况是使用某种分配辅助函数，其决策逻辑如图6-12所示。这些决策基于JIT编译期间或运行时启动阶段已知的条件。图中可见两种主要选择：

- 若对象超过大对象阈值（将被放入LOH）或具有终结器（详见第12章的特殊方法），则使用通用但稍慢的 `JIT_New` 辅助函数。
- 否则将使用更快的辅助函数——具体版本取决于运行平台和GC模式。

![](asserts/6-12.png)

图6-12. JIT编译期间选择分配辅助函数的决策树（函数名称源自.NET Core源码)

需特别注意，该决策树仅在JIT编译阶段使用，最终会生成对应的分配辅助函数调用。因此在程序正常运行时不会产生额外开销，仅需调用预先确定的辅助函数。

> 注：创建数组时会生成CIL指令 `newarr`，该指令存在多个优化版本（例如专为一维对象数组或一维值类型数组设计的版本）。但由于底层分配机制本质上相同，为简洁起见此处不再赘述。

若需深入研究.NET分配机制，可从处理 `CEE_NEWOBJ` 操作码的JIT编译器逻辑入手（参见 `importer.cpp::Compiler::impImportBlockCode` 方法）。该方法会根据创建对象类型（数组、字符串、值类型或引用类型）做出不同处理。对于字符串和数组之外的引用类型，会调用 `CEEInfo::getNewHelper` 来执行图6-12中的部分决策逻辑。较慢的通用辅助函数对应 `CORINFO_HELP_NEWFAST` 常量，而更快的版本对应 `CORINFO_HELP_NEWSFAST`。这些辅助函数的具体实现由运行时启动阶段的 `InitJITHelpers1` 方法决定，这解释了图6-12决策树的剩余部分。

### 小对象堆分配

小对象堆的分配主要基于指针碰撞（bump pointer）技术。核心目标是通过前文所述的分配上下文机制，以指针碰撞方式完成大多数对象分配。仅当该方式失败时才会执行较慢的备用路径（后文详述）。

SOH最快的分配辅助函数仅需数行汇编代码（见代码清单6-7）。根据图6-12的决策树，在Server GC模式下或多逻辑处理器机器上，所有不含终结器的SOH对象都会使用该版本。

> 单处理器机器专用版本名为 `JIT_TrialAllocSFastSP`，包含锁机制以确保全局单一分配上下文的安全访问。

这段高效代码仅通过若干比较和加法指令即可完成（如注释所示）。在理想情况下，“分配”内存只需递增已提交且初始化的分配指针值，这正是“NET中内存分配成本极低”说法的由来。

代码清单6-7. 最高效的分配辅助函数

```assembly
; As input, rcx contains MethodTable pointer
; As result, rax contains the address of the new object
LEAF_ENTRY JIT_TrialAllocSFastMP_InlineGetThread, _TEXT
    ; Read object size into edx
    mov edx, [rcx + OFFSET__MethodTable__m_BaseSize]
    ; m_BaseSize is guaranteed to be a multiple of 8.
    ; Read Thread Local Storage address into r11
    INLINE_GETTHREAD r11
    ; Read alloc_limit into r10
    mov r10, [r11 + OFFSET__Thread__m_alloc_context__alloc_limit]
    ; Read alloct_ptr into rax
    mov rax, [r11 + OFFSET__Thread__m_alloc_context__alloc_ptr]
    add rdx, rax ; rdx = alloc_ptr + size
    cmp rdx, r10 ; is rdx smaller than alloc_limit
    ja AllocFailed
    ; Update alloc_ptr in TLS
    mov [r11 + OFFSET__Thread__m_alloc_context__alloc_ptr], rdx
	; Store the MT under alloc_ptr address (setting up the new object)
    mov [rax], rcx
    ret
AllocFailed:
	jmp JIT_NEW ; fast-path failed, jump to slow-path
LEAF_END JIT_TrialAllocSFastMP_InlineGetThread, _TEXT
```

如果当前分配上下文小于所需大小，最快的基于汇编的分配器会回退到调用更通用的 `JIT_NEW` 辅助函数（该函数也用于带终结器的对象或大对象堆中的分配）。这个通用辅助函数包含慢路径分配代码。正是这种必须放弃快速路径的情况，使得“分配是廉价的”这一说法并不总是成立。慢路径是一个相当复杂的状态机，它试图找到合适的位置来存储所需大小的对象。

慢路径有多复杂？它从 `a_state_start` 状态开始，当之前描述的快速分配失败时触发。该状态无条件转入 `a_state_try_fit` 状态，调用 `gc_heap::soh_try_fit` 方法（见图6-13）。随后整个复杂的流程便开始了！存在多种可能的决策路径，以下是其中最重要的几种：

- 慢路径首先尝试利用**短暂段(ephemeral segment)**中现有的未使用空间（见图6-13描述的 `soh_try_fit` 方法）。具体会：
  - 尝试通过空闲列表找到适合新分配上下文的空闲间隙（回顾图6-4）
  - 尝试在已提交内存中找到足够空间
  - 尝试从保留内存中提交更多内存
- 如果上述方法均失败，则会触发垃圾回收。根据条件不同，可能会多次触发回收。
- 如果所有尝试均失败，分配器将无法分配请求的内存，从而触发 `OutOfMemoryException`。

你可以在.NET的 `gc_heap::allocate_soh` 方法中找到小对象堆慢路径代码。

> 由于小对象堆分配触发GC（最常见情况）在CLR事件数据中通常标记为 `AllocSmall` 原因。

![](asserts/6-13.png)图6-13展示了 `soh_try_fit` 方法的决策树

需要重点注意的是，与指针碰撞分配的快速路径相比，慢路径可能变得极其复杂（包括尝试适配空闲列表项甚至触发多次GC）。因此，“分配是廉价的”这一结论仅在特定条件下成立。开发者应当理解分配的真实成本，通过限制不必要的对象分配、避免盲目使用高分配量的库来优化性能。即使不触发GC，慢路径本身也可能代价高昂。在性能关键代码中，最佳实践是彻底避免分配（这也引出了性能优化第14条准则——避免分配）。

还需注意，带终结器的对象会使用更通用的分配辅助函数，且终结机制会带来额外开销（第12章详述）。这使得第25条准则——避免使用终结器显得尤为重要。

### 大对象堆与固定对象堆分配

令人惊讶的是，CLR在大对象堆（LOH）和固定对象堆（POH）的分配上共享了大量代码。主要区别在于：显然POH中的对象不可移动（无法执行压缩）。查看.NET源代码时，你会发现许多函数和变量名包含“uoh”（User Old Heap的缩写），这个名称源于LOH和POH中的对象都由用户代码分配，并被标识为老年代（gen 2）的一部分。描述分配位置的 `GC_ALLOC_FLAGS` 标志定义了三个常量，它们直观展现了LOH与POH的相似性：

```
GC_ALLOC_LARGE_OBJECT_HEAP =32,
GC_ALLOC_PINNED_OBJECT_HEAP =64,
GC_ALLOC_USER_OLD_HEAP = GC_ALLOC_LARGE_OBJECT_HEAP | GC_ALLOC_PINNED_OBJECT_HEAP,
```

分配过程中的主要差异是：LOH中的对象必须对齐内存边界，而POH不需要。此外，即使分配超过LOH阈值大小的固定数组，仍会置于POH而非LOH。其余代码逻辑则完全一致。

在用户旧堆（UOH）中分配时，第一步是查找空闲列表中是否有足够空间。若未找到，则使用段末尾空间的简化指针碰撞技术。虽然分配上下文会在函数间传递，但其仅用于跟踪对象分配地址。UOH分配没有快速路径，因此不采用基于分配上下文的优化——对于LOH而言，85,000字节的最小尺寸远大于典型分配上下文大小，清零如此大块内存的开销会使分配上下文优化的收益微乎其微；对于POH分配，虽然固定缓冲区通常也较大（且共享代码库的维护价值），使得分配上下文优化同样不具吸引力。

因此，UOH分配器始终采用与SOH慢路径相似的统一路径：

- 首先尝试利用现有未使用空间（见图6-14描述的 `uoh_try_fit`方法）

  - 在每个包含LOH或POH的段中，尝试在空闲列表中找到适合对象的空闲间隙

  - 尝试在已提交内存中寻找足够空间

  - 尝试从保留内存提交更多内存

- 若上述方法均失败，则触发垃圾回收（可能多次）

- 最终若仍失败，将引发 `OutOfMemoryException`

> UOH分配逻辑实现在.NET的 `gc_heap::allocate_uoh`方法中，其流程如图6-14所示。

![](asserts/6-14.png)

如你所见，用户旧堆（UOH）的状态机比小对象堆（SOH）更为复杂。但需特别注意：尽管UOH不使用分配上下文，分配器仍需确保对象创建后的初始状态清零，这意味着必须对内存进行归零操作。对于大型对象而言，内存清零的代价可能非常显著——结合第4章所述的内存访问延迟（表4-2），清零一个数MB大小的对象可能需要数十毫秒，这对应用程序而言可能是相当长的时间。

因此必须牢记：UOH中的对象分配成本远高于SOH，这引出了第15条准则——避免过度UOH分配。**创建可复用对象池是解决该问题最简单的方案。**

> 注意 .NET垃圾回收器持续改进，运行时新版本常引入重要优化。例如自.NET 4.5（及.NET Core 1.0）起，LOH分配器通过前文所述的分桶策略显著提升了空闲列表利用率。

一个有趣的问题是：.NET中可创建的最大对象尺寸是多少？自.NET诞生起，该限制始终是 `2GB`。虽然实践中很少创建如此巨大的对象，但某些场景可能需要更大的数组。在.NET 4.5之前无法突破此限制，而4.5版本新增的 `gcAllowVeryLargeObjects` 配置项（见代码清单6-8）允许创建接近64位有符号长整型上限（减去微小偏移量）的对象。虽然该设置支持创建超过 `2GB` 的数组，但其他对象尺寸限制仍保持不变：

- 数组元素数量上限仍为 `UInt32.MaxValue`（2,147,483,591）
- 单维数组最大索引：字节数组及单字节结构数组为 2,147,483,591（0x7FFFFFC7），其他类型为 2,146,435,071（0X7FEFFFFF）

- 字符串等非数组对象的最大尺寸不变

代码清单6-8 启用 `gcAllowVeryLargeObjects` 的配置（默认禁用）

```
<configuration>
	<runtime>
		<gcAllowVeryLargeObjects enabled="true" />
	</runtime>
</configuration>
```

如此巨大的对象将分配至何处？毫无疑问会被分配至LOH段——因其远超大型对象阈值。运行时很可能为此创建全新段，因为现有段几乎不可能容纳如此庞大的对象。请注意：由于内存访问延迟，分配此类巨型对象可能需要数秒时间！

> 如第4、5章所述，字符串字面量和运行时类型分配在NGHC（非GC堆）中。第15章将详述未公开API及其在此处分配对象的危险性。若需探查冻结对象的分配位置，可追踪 `SystemDomain::GetFrozenObjectHeapManager` 调用路径，最终会定位到运行时类型和静态装箱实例的分配点。

## 堆平衡机制

如前所述，服务器模式下的GC管理多个堆——每个逻辑处理器对应一个托管堆。多托管堆意味着存在多个短暂段和多个大对象堆段，同时应用程序中存在多个托管线程。这两者如何关联？线程如何与堆绑定？

这需要先解答另一个问题：堆如何与逻辑处理器绑定？理解该机制需结合第4章CPU与内存协作的知识。CLR致力于让托管堆尽可能“靠近”特定逻辑CPU核心（从访问时序角度），并避免同步开销，因此做出以下设计决策：

- 当操作系统支持获取当前线程执行核心信息时（Windows及多数Linux/macOS版本均支持），每个逻辑CPU固定绑定一个托管堆且永不更改。该设计通过提升局部性最大化CPU缓存效率，避免缓存一致性协议开销
- 若操作系统不支持核心信息，则执行微基准测试来经验性确定特定核心访问速度最快的堆
- 若机器采用 `NUMA` 架构（第2章提及），堆绑定将限制在单个 `NUMA` 组内

> 若对微基准测试实现感兴趣，可从 `heap_select::access_time` 静态函数开始研究

当托管线程开始分配内存时，会被绑定到其当前执行处理器对应的堆。图6-15展示了GC托管堆、线程与逻辑核心的典型关系：运行于两个逻辑处理器的线程，正在消耗采用“all-at-once”策略构建的托管内存（见前章）。第一个CPU绑定 SOH₁ 和 LOH₁ 段，第二个CPU绑定 SOH₂ 和 LOH₂ 段（段间完全隔离）。注意处理器虽然操作进程地址空间中的特定内存区域（通过段概念隔离），但内存中并不存在操作系统或硬件层面的魔法隔离机制。不过这种隔离设计能有效利用缓存，因为每个CPU频繁且独占地操作这些段。

运行在 CPU#1 的线程（标记为 T₁ 和 T₂）其分配上下文位于 SOH₁ 内，而第二个CPU上的线程（示例中为 T₃）则使用第二个堆，以此类推。由于LOH不使用分配上下文，图中未作体现。

![](asserts/6-15.png)

图6-15展示了逻辑处理器、线程与GC托管堆的绑定关系示意图

当线程创建时，由操作系统决定其执行的逻辑处理器。这在所有托管线程内存分配量相近时运行良好，但某些情况下可能出现部分线程分配量显著高于其他线程的现象，这将导致如图6-16所示的堆不平衡状态：线程3和4的内存分配量远超线程1和2（导致 SOH₂ 剩余空间急剧减少）。这种状态会引发三个主要问题：

- SOH₂ 将很快面临内存不足，触发GC并最终需要创建新SOH段
- CPU缓存利用率失衡
- 负责回收SOH₁的线程将承担更多工作

![](asserts/6-16.png)

图6-16 多线程分配不均导致的堆不平衡状态

GC在通过慢路径分配时会执行堆平衡检查。若检测到不平衡，将为高分配线程重新分配堆——即将其分配上下文迁移至其他堆。这显然会违反前文所述的设计原则（线程在某个逻辑核心上执行却使用其他核心绑定的堆），因此GC会立即要求操作系统将该线程迁移至对应逻辑CPU执行。目前该行为仅通过Windows的 `SetThreadIdealProcessorEx` 函数实现（其他操作系统可能缺乏等效API）。堆平衡后的状态如图6-17所示。

![](asserts/6-17.png)

图6-17 图6-15场景的堆平衡结果

自.NET 4.5起，LOH堆也实现了平衡机制，这显著提升了分配性能。由于LOH平衡技术与SOH相同，此处不再赘述。

#### 固定对象堆(POH)分配API

自.NET 5起，只有数组能被分配到固定对象堆(Pinned Object Heap)。唯一的方式是使用GC类中的两个方法——`AllocateArray` 或 `AllocateUninitializedArray`，并将其 `pinned` 参数设为true。这些固定数组的元素类型只能是纯值类型（不包含任何引用类型字段），包括布尔值、数值以及仅包含值类型字段的结构体。若尝试分配不符合要求的类型数组，代码虽能编译通过，但运行时会抛出 `ArgumentException`。该限制在.NET 8中被移除。

## 内存不足异常(OutOfMemoryException)

从分配器的决策树可见，有时确实无法分配所需内存。这种情况常被误解，让我们深入剖析细节。

首先，何时会抛出 `OutOfMemoryException`？这是前文所述分配路径的最后选择，意味着：

- 垃圾回收器在分配期间已被触发（可能多次，包括完全压缩式GC），因此SOH碎片化不应是主因。除非问题极其特殊且波动，否则再次触发GC几乎无济于事。内存不足异常绝非因.NET运行时忘记回收内存所致。不过，若LOH分配时出现该异常，可考虑显式触发LOH压缩（见第7章）并再次执行GC。

- 分配器无法准备指定大小的内存区域，原因有二：
  - 虚拟内存耗尽：分配器无法保留足够大的内存区域（如创建新段）。主要由虚拟内存碎片化导致，32位运行时尤甚。碎片化会导致内存使用效率低下，因此即使系统显示有充足空闲RAM，仍可能抛出异常。切记表2-5所示的严格虚拟地址空间限制——32位运行时在64位系统上仅能支配2-3GB虚拟地址空间，即便物理内存充足。
  - 物理后备存储耗尽（包括RAM和页面/交换文件）：分配器无法提交更多内存（如扩展现有段）。需注意操作系统统筹管理所有进程内存，当系统整体内存使用（含磁盘交换）接近极限时，即使显示有空闲RAM，系统仍会拒绝运行时提交内存的请求。

由此可得两个重要结论：

- 手动触发GC通常无法缓解内存不足异常（除非在分配大对象时显式触发LOH压缩）
- 出现内存不足异常时系统显示有空闲RAM属正常现象

若遭遇内存不足异常，除修复内存泄漏外，可采取以下优化措施：

- **减少对象分配**：分析内存使用，消除不必要分配（本章后续将揭示许多隐藏的分配来源）
- **使用对象池**：通过对象复用降低碎片化，现有池方案可直接使用或自行实现
- **启用VM保留模式**：如第5章所述（对32位运行时尤为重要）
- **编译为64位**：简单有效的解决方案，通常能大幅扩展虚拟地址空间

### 场景6-1：内存不足异常

**问题描述**：某.NET生产环境进程间歇性崩溃并抛出`OutOfMemoryException`，其他环境无法复现。由于问题发生频率极低，难以附加监控工具，且无法预测下次异常发生时间，导致无法捕获完整内存转储进行分析。

**分析方案**：好消息是，Windows平台（.NET Framework和.NET Core）可配置在 `OutOfMemoryException` 发生时自动捕获完整内存转储！具体步骤如下：

1. **安装ProcDump监控工具**
   - 通过命令`procdump -i <转储文件存储目录> -ma`全局安装（如图6-18所示）
   - 调查完成后务必用 `procdump -u` 卸载，否则机器上所有崩溃进程都会生成转储文件，可能导致磁盘空间耗尽

![](asserts/6-18.png)

图 6-18. 在系统范围内安装 `procdump`工具可在发生 `OutOfMemoryException` 时自动生成内存转储文件

- 进程现已被监控，发生`OutOfMemoryException`时将自动生成完整转储
- 用 WinDbg 打开转储文件，执行`!analyze -v`命令（见代码清单6-9），可获取异常详细信息

代码清单6-9：WinDbg分析内存转储——内存不足异常信息

```plaintext
> !analyze -v
***********************************************************************
*                                                                     *
*                        Exception Analysis                           *
*                                                                     *
***********************************************************************
...
STACK_TEXT: 
02b7ee0c 273b25dd TestOOM!TestOOM.Program.TestOOM+0x3d  
02b7ee1c 273b1992 TestOOM!TestOOM.Program.Main+0x82
...
FAULTING_SOURCE_LINE: C:\Book\code\TestOOM\Program.cs  
FAULTING_SOURCE_FILE: C:\Book\code\TestOOM\Program.cs  
FAULTING_SOURCE_LINE_NUMBER: 89  
FAULTING_SOURCE_CODE:  
86: List<byte[]> bytes = new List<byte[]>();  
87: while (true)  
88: {  
> 89:     bytes.Add(new byte[1024 * 1024 * 1024]);  
90: }  
91: }
```

如代码清单6-9所示：`STACK_TEXT` 段显示触发异常的线程调用栈。若编译时包含符号文件（PDB），`FAULTING_SOURCE_CODE` 段会直接定位到引发异常的源代码行（本例为第89行的大数组分配）

对于 .NET Framework，你可以使用 `!analyzeoom` 命令可获取 GC 相关的 OOM 信息（代码清单6-10）。注意：该SOS命令暂不支持.NET Core。

代码清单6-10：WinDbg中analyzeoom命令显示的GC相关OOM信息

```plaintext
0:000> !analyzeoom  
Managed OOM occured after GC #2 (Requested to allocate 0 bytes)  
Reason: Didn't have enough memory to allocate an LOH segment  
Detail: LOH: Failed to reserve memory (1090519040 bytes)
```

您可以继续采用本书提到的其他基于内存转储的分析方法，包括检查内存段（segments）和堆（heaps）状态。需要特别注意的是：触发内存不足异常的代码可能并非问题的直接根源——它可能只是恰好在分配器无法为新对象找到合适内存空间时执行的线程。实际的内存瓶颈可能隐藏在别处。因此，建议重点分析转储文件中以下内容：

- 数量最多的对象类型
- 体积最大的对象实例
- 对象在各代堆中的分布情况

> 注意：在抛出内存不足异常前，CLR需要先分配异常对象实例。但在内存耗尽的情况下，运行时采用了巧妙的机制：系统启动时会预分配 `OutOfMemoryException` 实例（通过 `SystemDomain::CreatePreallocatedExceptions` 函数），当无法新建异常对象时直接复用该预分配实例。该机制同样适用于 `StackOverflowException` 和 `ExecutionEngineException` （具体实现可参考  `GetBestOutOfMemoryException`函数代码）。

## 栈分配

到目前为止，我们只讨论了在GC托管堆上分配对象的情况。这是最流行和最常用的方式。你已经看到我们付出了多大努力来使堆分配尽可能快。然而，正如前面章节所述，栈上的分配和释放默认就快得多——只需要移动栈指针，而且不会给GC带来任何开销。

如前所述，值类型在某些情况下可能会被分配在栈上。在特定条件下，你也可以显式要求进行栈分配。考虑到规则14——在热点路径上避免堆分配，这将是个非常有用的选项。

要在C#中显式进行栈分配，需要使用 `stackalloc` 运算符（见代码清单6-11）。它会返回一个指向栈上内存区域的指针。由于使用了指针类型，这类代码必须放在 `unsafe` 上下文中（除非像后文所示使用 `Span<T>` 类型）。新分配的内存内容未定义，因此不应做任何假设（比如认为内存会被清零）。

代码清单6-11 使用stackalloc显式栈分配

```c#
static unsafe void Test(int t)
{ 
	SomeStruct* array = stackalloc SomeStruct[20];
}
```

`stackalloc` 在C#领域非常罕见。主要因为许多开发者要么不了解这个特性，要么由于缺乏接受指针的API而未能完全掌握其用法。随着第14章将介绍的 `Span<T>` 类型的出现，这一现状已有所改变。例如当需要极高数据处理效率且不希望在大堆上分配大型数组时，就可以使用它。这种方案有两个优势：

- 如前所述，这类对象的释放只需移动栈指针——没有堆分配辅助机制，没有慢速路径，完全不涉及GC。
- 这类对象的地址隐式固定（不会移动），因为栈帧永远不会移动——你可以将指针传递给非托管代码而无需引入固定开销（但需确保非托管代码不会在函数返回后继续使用该对象）。

`stackalloc` 运算符会被编译为CIL的 `localloc` 指令（见代码清单6-12）。ECMA标准对其的描述是（部分省略）“从本地动态内存池分配size字节。当前方法返回时，本地内存池可被重用”。注意它没有明确提及栈，而是使用更通用的“本地内存池”概念（第4章已提及）。如第4章所述，ECMA标准力求技术中立，避免使用栈或堆这类具体概念。

代码清单6-12 代码清单6-11生成的CIL代码片段，展示 `stackalloc` 如何被转换为 `localloc` 指令

```
ldc.i4.s 20
conv.u
sizeof SomeStruct
mul.ovf.un
localloc
```

但通过这种方式能在栈上分配什么？ECMA标准对 `localloc` 指令没有具体说明，只承诺会分配指定字节数。由于CIL只保证内存块，CLR目前只能将其用作简单数据类型的容器。C#语言规范对 `stackalloc`运算符的定义详细描述了这些限制：只能用于“非托管类型(`unmanaged_type`)”数组。非托管类型包括：

- 基本类型：`sbyte, byte, short, ushort, int, uint, long, ulong, char, float, double, decimal` 或 `bool`
- 任何枚举类型
- 任何指针类型
- 任何用户定义的结构体（非构造类型且仅包含非托管类型字段）

需注意无法显式释放 `stackalloc` 分配的内存。方法结束时内存会被隐式释放。当密集使用栈时需特别注意，大量长时间运行的方法可能最终导致 `StackOverflowException`。

> `localloc` 指令会被JIT编译为一系列汇编 `push` 和 `sub rsp [size]` 指令来扩展栈帧。在32位和64位框架下，扩展大小会分别按8字节和16字节对齐。因此即使 `stackalloc` 两个整数的数组（通常占8字节），栈帧也会被扩展16字节（64位下）。因为在x64架构上，栈需要16字节对齐。更多细节可参考https://github.com/MicrosoftDocs/cpp-docs/blob/main/docs/build/stack-usage.md文档。

与代码清单6-11不同，使用 `stackalloc` 时不必强制使用 `unsafe` 代码。自C#7.2和.NET Core 2.1起，可以通过 `Span<T>` 类型（第15章详解）安全地编写代码，如代码清单6-13所示。

代码清单6-13 借助 `Span<T>` 支持，在安全代码中使用 `stackalloc` 进行显式栈分配

```c#
 static void Test(int t)
 { 
   Span<SomeStruct> array = stackalloc SomeStruct[20];
 }
```

## 避免内存分配

前文已详细探讨了内存分配及其底层机制。现在你应该充分认识到，在.NET中“内存分配很廉价”的说法有时成立（得益于分配上下文中的指针碰撞技术），但实际情况要复杂得多：

- 当走快速路径时，内存分配确实廉价。但分配上下文有时会不可预测地耗尽，此时必须切换上下文，触发更复杂（因而更慢）的分配路径

- 这些复杂分配路径会不时触发垃圾回收

- 大对象堆(LOH)上的大对象分配较慢，主要因为内存清零的成本

  > **内存清零**是指在分配新对象时，将分配给该对象的内存区域中的每个字节都设置为0的过程。在底层，这通常通过类似于`memset()`这样的函数实现，或使用专门的CPU指令（如Intel的 `REP STOSB`或AVX指令集中的向量操作）来填充内存。
  >
  > .NET必须清零内存的原因有三个：
  >
  > 1. **安全性**：防止新对象能够访问到之前对象留下的可能敏感的数据
  > 2. **语言规范需求**：C#规范要求所有字段必须有确定的初始值（引用类型为`null`，数值类型为`0`等）
  > 3. **简化开发**：开发人员可以假设对象字段已初始化为默认值
  >
  > 大对象堆(LOH)上的清零操作特别昂贵：
  >
  > 1. 内存体积因素
  >
  >    - 大对象堆用于存储大于85KB的对象（在标准.NET配置中）
  >
  >    - 清零时间与内存大小成正比，清零1MB内存比清零1KB内存大约需要1000倍时间
  >
  > 2. 硬件架构限制
  >
  >    - **内存带宽瓶颈**：清零大量连续内存受限于系统内存总线带宽
  >
  >    - **CPU缓存影响**：大对象远超L1/L2/L3缓存大小，导致大量缓存未命中
  >
  >    - **内存页面处理**：大对象可能跨越多个物理内存页面，增加TLB（转译后备缓冲器）未命中
  >
  > 3. 没有分配上下文优化
  >
  >    - 小对象堆(SOH)通常可以利用线程本地分配缓冲区(TLAB)和预先清零的内存块
  >
  >    - 大对象堆由于对象尺寸，无法有效利用这些优化
  >
  > 4. 处理器执行特性
  >
  >    - 清零大内存块时，CPU流水线可能会受到影响
  >
  >    - 分支预测和指令级并行性在重复的内存操作中效率降低
  >
  >    - NUMA架构下，跨节点的大内存分配会进一步降低性能
  >
  > 举个例子：假设分配一个大小为100MB的数组：
  >
  > - 系统必须清零约104,857,600个字节
  > - 在3GB/s的内存写入带宽下，理论上最快需要约35毫秒
  > - 实际上，考虑到其他开销，可能需要50-100毫秒
  > - 相比之下，分配一个小对象可能只需几十纳秒

- 大量分配对象会增加GC的工作量——这个显而易见的道理却至关重要。若分配大量临时对象，后续必须清理。创建的对象越多，打破对象生命周期分代假设的概率就越高

因此，.NET中最有效的内存优化方法之一就是避免分配，或至少保持分配意识。少量分配意味着：

- 给GC的内存压力小
- 内存访问成本低
- 与操作系统的交互少

性能敏感的.NET开发者需要掌握的核心知识是：了解内存分配的来源，以及如何消除或最小化它们。

本节列举常见分配来源及应对方案。但请注意一个重要原则——必须谨慎对待最小化分配这件事。有句常被滥用的名言：“过早优化是万恶之源”。确实没必要逐行分析代码中的每个分配点，这只会降低效率却收效甚微。每分钟执行一次的代码分配200字节还是800字节有区别吗？很可能没有。关键取决于代码需求。因此，从性能关键路径开始分析分配总是明智的，这些优化能带来最大收益。

首先需要了解常见分配来源以避免明显错误，至少清楚所写代码的内存开销。结合应用整体需求和具体场景，就能判断是否可接受。其次，掌握分配来源知识有助于应用规则5——尽早测量GC。只有通过测量才能避免对错误代码的过早优化，才能判断是否需要最小化分配，才能确定优化重点。

下文列出常见分配来源（有些显而易见，有些则不然），包括其发生条件及规避方法。

> 本章后续展示C#编译器机制时，使用 dnSpy 工具反编译代码有助于理解底层原理。建议读者通过修改代码、反编译观察运行时最终执行的代码变化来加深理解。

### 引用类型的显式分配

大多数分配场景显而易见——显式创建对象时。此时可以考虑是否真的需要创建堆上的引用类型对象。以下是不同场景的解决方案。

#### 通用场景——考虑使用结构体

开发者可能习惯使用类而忽略替代方案。实际上多数场景下，可以通过结构体在方法参数和返回值间传递少量数据。第4章代码清单4-7展示了这种情况，清单4-8和4-9则显示相比在堆上创建小对象，使用结构体生成的代码更优。表4-1的基准测试显示两者性能差异显著。

因此，当方法间传递的少量数据不存储在堆数据结构中时，应优先考虑结构体。许多业务逻辑都符合这个特点——获取数据、本地处理、返回结果。以代码清单6-14为例，该代码返回指定位置半径内所有雇员的完整姓名，展示了从外部服务获取集合的典型用法，但这种方式显式创建了大量对象：

- `PersonDataClass` 对象列表及对象本身
- 外部服务返回的 `Employee` 对象

```c#
[Benchmark]
public List PeopleEmployeedWithinLocation_Classes(int amount, LocationClass location)
{
    List result = new List();
    List input = service.GetPersonsInBatchClasses(amount);
    DateTime now = DateTime.Now;
    for (int i = 0; i < input.Count; ++i)
    {
        PersonDataClass item = input[i];
        if (now.Subtract(item.BirthDate).TotalDays > 18 * 365)
        {
            var employee = service.GetEmployeeClass(item.EmployeeId);
            if (locationService.DistanceWithClass(location, employee.Address) < 10.0)
            {
                string name = string.Format("{0} {1}", item.Firstname, item.Lastname);
                result.Add(name);
            }
        }
    }
    return result;
}

internal List GetPersonsInBatchClasses(int amount)
{
    List result = new List(amount);
    // 从外部源填充列表
    return result;
}
```

若改用结构体实现（见代码清单6-15），由于人员数据仅在方法内使用，可安全存储在栈上。`GetPersonsInBatch` 方法返回结构体数组能提高数据局部性、降低开销（如第4章所述）。外部服务如 `GetEmployeeStruct` 可返回小结构体，`DistanceWithStruct` 等方法可通过引用传递值类型参数避免复制。

代码清单6-15 尽可能使用结构体的业务逻辑示例

```c#
[Benchmark]
public List PeopleEmployeedWithinLocation_Structs(int amount, LocationStruct location)
{
    List result = new List();
    PersonDataStruct[] input = service.GetPersonsInBatchStructs(amount);
    DateTime now = DateTime.Now;
    for (int i = 0; i < input.Length; ++i)
    {
        ref PersonDataStruct item = ref input[i];
        if (now.Subtract(item.BirthDate).TotalDays > 18 * 365)
        {
            var employee = service.GetEmployeeStruct(item.EmployeeId);
            if (locationService.DistanceWithStruct(ref location, employee.Address) < 10.0)
            {
                string name = string.Format("{0} {1}", item.Firstname, item.Lastname);
                result.Add(name);
            }
        }
    }
    return result;
}

internal PersonDataStruct[] GetPersonsInBatchStructs(int amount)
{
    PersonDataStruct[] result = new PersonDataStruct[amount];
    // 从外部源填充数组
    return result;
}
```

相比清单6-14，清单6-15代码因引用传递略显复杂，但仍保持可读性。实测内存分配量减半（见表6-2），高频调用时差异显著。

表6-2 处理1000个对象/结构体时的基准测试结果

| 方法                                  | 平均耗时  | Gen 0回收 | 内存分配 |
| ------------------------------------- | --------- | --------- | -------- |
| PeopleEmployeedWithinLocation_Classes | 348.8微秒 | 15.1367次 | 62.60 KB |
| PeopleEmployeedWithinLocation_Structs | 344.7微秒 | 9.2773次  | 39.13 KB |

> 注意：`record`（底层是类）与 `record struct`（底层是结构体）具有相同的性能特性。虽然 `record struct` 在`GetHashCode` 和相等比较实现上有优势，但从内存管理角度看与普通结构体无异。

#### 元组——使用ValueTuple替代

通常需要返回或传递一个非常简单的数据结构，该结构只有几个字段。如果该类型仅使用一次，可能会倾向于使用元组或匿名类型，而不是定义一个类（见代码清单6-16）。然而，需要理解的是，`Tuple` 和匿名类型都是引用类型，因此总是在堆上分配内存。

代码清单6-16. 为仅使用一次的数据创建的元组和匿名类型

```csharp
var tuple1 = new Tuple<int, double>(0, 0.0);  
var tuple2 = Tuple.Create(0, 0.0);  
var tuple3 = new { A = 1, B = 0.0 };  
```

根据前文所述，在这种情况下应考虑使用用户定义的结构体。然而，自C# 7.0起，引入了一种新的值类型——值元组（`ValueTuple`），由 `ValueTuple` 结构体表示（见代码清单6-17）。这可以很好地替代之前使用的类，在某些场景下无需创建自定义结构体。

代码清单6-17. C# 7.0中引入的值元组

```csharp
var tuple4 = (0, 0.0);  
var tuple5 = (A: 0, B: 0.0);  
tuple5.A = 3;  
```

典型用例包括从方法返回多个值。相比于使用 `Tuple`（或自定义类）来包含所有结果（如代码清单6-18中的 `ProcessData1` 方法），可以使用值元组结构体，其中仅包含其他结构体（如代码清单6-18中的 `ProcessData2` 方法）。

代码清单6-18. 值元组与元组用于从方法返回多个值的对比

```csharp
public static Tuple<ResultDesc, ResultData> ProcessData1(IEnumerable<SomeClass> data)  
{  
    // 进行一些处理  
    return new Tuple<ResultDesc, ResultData>(new ResultDesc() { ... }, new ResultData() { ... });  
    // 或使用：  
    // return Tuple.Create(new ResultDesc() { ... }, new ResultData() { Average = 0.0, Sum = 10.0 });  
}  

public static (ResultDescStruct, ResultDataStruct) ProcessData2(IEnumerable<SomeClass> data)  
{  
    // 进行一些处理  
    return (new ResultDescStruct() { ... }, new ResultDataStruct() { ... });  
}  

public class ResultDesc  
{  
    public int Count;  
}  

public class ResultData  
{  
    public double Sum;  
    public double Average;  
}  

public struct ResultDescStruct  
{  
    public int Count;  
}  

public struct ResultDataStruct  
{  
    public double Sum;  
    public double Average;  
}  
```

这可以显著减少从方法返回多个值时的开销（见表6-3）。由于使用了结构体，`ProcessData2` 运行时无需任何内存分配！整个函数的性能提升了四倍以上。

表6-3. 代码清单6-18的DotNetBenchmark结果

| 方法         | 平均时间  | 内存分配 |
| ------------ | --------- | -------- |
| ProcessData1 | 18.380 ns | 88 B     |
| ProcessData2 | 4.472 ns  | 0 B      |

值元组还引入了一个称为解构（deconstruction）的特性，允许从元组中提取值并直接分配给单独的变量。还可以使用丢弃符（discards）明确表示对元组中的某些元素不感兴趣（见代码清单6-19）。这在某些场景中非常有用，因为编译器和JIT可以利用这些信息进一步优化底层结构的使用。

代码清单6-19. 使用丢弃符解构元组

```csharp
(ResultDescStruct desc, _) = ProcessData2(list);  
```

> ORM中计划并可能即将推出更改，以允许将数据库查询结果具体化为值元组和结构体。这将使它们的使用更加实用。请关注您使用的ORM或自行投票支持此类更改！

#### 小型临时本地数据——考虑使用 stackalloc

前文已经展示了使用结构体替代对象可以为本地临时数据带来显著的好处。相比于创建对象列表，可以使用结构体数组。然而，需要注意的是，结构体数组仍然在堆上分配——唯一的好处是数据更紧凑。但可以通过使用 `stackalloc` 进一步消除堆分配。

假设有一个简单的方法，接收一个对象列表，将其转换为临时列表，并处理该列表以计算某些统计数据。典型的基于 LINQ 的方法如代码清单6-20所示，但希望您可以将其推广到更复杂的情况。这种方法会分配大量内存——包含许多临时对象的列表。

代码清单6-20. 完全基于类的简单列表处理示例

```csharp
public double ProcessEnumerable(List<BigData> list)  
{  
    double avg = ProcessData1(list.Select(x => new DataClass() { Age = x.Age, Sex = Helper(x.Description) ? Sex.Female : Sex.Male }));  
    _logger.Debug("Result: {0}", avg / _items);  
    return avg;  
}  

public double ProcessData1(IEnumerable<DataClass> list)  
{  
    // 对列表项进行一些处理  
    return result;  
}  

public class BigData  
{  
    public string Description;  
    public double Age;  
}  
```

可以像前面的示例一样使用结构体数组。但这里我们使用 `stackalloc` 和 `Span<T>`（不安全代码）（见代码清单6-21）。

代码清单6-21. 完全基于结构体和 `stackalloc` 的简单列表处理示例

```csharp
public double ProcessStackalloc(List<BigData> list)  
{  
    // 危险但无需不安全代码！  
    Span<DataStruct> data = stackalloc DataStruct[list.Count];  
    for (int i = 0; i < list.Count; ++i)  
    {  
        data[i].Age = list[i].Age;  
        data[i].Sex = Helper(list[i].Description) ? Sex.Female : Sex.Male;  
    }  
    double result = ProcessData2(data);  
    return result;  
}  

// 将Span作为只读传递，明确表示不应修改  
public double ProcessData2(ReadOnlySpan<DataStruct> list)  
{  
    // 对list[i]项进行一些处理  
    return result;  
}  
```

新版本的代码带来了巨大的差异（见表6-4）。改进后的版本完全不分配内存，且速度提升了约四倍！如果此类代码位于热路径上，这绝对值得考虑。

表6-4. 代码清单6-20和6-21的DotNetBenchmark结果——处理100个元素

| 方法              | 平均时间   | 内存分配 |
| ----------------- | ---------- | -------- |
| ProcessEnumerable | 1,169.9 ns | 3272 B   |
| ProcessStackalloc | 443.2 ns   | 0 B      |

然而，请注意，`stackalloc` 应仅用于小型缓冲区（例如不超过1 kB）。使用 `stackalloc` 方法的主要风险是触发`StackOverflowException`，这在栈空间不足时可能发生。`StackOverflowException` 是一种无法捕获的异常，会直接终止整个应用程序而无法缓解。因此，分配过大的缓冲区是有风险的。代码清单6-21中的栈分配行尤其危险，因为元素数量事先未知。为了更安全，可以考虑一种模式，即检查元素数量，仅在足够小时使用 `stackalloc`，如代码清单6-22所示。

代码清单6-22. 基于结构体的简单列表处理示例，更安全地使用 `stackalloc`

```csharp
public double ProcessStackalloc(List<BigData> list)  
{  
    Span<DataStruct> data = list.Count < 100 ? stackalloc DataStruct[list.Count] : new DataStruct[list.Count];  
    for (int i = 0; i < list.Count; ++i)  
    {  
        data[i].Age = list[i].Age;  
        data[i].Sex = Helper(list[i].Description) ? Sex.Female : Sex.Male;  
    }  
    double result = ProcessData2(data);  
    return result;  
}  

// 将Span作为只读传递，明确表示不应修改  
public double ProcessData2(ReadOnlySpan<DataStruct> list)  
{  
    // 对list[i]项进行一些处理  
    return result;  
}  
```

在栈上分配大型数据甚至从性能角度来看也不太好，因为在线程栈上填充大块内存区域会引入大量内存页到进程工作集中（导致页面错误）。这些页面不与其他线程共享，因此可能是一种浪费的方法。

> 栈是一种快速分配和释放内存的结构，主要用作函数调用的局部变量存储。当一个函数被调用时，局部变量会在栈上分配内存，函数返回时，这些内存会自动释放。
>
> 当栈上分配大型数据的时候（比如一个几MB的数组），需要大量的内存页。如果这些内存页还没有被加载到内存中，就会触发大量页面错误，页面错误会导致内核模式的上下文切换，并消耗CPU时间来完成内存映射。这时候性能就会极具下降。
>
> 这里的**工作集**指的是程序在一段时间内频繁访问的内存页集合。栈上的数据是线程局部的，**不能被其他线程共享**。如果一个线程在栈上分配了大型数据，这些内存页只属于这个线程的工作集。如果程序有多个线程，每个线程都在栈上分配大块内存，内存页的需求会迅速膨胀，导致内存使用效率低下。

如果决定使用 `stackalloc` 并希望100%确保不会发生 `StackOverflowException`，可能会想使用 `RuntimeHelpers.TryEnsureSufficientExecutionStack()` 或 `RuntimeHelpers.EnsureSufficientExecutionStack()` 方法。如文档所述，这些方法“确保剩余的栈空间足够执行平均的.NET Framework函数”。当前值在32位和64位环境中分别为64 kB和128 kB。换句话说，如果`RuntimeHelpers.TryEnsureSufficientExecutionStack()` 返回 `true`，则 `stackalloc` 大小低于128 kB的缓冲区可能是安全的。我们说的是“可能”，因为这些值是实现细节，并不保证——仅确保“平均.NET Framework函数”的空间，这可能不包括大型 `stackalloc`。换句话说，仅 `stackalloc` 非常小的缓冲区是安全的（如前所述，1 kB似乎是安全值）。
